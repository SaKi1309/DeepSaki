{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"DeepSaki","text":"<p>Custom deep learning package for TensorFlow by Sascha Kirch.</p>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>DeepSaki<ul> <li>activations</li> <li>augmentations</li> <li>constraints</li> <li>initializers</li> <li>layers</li> <li>loss</li> <li>models</li> <li>optimizer</li> <li>utils</li> </ul> </li> </ul>"},{"location":"reference/DeepSaki/activations/","title":"activations","text":"<p>Activation functions applicable to complex-valued and real-valued inputs</p>"},{"location":"reference/DeepSaki/activations/#DeepSaki.activations.complex_valued_activations.ComplexActivation","title":"ComplexActivation","text":"<pre><code>ComplexActivation(\n    activation: tf.keras.layers.Layer = tf.keras.layers.ReLU(),\n    **kwargs: Any\n)\n</code></pre> <p>             Bases: <code>tf.keras.layers.Layer</code></p> <p>Wrapper to apply a given <code>activation</code> to a complex input individually for the real and imaginary part.</p> Inherits from <p>tf.keras.layers.Layer</p> <p>Initialize ComplexActivation.</p> <p>Parameters:</p> Name Type Description Default <code>activation</code> <code>tf.keras.layers.Layer</code> <p>Activation function to complexyfy. Defaults to tf.keras.layers.ReLU().</p> <code>tf.keras.layers.ReLU()</code> <code>kwargs</code> <code>Any</code> <p>keyword arguments passed to the parent class tf.keras.layers.Layer.</p> <code>{}</code> Source code in <code>DeepSaki/activations/complex_valued_activations.py</code> <pre><code>def __init__(self, activation: tf.keras.layers.Layer = tf.keras.layers.ReLU(), **kwargs: Any) -&gt; None:\n    \"\"\"Initialize ComplexActivation.\n\n    Args:\n        activation (tf.keras.layers.Layer, optional): Activation function to complexyfy. Defaults to tf.keras.layers.ReLU().\n        kwargs: keyword arguments passed to the parent class tf.keras.layers.Layer.\n    \"\"\"\n    super(ComplexActivation, self).__init__(**kwargs)\n    self.activation = activation\n</code></pre>"},{"location":"reference/DeepSaki/activations/#DeepSaki.activations.complex_valued_activations.ComplexActivation.call","title":"call","text":"<pre><code>call(\n    inputs: tf.Tensor,\n) -&gt; Union[tf.complex64, tf.complex128]\n</code></pre> <p>Splits its intput <code>inputs</code>into a real and imaginary part, applies <code>activation</code> and constructs a complex number.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>tf.Tensor</code> <p>Input tensor to be activated. Might be a complex or real valued tensor.</p> required <p>Returns:</p> Type Description <code>Union[tf.complex64, tf.complex128]</code> <p>Union[tf.complex64,tf.complex128]: Complex tensor with activated real and imaginary part.</p> Source code in <code>DeepSaki/activations/complex_valued_activations.py</code> <pre><code>def call(self, inputs: tf.Tensor) -&gt; Union[tf.complex64, tf.complex128]:\n    \"\"\"Splits its intput `inputs`into a real and imaginary part, applies `activation` and constructs a complex number.\n\n    Args:\n        inputs (tf.Tensor): Input tensor to be activated. Might be a complex or real valued tensor.\n\n    Returns:\n        Union[tf.complex64,tf.complex128]: Complex tensor with activated real and imaginary part.\n    \"\"\"\n    real = self.activation(tf.math.real(inputs))\n    imag = self.activation(tf.math.imag(inputs))\n    return tf.complex(real, imag)\n</code></pre>"},{"location":"reference/DeepSaki/activations/#DeepSaki.activations.complex_valued_activations.ComplexActivation.get_config","title":"get_config","text":"<pre><code>get_config() -&gt; Dict[str, Any]\n</code></pre> <p>Returns configuration of class instance.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict[str,Any]: Dictionary containing the class' configuration.</p> Source code in <code>DeepSaki/activations/complex_valued_activations.py</code> <pre><code>def get_config(self) -&gt; Dict[str, Any]:\n    \"\"\"Returns configuration of class instance.\n\n    Returns:\n        Dict[str,Any]: Dictionary containing the class' configuration.\n    \"\"\"\n    config = super(ComplexActivation, self).get_config()\n    config.update({\"activation\": self.activation})\n    return config\n</code></pre>"},{"location":"reference/DeepSaki/augmentations/","title":"augmentations","text":"<p>Cutting operations performed on batched 3D grid-shaped data types like images.</p>"},{"location":"reference/DeepSaki/augmentations/#DeepSaki.augmentations.grid_cutting.cut_mix","title":"cut_mix","text":"<pre><code>cut_mix(\n    batch1: tf.Tensor,\n    batch2: tf.Tensor,\n    ignore_background: bool = False,\n    invert_mask: bool = False,\n    mask: Optional[tf.Tensor] = None,\n) -&gt; Tuple[tf.Tensor, tf.Tensor]\n</code></pre> <p>Performs the cutmix operation of two image batches.</p> <p>A random image patch from <code>batch2</code> is taken and inserted into <code>batch1.</code></p> <p>Parameters:</p> Name Type Description Default <code>batch1</code> <code>tf.Tensor</code> <p>Batch of grid-shaped data of shape (<code>batch</code>, <code>height</code>, <code>width</code>, <code>channel</code>).</p> required <code>batch2</code> <code>tf.Tensor</code> <p>Batch of grid-shaped data of shape (<code>batch</code>, <code>height</code>, <code>width</code>, <code>channel</code>).</p> required <code>ignore_background</code> <code>bool</code> <p>If true, pixels belonging to the backgroud are ignored. Only applicable for images where the background is represented as 0. Defaults to False.</p> <code>False</code> <code>invert_mask</code> <code>bool</code> <p>If true, the mask is inverted. 1-&gt;0 and 0-&gt;1. Defaults to False.</p> <code>False</code> <code>mask</code> <code>Optional[tf.Tensor]</code> <p>Binary mask that requires same shape as <code>batch1</code> and <code>batch2</code>. If <code>None</code> mask is generated randomly. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>ground_truth_mask</code> <code>tf.Tensor</code> <p>Actual mask that has been applied</p> <code>new_batch</code> <code>tf.Tensor</code> <p>Batch with applied cutmix opperation</p> Source code in <code>DeepSaki/augmentations/grid_cutting.py</code> <pre><code>def cut_mix(\n    batch1: tf.Tensor,\n    batch2: tf.Tensor,\n    ignore_background: bool = False,\n    invert_mask: bool = False,\n    mask: Optional[tf.Tensor] = None,\n) -&gt; Tuple[tf.Tensor, tf.Tensor]:\n    \"\"\"Performs the cutmix operation of two image batches.\n\n    A random image patch from `batch2` is taken and inserted into `batch1.`\n\n    Args:\n        batch1 (tf.Tensor): Batch of grid-shaped data of shape (`batch`, `height`, `width`, `channel`).\n        batch2 (tf.Tensor): Batch of grid-shaped data of shape (`batch`, `height`, `width`, `channel`).\n        ignore_background (bool, optional): If true, pixels belonging to the backgroud are ignored. Only applicable for\n            images where the background is represented as 0. Defaults to False.\n        invert_mask (bool, optional): If true, the mask is inverted. 1-&gt;0 and 0-&gt;1. Defaults to False.\n        mask (Optional[tf.Tensor], optional): Binary mask that requires same shape as `batch1` and `batch2`. If `None`\n            mask is generated randomly. Defaults to None.\n\n    Returns:\n        ground_truth_mask: Actual mask that has been applied\n        new_batch: Batch with applied cutmix opperation\n    \"\"\"\n    batch1 = tf.cast(batch1, tf.float32)\n    batch2 = tf.cast(batch2, tf.float32)\n\n    if mask is None:  # generate mask\n        mask = _get_mask(shape=batch1.shape)\n\n    if ignore_background:  # check where in image are no background pixels (value = 1)\n        batch1_mask = tf.cast(tf.where(batch1 &gt; 0, 1, 0), tf.int32)\n        batch2_mask = tf.cast(tf.where(batch2 &gt; 0, 1, 0), tf.int32)\n        mutal_person_mask = tf.cast(tf.clip_by_value((batch1_mask + batch2_mask), 0, 1), tf.float32)\n        ground_truth_mask = 1 - (1 - mask) * mutal_person_mask\n\n    else:\n        ground_truth_mask = mask\n\n    if invert_mask:\n        ground_truth_mask = 1 - ground_truth_mask\n\n    new_batch = batch1 * ground_truth_mask + batch2 * (1 - ground_truth_mask)\n\n    return ground_truth_mask, new_batch\n</code></pre>"},{"location":"reference/DeepSaki/augmentations/#DeepSaki.augmentations.grid_cutting.cut_out","title":"cut_out","text":"<pre><code>cut_out(\n    batch: tf.Tensor,\n    invert_mask: bool = False,\n    mask: Optional[tf.Tensor] = None,\n) -&gt; Tuple[tf.Tensor, tf.Tensor]\n</code></pre> <p>Performs the cutout operation of a batch of images.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>tf.Tensor</code> <p>Batch of grid-shaped data of shape (<code>batch</code>, <code>height</code>, <code>width</code>, <code>channel</code>).</p> required <code>invert_mask</code> <code>bool</code> <p>If true, the mask is inverted. 1-&gt;0 and 0-&gt;1. Defaults to False.</p> <code>False</code> <code>mask</code> <code>Optional[tf.Tensor]</code> <p>Binary mask that requires same shape as <code>batch1</code> and <code>batch2</code>. If <code>None</code> mask is generated randomly. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>mask</code> <code>tf.Tensor</code> <p>Actual mask that has been applied</p> <code>new_batch</code> <code>tf.Tensor</code> <p>Batch with applied cutout opperation</p> Source code in <code>DeepSaki/augmentations/grid_cutting.py</code> <pre><code>def cut_out(\n    batch: tf.Tensor, invert_mask: bool = False, mask: Optional[tf.Tensor] = None\n) -&gt; Tuple[tf.Tensor, tf.Tensor]:\n    \"\"\"Performs the cutout operation of a batch of images.\n\n    Args:\n        batch (tf.Tensor): Batch of grid-shaped data of shape (`batch`, `height`, `width`, `channel`).\n        invert_mask (bool, optional):  If true, the mask is inverted. 1-&gt;0 and 0-&gt;1. Defaults to False.\n        mask (Optional[tf.Tensor], optional): Binary mask that requires same shape as `batch1` and `batch2`. If `None`\n            mask is generated randomly. Defaults to None.\n\n    Returns:\n        mask: Actual mask that has been applied\n        new_batch: Batch with applied cutout opperation\n    \"\"\"\n    batch = tf.cast(batch, tf.float32)\n\n    if mask is None:  # generate mask\n        mask = _get_mask(shape=batch.shape)\n\n    if invert_mask:\n        mask = 1 - mask\n\n    new_batch = batch * mask\n    return mask, new_batch\n</code></pre>"},{"location":"reference/DeepSaki/constraints/","title":"constraints","text":"<p>Collection of custom constraints.</p> <p>Description of TensorFlow's <code>tf.keras.constraints.Constraint</code> base class:     A Constraint instance works like a stateless function. Users who subclass this class should override the     <code>__call__</code> method, which takes a single weight parameter and return a projected version of that parameter (e.g.     normalized or clipped). Constraints can be used with various Keras layers via the <code>kernel_constraint</code> or     <code>bias_constraint</code> arguments.</p>"},{"location":"reference/DeepSaki/constraints/#DeepSaki.constraints.constraints.NonNegative","title":"NonNegative","text":"<p>             Bases: <code>tf.keras.constraints.Constraint</code></p> <p>Constraint that enforces positive activations.</p>"},{"location":"reference/DeepSaki/constraints/#DeepSaki.constraints.constraints.NonNegative.__call__","title":"__call__","text":"<pre><code>__call__(w: tf.Tensor) -&gt; tf.Tensor\n</code></pre> <p>Clips negative values of a provided weight tensor <code>w</code> to 0.0 and leaves positive values unchanged.</p> <p>Parameters:</p> Name Type Description Default <code>w</code> <code>tf.Tensor</code> <p>Tensor containing the wehights of a layer.</p> required <p>Returns:</p> Type Description <code>tf.Tensor</code> <p>Tensor where negative values are clipped to 0.0.</p> Source code in <code>DeepSaki/constraints/constraints.py</code> <pre><code>def __call__(self, w: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"Clips negative values of a provided weight tensor `w` to 0.0 and leaves positive values unchanged.\n\n    Args:\n        w (tf.Tensor): Tensor containing the wehights of a layer.\n\n    Returns:\n        Tensor where negative values are clipped to 0.0.\n    \"\"\"\n    return w * tf.cast(tf.math.greater_equal(w, 0.0), w.dtype)\n</code></pre>"},{"location":"reference/DeepSaki/initializers/","title":"initializers","text":"<p>Set of initializers based on the He initializer.</p> <p>In contrast to the tensorflow implementation, an alpha value can be set to consider the non-zero slope of a LeakyReLU activation.</p>"},{"location":"reference/DeepSaki/initializers/#DeepSaki.initializers.initializer_helper.make_initializer_complex","title":"make_initializer_complex","text":"<pre><code>make_initializer_complex(\n    initializer: tf.keras.initializers.Initializer,\n) -&gt; Callable[[List[int], tf.DType], tf.complex]\n</code></pre> <p>Returns a function that applies a given <code>initializer</code> to generate a complex-valued tensor for initialization.</p> <p>The function applies the initializer twice, once for the <code>real</code> part and once for the <code>imaginary</code> part and then constructs a complex-valued tensor of the provided <code>shape</code>.</p> <p>Examples: <pre><code># Standalone usage:\ninitializer = make_initializer_complex(tf.keras.initializers.GlorotUniform())\nvalues = initializer(shape=(2, 2))\n</code></pre> <pre><code># Usage in a Keras layer:\ninitializer = make_initializer_complex(tf.keras.initializers.GlorotUniform())\nlayer = tf.keras.layers.Dense(3, kernel_initializer=initializer)\n</code></pre></p> <p>Parameters:</p> Name Type Description Default <code>initializer</code> <code>tf.keras.initializers.Initializer</code> <p>Any real valued initializer object.</p> required <p>Returns:</p> Type Description <code>Callable[[List[int], tf.DType], tf.complex]</code> <p>Wrapper function with same function signature as a <code>tf.keras.initializers.Initializer</code> object.</p> Source code in <code>DeepSaki/initializers/initializer_helper.py</code> <pre><code>def make_initializer_complex(\n    initializer: tf.keras.initializers.Initializer,\n) -&gt; Callable[[List[int], tf.DType], tf.complex]:\n    \"\"\"Returns a function that applies a given `initializer` to generate a complex-valued tensor for initialization.\n\n    The function applies the initializer twice, once for the `real` part and once for the `imaginary` part and then\n    constructs a complex-valued tensor of the provided `shape`.\n\n\n    **Examples:**\n    ```python\n    # Standalone usage:\n    initializer = make_initializer_complex(tf.keras.initializers.GlorotUniform())\n    values = initializer(shape=(2, 2))\n    ```\n    ```python\n    # Usage in a Keras layer:\n    initializer = make_initializer_complex(tf.keras.initializers.GlorotUniform())\n    layer = tf.keras.layers.Dense(3, kernel_initializer=initializer)\n    ```\n\n    Args:\n        initializer (tf.keras.initializers.Initializer): Any real valued initializer object.\n\n    Returns:\n        Wrapper function with same function signature as a `tf.keras.initializers.Initializer` object.\n    \"\"\"\n\n    def complex_initializer(shape: List[int], dtype: tf.DType = tf.float64) -&gt; tf.complex:\n        \"\"\"Function that applies a given `initializer` to generate a complex-valued tensor for initialization.\n\n        Args:\n            shape (List[int]): Shape of the tensor to be initialized.\n            dtype (tf.DType, optional): dtype of the individual terms of the complex number. Defaults to `tf.float64`.\n\n        Returns:\n            Complex-valued tensor with values drawn from the `initializer`, seperatly for `real` and `imaginary` part.\n        \"\"\"\n        if dtype == tf.complex64:\n            dtype = tf.float32\n        elif dtype == tf.complex128:\n            dtype = tf.float64\n        real = initializer(shape, dtype)\n        imag = initializer(shape, dtype)\n        return tf.dtypes.complex(real, imag)\n\n    return complex_initializer\n</code></pre>"},{"location":"reference/DeepSaki/initializers/#DeepSaki.initializers.he_alpha.HeAlpha","title":"HeAlpha","text":"<pre><code>HeAlpha(alpha: float = 0.3, seed: Optional[int] = None)\n</code></pre> <p>             Bases: <code>tf.keras.initializers.Initializer</code></p> <p>Parent class for HeAlpha initializers. Can not be called, must be inherited from.</p> <p>HeAlpha is a He initializer that considers the negative slope of the LeakyReLU activation.</p> <p>Dunder method to initialize HeAlpha object.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>float</code> <p>Variable to control the width of the distribution. Should be set according the alpha value of the LeakyReLU activation. Defaults to 0.3.</p> <code>0.3</code> <code>seed</code> <code>Optional[int]</code> <p>Seed for the random distribution. Defaults to None.</p> <code>None</code> Source code in <code>DeepSaki/initializers/he_alpha.py</code> <pre><code>def __init__(self, alpha: float = 0.3, seed: Optional[int] = None) -&gt; None:\n    \"\"\"Dunder method to initialize HeAlpha object.\n\n    Args:\n        alpha (float, optional): Variable to control the width of the distribution. Should be set according the\n            alpha value of the LeakyReLU activation. Defaults to 0.3.\n        seed (Optional[int], optional): Seed for the random distribution. Defaults to None.\n    \"\"\"\n    self.alpha = alpha\n    self.seed = seed\n</code></pre>"},{"location":"reference/DeepSaki/initializers/#DeepSaki.initializers.he_alpha.HeAlpha.__call__","title":"__call__","text":"<pre><code>__call__(\n    shape: List[int],\n    dtype: Optional[Union[tf.DType, np.dtype]] = None,\n) -&gt; NoReturn\n</code></pre> <p>Abstract dunder method to call the object instance that must be overridden by child classes.</p> <p>Parameters:</p> Name Type Description Default <code>shape</code> <code>List[int]</code> <p>Shape of the tensor that shall be initialized.</p> required <code>dtype</code> <code>Optional[Union[tf.DType, np.dtype]]</code> <p>dtype to which the data should be casted to. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>if calling child class does not override <code>__call()__</code></p> Source code in <code>DeepSaki/initializers/he_alpha.py</code> <pre><code>def __call__(self, shape: List[int], dtype: Optional[Union[tf.DType, np.dtype]] = None) -&gt; NoReturn:\n    \"\"\"Abstract dunder method to call the object instance that must be overridden by child classes.\n\n    Args:\n        shape (List[int]): Shape of the tensor that shall be initialized.\n        dtype (Optional[Union[tf.DType, np.dtype]], optional): dtype to which the data should be casted to.\n            Defaults to None.\n\n    Raises:\n        NotImplementedError: if calling child class does not override `__call()__`\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/DeepSaki/initializers/#DeepSaki.initializers.he_alpha.HeAlpha.compute_fans","title":"compute_fans","text":"<pre><code>compute_fans(shape: List[int]) -&gt; Tuple[int, int]\n</code></pre> <p>Computes the number of input and output units for a weight shape.</p> <p>Parameters:</p> Name Type Description Default <code>shape</code> <code>List[int]</code> <p>Shape of the input tensor representing the weights of a neuronal network.</p> required <p>Returns:</p> Type Description <code>Tuple[int, int]</code> <p>Tuple[int,int]: (fan_in, fan_out)</p> Source code in <code>DeepSaki/initializers/he_alpha.py</code> <pre><code>def compute_fans(self, shape: List[int]) -&gt; Tuple[int, int]:\n    \"\"\"Computes the number of input and output units for a weight shape.\n\n    Args:\n        shape (List[int]): Shape of the input tensor representing the weights of a neuronal network.\n\n    Returns:\n        Tuple[int,int]: (fan_in, fan_out)\n    \"\"\"\n    if len(shape) &lt; 1:  # Just to avoid errors for constants.\n        fan_in = fan_out = 1\n    elif len(shape) == 1:\n        fan_in = fan_out = shape[0]\n    elif len(shape) == 2:\n        fan_in = shape[0]\n        fan_out = shape[1]\n    else:\n        # Assuming convolution kernels (2D, 3D, or more).\n        # kernel shape: (..., input_depth, depth)\n        receptive_field_size = 1\n        for dim in shape[:-2]:\n            receptive_field_size *= dim\n        fan_in = shape[-2] * receptive_field_size\n        fan_out = shape[-1] * receptive_field_size\n    return int(fan_in), int(fan_out)\n</code></pre>"},{"location":"reference/DeepSaki/initializers/#DeepSaki.initializers.he_alpha.HeAlpha.get_config","title":"get_config","text":"<pre><code>get_config() -&gt; Dict[str, Any]\n</code></pre> <p>Serialize object and return dictionary containing member variables.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict[str,Any]: {\"alpha\": self.alpha, \"seed\": self.seed}</p> Source code in <code>DeepSaki/initializers/he_alpha.py</code> <pre><code>def get_config(self) -&gt; Dict[str, Any]:\n    \"\"\"Serialize object and return dictionary containing member variables.\n\n    Returns:\n        Dict[str,Any]: {\"alpha\": self.alpha, \"seed\": self.seed}\n    \"\"\"\n    return {\"alpha\": self.alpha, \"seed\": self.seed}\n</code></pre>"},{"location":"reference/DeepSaki/initializers/#DeepSaki.initializers.he_alpha.HeAlphaNormal","title":"HeAlphaNormal","text":"<pre><code>HeAlphaNormal(\n    alpha: float = 0.3, seed: Optional[int] = None\n)\n</code></pre> <p>             Bases: <code>HeAlpha</code></p> <p>HeAlpha initializer drawing values from an normal distribution distribution.</p> <p>$$ W^{[l]} \\sim \\mathcal{N}\\left(\\mu = 0, \\sigma^{2}= \\frac{2}{(1+\\alpha^{2})n[l]}\\right), $$ where \\(\\mu\\) is the mean, \\(\\sigma^2\\) is the variance, \\(\\alpha\\) is a configurable variable and \\(n[l]\\) is the number of parameters in layer \\(l\\)</p> <p>Dunder method to initialize HeAlphaUniform object.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>float</code> <p>Variable to control the width of the distribution. Should be set according the alpha value of the LeakyReLU activation. Defaults to 0.3.</p> <code>0.3</code> <code>seed</code> <code>Optional[int]</code> <p>Seed for the random distribution. Defaults to None.</p> <code>None</code> Source code in <code>DeepSaki/initializers/he_alpha.py</code> <pre><code>def __init__(self, alpha: float = 0.3, seed: Optional[int] = None) -&gt; None:\n    \"\"\"Dunder method to initialize HeAlphaUniform object.\n\n    Args:\n        alpha (float, optional): Variable to control the width of the distribution. Should be set according the\n            alpha value of the LeakyReLU activation. Defaults to 0.3.\n        seed (Optional[int], optional): Seed for the random distribution. Defaults to None.\n    \"\"\"\n    super(HeAlphaNormal, self).__init__(alpha, seed)\n</code></pre>"},{"location":"reference/DeepSaki/initializers/#DeepSaki.initializers.he_alpha.HeAlphaNormal.__call__","title":"__call__","text":"<pre><code>__call__(\n    shape: List[int],\n    dtype: Optional[Union[tf.DType, np.dtype]] = None,\n) -&gt; tf.Tensor\n</code></pre> <p>Dunder method to call the object instance.</p> <p>Parameters:</p> Name Type Description Default <code>shape</code> <code>List[int]</code> <p>Shape of the tensor that shall be initialized.</p> required <code>dtype</code> <code>Optional[Union[tf.DType, np.dtype]]</code> <p>dtype to which the data should be casted to. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>tf.Tensor</code> <p>tf.Tensor: Tensor containing the weights sampled from a normal distribution for initialization.</p> Source code in <code>DeepSaki/initializers/he_alpha.py</code> <pre><code>def __call__(self, shape: List[int], dtype: Optional[Union[tf.DType, np.dtype]] = None) -&gt; tf.Tensor:\n    \"\"\"Dunder method to call the object instance.\n\n    Args:\n        shape (List[int]): Shape of the tensor that shall be initialized.\n        dtype (Optional[Union[tf.DType, np.dtype]], optional): dtype to which the data should be casted to.\n            Defaults to None.\n\n    Returns:\n        tf.Tensor: Tensor containing the weights sampled from a normal distribution for initialization.\n    \"\"\"\n    fan_in, _ = self.compute_fans(shape)\n    std = np.sqrt(2) / np.sqrt((1 + self.alpha**2) * fan_in)\n    return tf.random.truncated_normal(shape, mean=0, stddev=std, dtype=dtype, seed=self.seed)\n</code></pre>"},{"location":"reference/DeepSaki/initializers/#DeepSaki.initializers.he_alpha.HeAlphaUniform","title":"HeAlphaUniform","text":"<pre><code>HeAlphaUniform(\n    alpha: float = 0.3, seed: Optional[int] = None\n)\n</code></pre> <p>             Bases: <code>HeAlpha</code></p> <p>HeAlpha initializer drawing values from an uniform distribution.</p> <p>$$ W^{[l]} \\sim \\mathcal{U}\\left(a = -\\sqrt{\\frac{6}{n^{[l]}+n^{[l+1]}}}, b = \\sqrt{\\frac{6}{n^{[l]}+n^{[l+1]}}}\\right), $$ where \\(\\alpha\\) is a configurable variable and \\(n[l]\\) is the number of parameters in layer \\(l\\)</p> <p>Dunder method to initialize HeAlphaUniform object.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>float</code> <p>Variable to control the width of the distribution. Should be set according the alpha value of the LeakyReLU activation. Defaults to 0.3.</p> <code>0.3</code> <code>seed</code> <code>Optional[int]</code> <p>Seed for the random distribution. Defaults to None.</p> <code>None</code> Source code in <code>DeepSaki/initializers/he_alpha.py</code> <pre><code>def __init__(self, alpha: float = 0.3, seed: Optional[int] = None) -&gt; None:\n    \"\"\"Dunder method to initialize HeAlphaUniform object.\n\n    Args:\n        alpha (float, optional): Variable to control the width of the distribution. Should be set according the\n            alpha value of the LeakyReLU activation. Defaults to 0.3.\n        seed (Optional[int], optional): Seed for the random distribution. Defaults to None.\n    \"\"\"\n    super(HeAlphaUniform, self).__init__(alpha, seed)\n</code></pre>"},{"location":"reference/DeepSaki/initializers/#DeepSaki.initializers.he_alpha.HeAlphaUniform.__call__","title":"__call__","text":"<pre><code>__call__(\n    shape: List[int],\n    dtype: Optional[Union[tf.DType, np.dtype]] = None,\n) -&gt; tf.Tensor\n</code></pre> <p>Dunder method to call the object instance.</p> <p>Parameters:</p> Name Type Description Default <code>shape</code> <code>List[int]</code> <p>Shape of the tensor that shall be initialized.</p> required <code>dtype</code> <code>Optional[Union[tf.DType, np.dtype]]</code> <p>dtype to which the data should be casted to. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>tf.Tensor</code> <p>tf.Tensor: Tensor containing the weights sampled from a uniform distribution for initialization.</p> Source code in <code>DeepSaki/initializers/he_alpha.py</code> <pre><code>def __call__(self, shape: List[int], dtype: Optional[Union[tf.DType, np.dtype]] = None) -&gt; tf.Tensor:\n    \"\"\"Dunder method to call the object instance.\n\n    Args:\n        shape (List[int]): Shape of the tensor that shall be initialized.\n        dtype (Optional[Union[tf.DType, np.dtype]], optional): dtype to which the data should be casted to.\n            Defaults to None.\n\n    Returns:\n        tf.Tensor: Tensor containing the weights sampled from a uniform distribution for initialization.\n    \"\"\"\n    fan_in, _ = self.compute_fans(shape)\n    limit = np.sqrt(6 / ((1 + self.alpha**2) * fan_in))\n    return tf.random.uniform(shape, -limit, limit, dtype=dtype, seed=self.seed)\n</code></pre>"},{"location":"reference/DeepSaki/layers/","title":"layers","text":"<p>Collection of padding layer operations.</p> <p>Collection of functions to simplify the code in various layers.</p> <p>Collection of pooling layer operations to reduce the spatial dimensionality of a feature map.</p>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.padding.ReflectionPadding2D","title":"ReflectionPadding2D","text":"<pre><code>ReflectionPadding2D(\n    padding: Tuple[int, int] = (1, 1), **kwargs: Any\n)\n</code></pre> <p>             Bases: <code>tf.keras.layers.Layer</code></p> Source code in <code>DeepSaki/layers/padding.py</code> <pre><code>def __init__(self, padding: Tuple[int, int] = (1, 1), **kwargs: Any) -&gt; None:\n    super(ReflectionPadding2D, self).__init__(**kwargs)\n    self.padding = tuple(padding)\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.padding.ReflectionPadding2D.compute_output_shape","title":"compute_output_shape","text":"<pre><code>compute_output_shape(\n    input_shape: tf.TensorShape,\n) -&gt; Tuple[int, int, int, int]\n</code></pre> <p>If you are using \"channels_last\" configuration</p> Source code in <code>DeepSaki/layers/padding.py</code> <pre><code>def compute_output_shape(self, input_shape: tf.TensorShape) -&gt; Tuple[int, int, int, int]:\n    \"\"\"If you are using \"channels_last\" configuration\"\"\"\n    return (\n        input_shape[0],\n        input_shape[1] + 2 * self.padding[0],\n        input_shape[2] + 2 * self.padding[1],\n        input_shape[3],\n    )\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.padding.ReflectionPadding2D.get_config","title":"get_config","text":"<pre><code>get_config() -&gt; Dict[str, Any]\n</code></pre> <p>Serialization of the object.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with the class' variable names as keys.</p> Source code in <code>DeepSaki/layers/padding.py</code> <pre><code>def get_config(self) -&gt; Dict[str, Any]:\n    \"\"\"Serialization of the object.\n\n    Returns:\n        Dictionary with the class' variable names as keys.\n    \"\"\"\n    config = super(ReflectionPadding2D, self).get_config()\n    config.update({\"padding\": self.padding})\n    return config\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_composites.Conv2DBlock","title":"Conv2DBlock","text":"<pre><code>Conv2DBlock(\n    filters: int,\n    kernels: int,\n    use_residual_Conv2DBlock: bool = False,\n    split_kernels: bool = False,\n    number_of_convs: int = 1,\n    activation: str = \"leaky_relu\",\n    dropout_rate: float = 0.0,\n    final_activation: bool = True,\n    use_spec_norm: bool = False,\n    strides: Tuple[int, int] = (1, 1),\n    padding: PaddingType = PaddingType.ZERO,\n    apply_final_normalization: bool = True,\n    use_bias: bool = True,\n    kernel_initializer: tf.keras.initializers.Initializer = HeAlphaUniform(),\n    gamma_initializer: tf.keras.initializers.Initializer = HeAlphaUniform(),\n)\n</code></pre> <p>             Bases: <code>tf.keras.layers.Layer</code></p> <p>Wraps a two-dimensional convolution into a more complex building block args:   - filters: number of filters in the output feature map   - kernels: size of the convolutions kernels   - use_residual_Conv2DBlock (optional, default: False):   - split_kernels (optional, default: False): to decrease the number of parameters, a convolution with the kernel_size (kernel,kernel) can be splitted into two consecutive convolutions with the kernel_size (kernel,1) and (1,kernel) respectivly   - number_of_convs (optional, default: 1): number of consecutive convolutional building blocks, i.e. Conv2DBlock.   - activation (optional, default: \"leaky_relu\"): string literal to obtain activation function   - dropout_rate (optional, default: 0): probability of the dropout layer. If the preceeding layer has more than one channel, spatial dropout is applied, otherwise standard dropout   - final_activation (optional, default: True): whether or not to activate the output of this layer   - use_spec_norm (optional, default: False): applies spectral normalization to convolutional and dense layers   - strides (optional, default: (1,1)): stride of the filter   - padding (optional, default: \"zero\"): padding type. Options are \"none\", \"zero\" or \"reflection\"   - apply_final_normalization (optional, default: True): Whether or not to place a normalization on the layer's output   - use_bias (optional, default: True): determines whether convolutions and dense layers include a bias or not   - kernel_initializer (optional, default: HeAlphaUniform()): Initialization of the convolutions kernels.   - gamma_initializer (optional, default: HeAlphaUniform()): Initialization of the normalization layers.</p> Source code in <code>DeepSaki/layers/layer_composites.py</code> <pre><code>def __init__(\n    self,\n    filters: int,\n    kernels: int,\n    use_residual_Conv2DBlock: bool = False,\n    split_kernels: bool = False,\n    number_of_convs: int = 1,\n    activation: str = \"leaky_relu\",\n    dropout_rate: float = 0.0,\n    final_activation: bool = True,\n    use_spec_norm: bool = False,\n    strides: Tuple[int, int] = (1, 1),\n    padding: PaddingType = PaddingType.ZERO,\n    apply_final_normalization: bool = True,\n    use_bias: bool = True,\n    kernel_initializer: tf.keras.initializers.Initializer = HeAlphaUniform(),\n    gamma_initializer: tf.keras.initializers.Initializer = HeAlphaUniform(),\n):\n    super(Conv2DBlock, self).__init__()\n    self.filters = filters\n    self.use_residual_Conv2DBlock = use_residual_Conv2DBlock\n    self.kernels = kernels\n    self.split_kernels = split_kernels\n    self.number_of_convs = number_of_convs\n    self.activation = activation\n    self.dropout_rate = dropout_rate\n    self.final_activation = final_activation\n    self.use_spec_norm = use_spec_norm\n    self.strides = strides\n    self.padding = padding\n    self.apply_final_normalization = apply_final_normalization\n    self.use_bias = use_bias\n    self.kernel_initializer = kernel_initializer\n    self.gamma_initializer = gamma_initializer\n\n    self.pad = int((kernels - 1) / 2)  # assumes odd kernel size, which is typical!\n\n    if split_kernels:\n        self.convs = [\n            Conv2DSplitted(\n                filters=filters, kernels=kernels, use_bias=use_bias, strides=strides, use_spec_norm=use_spec_norm\n            )\n            for _ in range(number_of_convs)\n        ]\n    else:\n        if use_spec_norm:\n            self.convs = [\n                tfa.layers.SpectralNormalization(\n                    tf.keras.layers.Conv2D(\n                        filters=filters,\n                        kernel_size=(kernels, kernels),\n                        kernel_initializer=kernel_initializer,\n                        use_bias=use_bias,\n                        strides=strides,\n                    )\n                )\n                for _ in range(number_of_convs)\n            ]\n        else:\n            self.convs = [\n                tf.keras.layers.Conv2D(\n                    filters=filters,\n                    kernel_size=(kernels, kernels),\n                    kernel_initializer=kernel_initializer,\n                    use_bias=use_bias,\n                    strides=strides,\n                )\n                for _ in range(number_of_convs)\n            ]\n\n    if apply_final_normalization:\n        num_instancenorm_blocks = number_of_convs\n    else:\n        num_instancenorm_blocks = number_of_convs - 1\n    self.IN_blocks = [\n        tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)\n        for _ in range(num_instancenorm_blocks)\n    ]\n    self.dropout = dropout_func(filters, dropout_rate)\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_composites.Conv2DSplitted","title":"Conv2DSplitted","text":"<pre><code>Conv2DSplitted(\n    filters: int,\n    kernels: int,\n    use_spec_norm: bool = False,\n    strides: Tuple[int, int] = (1, 1),\n    use_bias: bool = True,\n    kernel_initializer: tf.keras.initializers.Initializer = HeAlphaUniform(),\n)\n</code></pre> <p>             Bases: <code>tf.keras.layers.Layer</code></p> <p>To decrease the number of parameters, a convolution with the kernel_size (kernel,kernel) can be splitted into two consecutive convolutions with the kernel_size (kernel,1) and (1,kernel) respectivly args:   - filters: number of filters in the output feature map   - kernels: size of the convolutions kernels, which will be translated to (kernels, 1) &amp; (1,kernels) for the first and seccond convolution respectivly   - use_spec_norm (optional, default: False): applies spectral normalization to convolutional  layers   - strides (optional, default: (1,1)): stride of the filter   - use_bias (optional, default: True): determines whether convolutions layers include a bias or not   - kernel_initializer (optional, default: HeAlphaUniform()): Initialization of the convolutions kernels.</p> Source code in <code>DeepSaki/layers/layer_composites.py</code> <pre><code>def __init__(\n    self,\n    filters: int,\n    kernels: int,\n    use_spec_norm: bool = False,\n    strides: Tuple[int, int] = (1, 1),\n    use_bias: bool = True,\n    kernel_initializer: tf.keras.initializers.Initializer = HeAlphaUniform(),\n) -&gt; None:\n    super(Conv2DSplitted, self).__init__()\n    self.filters = filters\n    self.kernels = kernels\n    self.use_spec_norm = use_spec_norm\n    self.strides = strides\n    self.use_bias = use_bias\n    self.kernel_initializer = kernel_initializer\n\n    self.conv1 = tf.keras.layers.Conv2D(\n        filters=filters,\n        kernel_size=(1, kernels),\n        kernel_initializer=kernel_initializer,\n        use_bias=use_bias,\n        strides=strides,\n    )\n    self.conv2 = tf.keras.layers.Conv2D(\n        filters=filters,\n        kernel_size=(kernels, 1),\n        kernel_initializer=kernel_initializer,\n        use_bias=use_bias,\n        strides=strides,\n    )\n\n    if use_spec_norm:\n        self.conv1 = tfa.layers.SpectralNormalization(self.conv1)\n        self.conv2 = tfa.layers.SpectralNormalization(self.conv2)\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_composites.DenseBlock","title":"DenseBlock","text":"<pre><code>DenseBlock(\n    units: int,\n    numberOfLayers: int = 1,\n    activation: str = \"leaky_relu\",\n    dropout_rate: float = 0.0,\n    final_activation: bool = True,\n    use_spec_norm: bool = False,\n    apply_final_normalization: bool = True,\n    use_bias: bool = True,\n    kernel_initializer: tf.keras.initializers.Initializer = HeAlphaUniform(),\n    gamma_initializer: tf.keras.initializers.Initializer = HeAlphaUniform(),\n)\n</code></pre> <p>             Bases: <code>tf.keras.layers.Layer</code></p> <p>Wraps a dense layer into a more complex building block args:   - units: number of units of each dense block   - numberOfLayers (optional, default: 1): number of consecutive convolutional building blocks, i.e. Conv2DBlock.   - activation (optional, default: \"leaky_relu\"): string literal to obtain activation function   - dropout_rate (optional, default: 0): probability of the dropout layer. If the preceeding layer has more than one channel, spatial dropout is applied, otherwise standard dropout   - final_activation (optional, default: True): whether or not to activate the output of this layer   - use_spec_norm (optional, default: False): applies spectral normalization to convolutional and dense layers   - apply_final_normalization (optional, default: True): Whether or not to place a normalization on the layer's output   - use_bias (optional, default: True): determines whether convolutions and dense layers include a bias or not   - kernel_initializer (optional, default: HeAlphaUniform()): Initialization of the convolutions kernels.   - gamma_initializer (optional, default: HeAlphaUniform()): Initialization of the normalization layers.</p> Source code in <code>DeepSaki/layers/layer_composites.py</code> <pre><code>def __init__(\n    self,\n    units: int,\n    numberOfLayers: int = 1,\n    activation: str = \"leaky_relu\",\n    dropout_rate: float = 0.0,\n    final_activation: bool = True,\n    use_spec_norm: bool = False,\n    apply_final_normalization: bool = True,\n    use_bias: bool = True,\n    kernel_initializer: tf.keras.initializers.Initializer = HeAlphaUniform(),\n    gamma_initializer: tf.keras.initializers.Initializer = HeAlphaUniform(),\n) -&gt; None:\n    super(DenseBlock, self).__init__()\n    self.units = units\n    self.numberOfLayers = numberOfLayers\n    self.dropout_rate = dropout_rate\n    self.activation = activation\n    self.final_activation = final_activation\n    self.use_spec_norm = use_spec_norm\n    self.apply_final_normalization = apply_final_normalization\n    self.use_bias = use_bias\n    self.kernel_initializer = kernel_initializer\n    self.gamma_initializer = gamma_initializer\n\n    if use_spec_norm:\n        self.DenseBlocks = [\n            tfa.layers.SpectralNormalization(\n                tf.keras.layers.Dense(units=units, use_bias=use_bias, kernel_initializer=kernel_initializer)\n            )\n            for _ in range(numberOfLayers)\n        ]\n    else:\n        self.DenseBlocks = [\n            tf.keras.layers.Dense(units=units, use_bias=use_bias, kernel_initializer=kernel_initializer)\n            for _ in range(numberOfLayers)\n        ]\n\n    if apply_final_normalization:\n        num_instancenorm_blocks = numberOfLayers\n    else:\n        num_instancenorm_blocks = numberOfLayers - 1\n    self.IN_blocks = [\n        tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)\n        for _ in range(num_instancenorm_blocks)\n    ]\n    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_composites.DownSampleBlock","title":"DownSampleBlock","text":"<pre><code>DownSampleBlock(\n    downsampling: str = \"average_pooling\",\n    activation: str = \"leaky_relu\",\n    kernels: int = 3,\n    use_spec_norm: bool = False,\n    padding: PaddingType = PaddingType.ZERO,\n    use_bias: bool = True,\n    kernel_initializer: tf.keras.initializers.Initializer = HeAlphaUniform(),\n    gamma_initializer: tf.keras.initializers.Initializer = HeAlphaUniform(),\n)\n</code></pre> <p>             Bases: <code>tf.keras.layers.Layer</code></p> <p>Spatial down-sampling for grid-like data args:   - downsampling (optional, default: \"average_pooling\"):   - activation (optional, default: \"leaky_relu\"): string literal to obtain activation function   - kernels (optional, default: 3): size of the convolution's kernels when using downsampling = \"conv_stride_2\"   - use_spec_norm (optional, default: False): applies spectral normalization to convolutional and dense layers   - padding (optional, default: \"zero\"): padding type. Options are \"none\", \"zero\" or \"reflection\"   - use_bias (optional, default: True): determines whether convolutions and dense layers include a bias or not   - kernel_initializer (optional, default: HeAlphaUniform()): Initialization of the convolutions kernels.   - gamma_initializer (optional, default: HeAlphaUniform()): Initialization of the normalization layers.</p> Source code in <code>DeepSaki/layers/layer_composites.py</code> <pre><code>def __init__(\n    self,\n    downsampling: str = \"average_pooling\",\n    activation: str = \"leaky_relu\",\n    kernels: int = 3,\n    use_spec_norm: bool = False,\n    padding: PaddingType = PaddingType.ZERO,\n    use_bias: bool = True,\n    kernel_initializer: tf.keras.initializers.Initializer = HeAlphaUniform(),\n    gamma_initializer: tf.keras.initializers.Initializer = HeAlphaUniform(),\n) -&gt; None:\n    super(DownSampleBlock, self).__init__()\n    self.kernels = kernels\n    self.downsampling = downsampling\n    self.activation = activation\n    self.use_spec_norm = use_spec_norm\n    self.padding = padding\n    self.use_bias = use_bias\n    self.kernel_initializer = kernel_initializer\n    self.gamma_initializer = gamma_initializer\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_composites.ResBlockDown","title":"ResBlockDown","text":"<pre><code>ResBlockDown(\n    activation: str = \"leaky_relu\",\n    use_spec_norm: bool = False,\n    use_bias: bool = True,\n    padding: PaddingType = PaddingType.ZERO,\n    kernel_initializer: tf.keras.initializers.Initializer = HeAlphaUniform(),\n    gamma_initializer: tf.keras.initializers.Initializer = HeAlphaUniform(),\n)\n</code></pre> <p>             Bases: <code>tf.keras.layers.Layer</code></p> <p>Spatial down-sampling with residual connection for grid-like data args:   - activation (optional, default: \"leaky_relu\"): string literal to obtain activation function   - use_spec_norm (optional, default: False): applies spectral normalization to convolutional and dense layers   - use_bias (optional, default: True): determines whether convolutions and dense layers include a bias or not   - padding (optional, default: \"zero\"): padding type. Options are \"none\", \"zero\" or \"reflection\"   - kernel_initializer (optional, default: HeAlphaUniform()): Initialization of the convolutions kernels.   - gamma_initializer (optional, default: HeAlphaUniform()): Initialization of the normalization layers.</p> Source code in <code>DeepSaki/layers/layer_composites.py</code> <pre><code>def __init__(\n    self,\n    activation: str = \"leaky_relu\",\n    use_spec_norm: bool = False,\n    use_bias: bool = True,\n    padding: PaddingType = PaddingType.ZERO,\n    kernel_initializer: tf.keras.initializers.Initializer = HeAlphaUniform(),\n    gamma_initializer: tf.keras.initializers.Initializer = HeAlphaUniform(),\n) -&gt; None:\n    super(ResBlockDown, self).__init__()\n    self.activation = activation\n    self.use_spec_norm = use_spec_norm\n    self.use_bias = use_bias\n    self.padding = padding\n    self.kernel_initializer = kernel_initializer\n    self.gamma_initializer = gamma_initializer\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_composites.ResBlockUp","title":"ResBlockUp","text":"<pre><code>ResBlockUp(\n    activation: str = \"leaky_relu\",\n    use_spec_norm: bool = False,\n    use_bias: bool = True,\n    padding: PaddingType = PaddingType.ZERO,\n    kernel_initializer: tf.keras.initializers.Initializer = HeAlphaUniform(),\n    gamma_initializer: tf.keras.initializers.Initializer = HeAlphaUniform(),\n)\n</code></pre> <p>             Bases: <code>tf.keras.layers.Layer</code></p> <p>Spatial down-sampling with residual connection for grid-like data args:   - activation (optional, default: \"leaky_relu\"): string literal to obtain activation function   - use_spec_norm (optional, default: False): applies spectral normalization to convolutional and dense layers   - padding (optional, default: \"zero\"): padding type. Options are \"none\", \"zero\" or \"reflection\"   - use_bias (optional, default: True): determines whether convolutions and dense layers include a bias or not   - kernel_initializer (optional, default: HeAlphaUniform()): Initialization of the convolutions kernels.   - gamma_initializer (optional, default: HeAlphaUniform()): Initialization of the normalization layers.</p> Source code in <code>DeepSaki/layers/layer_composites.py</code> <pre><code>def __init__(\n    self,\n    activation: str = \"leaky_relu\",\n    use_spec_norm: bool = False,\n    use_bias: bool = True,\n    padding: PaddingType = PaddingType.ZERO,\n    kernel_initializer: tf.keras.initializers.Initializer = HeAlphaUniform(),\n    gamma_initializer: tf.keras.initializers.Initializer = HeAlphaUniform(),\n) -&gt; None:\n    super(ResBlockUp, self).__init__()\n    self.activation = activation\n    self.use_spec_norm = use_spec_norm\n    self.use_bias = use_bias\n    self.padding = padding\n    self.kernel_initializer = kernel_initializer\n    self.gamma_initializer = gamma_initializer\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_composites.ResidualIdentityBlock","title":"ResidualIdentityBlock","text":"<pre><code>ResidualIdentityBlock(\n    filters: int,\n    kernels: int,\n    activation: str = \"leaky_relu\",\n    numberOfBlocks: int = 1,\n    use_spec_norm: bool = False,\n    residual_cardinality: int = 1,\n    dropout_rate: float = 0.0,\n    use_bias: bool = True,\n    padding: PaddingType = PaddingType.ZERO,\n    kernel_initializer: tf.keras.initializers.Initializer = HeAlphaUniform(),\n    gamma_initializer: tf.keras.initializers.Initializer = HeAlphaUniform(),\n)\n</code></pre> <p>             Bases: <code>tf.keras.layers.Layer</code></p> <p>Residual identity block with configurable cardinality args:   - filters: number of filters in the output feature map   - kernels: size of the convolutions kernels   - numberOfBlocks (optional, default: 1): number of consecutive convolutional building blocks.   - activation (optional, default: \"leaky_relu\"): string literal to obtain activation function   - dropout_rate (optional, default: 0): probability of the dropout layer. If the preceeding layer has more than one channel, spatial dropout is applied, otherwise standard dropout   - use_spec_norm (optional, default: False): applies spectral normalization to convolutional and dense layers   - residual_cardinality (optional, default: 1): number of parallel convolution blocks   - padding (optional, default: \"zero\"): padding type. Options are \"none\", \"zero\" or \"reflection\"   - use_bias (optional, default: True): determines whether convolutions and dense layers include a bias or not   - kernel_initializer (optional, default: HeAlphaUniform()): Initialization of the convolutions kernels.   - gamma_initializer (optional, default: HeAlphaUniform()): Initialization of the normalization layers.</p> Source code in <code>DeepSaki/layers/layer_composites.py</code> <pre><code>def __init__(\n    self,\n    filters: int,\n    kernels: int,\n    activation: str = \"leaky_relu\",\n    numberOfBlocks: int = 1,\n    use_spec_norm: bool = False,\n    residual_cardinality: int = 1,\n    dropout_rate: float = 0.0,\n    use_bias: bool = True,\n    padding: PaddingType = PaddingType.ZERO,\n    kernel_initializer: tf.keras.initializers.Initializer = HeAlphaUniform(),\n    gamma_initializer: tf.keras.initializers.Initializer = HeAlphaUniform(),\n) -&gt; None:\n    super(ResidualIdentityBlock, self).__init__()\n    self.activation = activation\n    self.filters = filters\n    self.kernels = kernels\n    self.numberOfBlocks = numberOfBlocks\n    self.use_spec_norm = use_spec_norm\n    self.residual_cardinality = residual_cardinality\n    self.dropout_rate = dropout_rate\n    self.use_bias = use_bias\n    self.padding = padding\n    self.kernel_initializer = kernel_initializer\n    self.gamma_initializer = gamma_initializer\n\n    self.pad = int((kernels - 1) / 2)  # assumes odd kernel size, which is typical!\n\n    if residual_cardinality &gt; 1:\n        self.intermediateFilters = int(max(filters / 32, filters / 16, filters / 8, filters / 4, filters / 2, 1))\n    else:\n        self.intermediateFilters = int(max(filters / 4, filters / 2, 1))\n\n    # for each block, add several con\n    self.blocks = []\n    for i in range(numberOfBlocks):\n        cardinals = []\n        for _ in range(residual_cardinality):\n            cardinals.append(\n                [\n                    Conv2DBlock(\n                        filters=self.intermediateFilters,\n                        use_residual_Conv2DBlock=False,\n                        kernels=1,\n                        split_kernels=False,\n                        number_of_convs=1,\n                        activation=activation,\n                        use_spec_norm=use_spec_norm,\n                        use_bias=use_bias,\n                        padding=padding,\n                        kernel_initializer=kernel_initializer,\n                        gamma_initializer=gamma_initializer,\n                    ),\n                    Conv2DBlock(\n                        filters=self.intermediateFilters,\n                        use_residual_Conv2DBlock=False,\n                        kernels=kernels,\n                        split_kernels=False,\n                        number_of_convs=1,\n                        activation=activation,\n                        padding=PaddingType.NONE,\n                        use_spec_norm=use_spec_norm,\n                        use_bias=use_bias,\n                        kernel_initializer=kernel_initializer,\n                        gamma_initializer=gamma_initializer,\n                    ),\n                    Conv2DBlock(\n                        filters=filters,\n                        use_residual_Conv2DBlock=False,\n                        kernels=1,\n                        split_kernels=False,\n                        number_of_convs=1,\n                        activation=activation,\n                        use_spec_norm=use_spec_norm,\n                        use_bias=use_bias,\n                        padding=padding,\n                        kernel_initializer=kernel_initializer,\n                        gamma_initializer=gamma_initializer,\n                    ),\n                ]\n            )\n        self.blocks.append(cardinals)\n\n    self.dropout = dropout_func(filters, dropout_rate)\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_composites.ScalarGatedSelfAttention","title":"ScalarGatedSelfAttention","text":"<pre><code>ScalarGatedSelfAttention(\n    use_spec_norm: bool = False,\n    intermediate_channel: Optional[bool] = None,\n    kernel_initializer: tf.keras.initializers.Initializer = HeAlphaUniform(),\n    gamma_initializer: tf.keras.initializers.Initializer = HeAlphaUniform(),\n)\n</code></pre> <p>             Bases: <code>tf.keras.layers.Layer</code></p> <p>Scaled dot-product self attention that is gated by a learnable scalar. args: - use_spec_norm (optional, default: False): applies spectral normalization to convolutional and dense layers - intermediateChannel (optional, default: None): Integer that determines the intermediate channels within the self-attention model. If None, intermediate channels = inputChannels/8 - kernel_initializer (optional, default: HeAlphaUniform()): Initialization of the convolutions kernels. - gamma_initializer (optional, default: HeAlphaUniform()): Initialization of the normalization layers.</p> Source code in <code>DeepSaki/layers/layer_composites.py</code> <pre><code>def __init__(\n    self,\n    use_spec_norm: bool = False,\n    intermediate_channel: Optional[bool] = None,\n    kernel_initializer: tf.keras.initializers.Initializer = HeAlphaUniform(),\n    gamma_initializer: tf.keras.initializers.Initializer = HeAlphaUniform(),\n) -&gt; None:\n    super(ScalarGatedSelfAttention, self).__init__()\n    self.use_spec_norm = use_spec_norm\n    self.intermediateChannel = intermediate_channel\n    self.kernel_initializer = kernel_initializer\n    self.gamma_initializer = gamma_initializer\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_composites.ScaleLayer","title":"ScaleLayer","text":"<pre><code>ScaleLayer(\n    initializer: tf.keras.initializers.Initializer = tf.keras.initializers.Ones(),\n)\n</code></pre> <p>             Bases: <code>tf.keras.layers.Layer</code></p> <p>trainable scalar that can act as trainable gate args:   - initializer (optional, default: tf.keras.initializers.Ones()): initializes the scalar weight</p> Source code in <code>DeepSaki/layers/layer_composites.py</code> <pre><code>def __init__(self, initializer: tf.keras.initializers.Initializer = tf.keras.initializers.Ones()) -&gt; None:\n    super(ScaleLayer, self).__init__()\n    self.initializer = initializer\n    self.scale = self.add_weight(shape=[1], initializer=initializer, constraint=NonNegative(), trainable=True)\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_composites.UpSampleBlock","title":"UpSampleBlock","text":"<pre><code>UpSampleBlock(\n    upsampling: str = \"2D_upsample_and_conv\",\n    activation: str = \"leaky_relu\",\n    kernels: int = 3,\n    split_kernels: bool = False,\n    use_spec_norm: bool = False,\n    use_bias: bool = True,\n    padding: PaddingType = PaddingType.ZERO,\n    kernel_initializer: tf.keras.initializers.Initializer = HeAlphaUniform(),\n    gamma_initializer: tf.keras.initializers.Initializer = HeAlphaUniform(),\n)\n</code></pre> <p>             Bases: <code>tf.keras.layers.Layer</code></p> <p>Spatial up-sampling for grid-like data args:   - upsampling (optional, default: \"2D_upsample_and_conv\"):   - activation (optional, default: \"leaky_relu\"): string literal to obtain activation function   - kernels (optional, default: 3): size of the convolution's kernels when using upsampling = \"2D_upsample_and_conv\" or \"transpose_conv\"   - split_kernels (optional, default: False): to decrease the number of parameters, a convolution with the kernel_size (kernel,kernel) can be splitted into two consecutive convolutions with the kernel_size (kernel,1) and (1,kernel) respectivly. applies to upsampling = \"2D_upsample_and_conv\"   - use_spec_norm (optional, default: False): applies spectral normalization to convolutional and dense layers   - padding (optional, default: \"zero\"): padding type. Options are \"none\", \"zero\" or \"reflection\"   - use_bias (optional, default: True): determines whether convolutions and dense layers include a bias or not   - kernel_initializer (optional, default: HeAlphaUniform()): Initialization of the convolutions kernels.   - gamma_initializer (optional, default: HeAlphaUniform()): Initialization of the normalization layers.</p> Source code in <code>DeepSaki/layers/layer_composites.py</code> <pre><code>def __init__(\n    self,\n    upsampling: str = \"2D_upsample_and_conv\",\n    activation: str = \"leaky_relu\",\n    kernels: int = 3,\n    split_kernels: bool = False,\n    use_spec_norm: bool = False,\n    use_bias: bool = True,\n    padding: PaddingType = PaddingType.ZERO,\n    kernel_initializer: tf.keras.initializers.Initializer = HeAlphaUniform(),\n    gamma_initializer: tf.keras.initializers.Initializer = HeAlphaUniform(),\n) -&gt; None:\n    super(UpSampleBlock, self).__init__()\n    self.kernels = kernels\n    self.split_kernels = split_kernels\n    self.activation = activation\n    self.use_spec_norm = use_spec_norm\n    self.upsampling = upsampling\n    self.use_bias = use_bias\n    self.kernel_initializer = kernel_initializer\n    self.gamma_initializer = gamma_initializer\n    self.padding = padding\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_helper.InitializerFunc","title":"InitializerFunc","text":"<p>             Bases: <code>Enum</code></p> <p><code>Enum</code> used to define different types of initializer functions.</p> <p>Attributes:</p> Name Type Description <code>RANDOM_NORMAL</code> <code>int</code> <p>Corresponds to a random normal initializer function.</p> <code>RANDOM_UNIFORM</code> <code>int</code> <p>Corresponds to a random uniform initializer function.</p> <code>GLOROT_NORMAL</code> <code>int</code> <p>Corresponds to a Glorot normal initializer function.</p> <code>GLOROT_UNIFORM</code> <code>int</code> <p>Corresponds to a Glorot uniform initializer function.</p> <code>HE_NORMAL</code> <code>int</code> <p>Corresponds to a He normal initializer function.</p> <code>HE_UNIFORM</code> <code>int</code> <p>Corresponds to a He uniform initializer function.</p> <code>HE_ALPHA_NORMAL</code> <code>int</code> <p>Corresponds to a He Alpha normal initializer function.</p> <code>HE_ALPHA_UNIFORM</code> <code>int</code> <p>Corresponds to a He Alpha Uniform initializer function.</p>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_helper.PaddingType","title":"PaddingType","text":"<p>             Bases: <code>Enum</code></p> <p><code>Enum</code> used to define different types of padding opperations.</p> <p>Attributes:</p> Name Type Description <code>ZERO</code> <code>int</code> <p>Indicates to apply a zero padding operations.</p> <code>REFLECTION</code> <code>int</code> <p>Indicates to apply a reflection padding operation.</p>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_helper.dropout_func","title":"dropout_func","text":"<pre><code>dropout_func(\n    filters: int, dropout_rate: float\n) -&gt; tf.keras.layers.Layer\n</code></pre> <p>Wrapper to obtain a dropout layer depending on the size of the preceeding feature map args:   - filters: number of filters of previous layer   - dropout_rate: probability with which dropout is performed</p> Source code in <code>DeepSaki/layers/layer_helper.py</code> <pre><code>def dropout_func(filters: int, dropout_rate: float) -&gt; tf.keras.layers.Layer:\n    \"\"\"\n    Wrapper to obtain a dropout layer depending on the size of the preceeding feature map\n    args:\n      - filters: number of filters of previous layer\n      - dropout_rate: probability with which dropout is performed\n    \"\"\"\n    if filters &gt; 1:\n        return tf.keras.layers.SpatialDropout2D(dropout_rate)\n    return tf.keras.layers.Dropout(dropout_rate)\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_helper.get_initializer","title":"get_initializer","text":"<pre><code>get_initializer(\n    initializer: InitializerFunc, seed: Optional[int] = None\n) -&gt; tf.keras.initializers.Initializer\n</code></pre> <p>Wrapper to return a certain initializer given a descriptive string.</p> <p>Parameters:</p> Name Type Description Default <code>initializer</code> <code>InitializerFunc</code> <p>Enum description of the initializer.</p> required <code>seed</code> <code>Optional[int]</code> <p>Seed to make the behavior of the initializer deterministic. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>tf.keras.initializers.Initializer</code> <p>Instance of an initializer object.</p> Source code in <code>DeepSaki/layers/layer_helper.py</code> <pre><code>def get_initializer(initializer: InitializerFunc, seed: Optional[int] = None) -&gt; tf.keras.initializers.Initializer:\n    \"\"\"Wrapper to return a certain initializer given a descriptive string.\n\n    Args:\n        initializer (InitializerFunc): Enum description of the initializer.\n        seed (Optional[int], optional): Seed to make the behavior of the initializer deterministic. Defaults to None.\n\n    Returns:\n        Instance of an initializer object.\n    \"\"\"\n    valid_options = {\n        InitializerFunc.RANDOM_NORMAL: tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02, seed=seed),\n        InitializerFunc.RANDOM_UNIFORM: tf.keras.initializers.RandomUniform(minval=-0.002, maxval=0.02, seed=seed),\n        InitializerFunc.GLOROT_NORMAL: tf.keras.initializers.GlorotNormal(seed=seed),\n        InitializerFunc.GLOROT_UNIFORM: tf.keras.initializers.GlorotUniform(seed=seed),\n        InitializerFunc.HE_NORMAL: tf.keras.initializers.HeNormal(seed=seed),\n        InitializerFunc.HE_UNIFORM: tf.keras.initializers.HeUniform(seed=seed),\n        InitializerFunc.HE_ALPHA_NORMAL: HeAlphaNormal(seed=seed),\n        InitializerFunc.HE_ALPHA_UNIFORM: HeAlphaUniform(seed=seed),\n    }\n\n    assert initializer in valid_options, f\"Undefined initializer provided: {initializer}\"\n\n    return valid_options.get(initializer)\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_helper.pad_func","title":"pad_func","text":"<pre><code>pad_func(\n    pad_values: Tuple[int, int] = (1, 1),\n    padding_type: PaddingType = PaddingType.ZERO,\n) -&gt; tf.keras.layers.Layer\n</code></pre> <p>Wrapper to obtain a padding layer instance.</p> <p>Parameters:</p> Name Type Description Default <code>pad_values</code> <code>Tuple[int, int]</code> <p>Size of the padding values. Defaults to (1, 1).</p> <code>(1, 1)</code> <code>padding_type</code> <code>PaddingType</code> <p>[description]. Defaults to PaddingType.ZERO.</p> <code>PaddingType.ZERO</code> <p>Returns:</p> Type Description <code>tf.keras.layers.Layer</code> <p>Instance of a padding layer object.</p> Source code in <code>DeepSaki/layers/layer_helper.py</code> <pre><code>def pad_func(\n    pad_values: Tuple[int, int] = (1, 1), padding_type: PaddingType = PaddingType.ZERO\n) -&gt; tf.keras.layers.Layer:\n    \"\"\"Wrapper to obtain a padding layer instance.\n\n    Args:\n        pad_values (Tuple[int,int], optional): Size of the padding values. Defaults to (1, 1).\n        padding_type (PaddingType, optional): [_description_]. Defaults to PaddingType.ZERO.\n\n    Returns:\n        Instance of a padding layer object.\n    \"\"\"\n    valid_options = {\n        PaddingType.REFLECTION: ReflectionPadding2D(pad_values),\n        PaddingType.ZERO: tf.keras.layers.ZeroPadding2D(pad_values),\n    }\n    assert (\n        padding_type in valid_options\n    ), f\"Undefined padding type provided: '{padding_type}'. Valid options are: '{valid_options.keys()}'\"\n    return valid_options.get(padding_type)\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_helper.plot_layer","title":"plot_layer","text":"<pre><code>plot_layer(\n    layer: tf.keras.layers.Layer, input_shape: List[int]\n) -&gt; None\n</code></pre> <p>Creates an model from a given layer to be able to call model.summary() and to plot a graphic args:   layer: tf.keras.layer object to be ploted   input_shape: shape of the input data without batchsize -&gt; (height, width, channel)</p> Source code in <code>DeepSaki/layers/layer_helper.py</code> <pre><code>def plot_layer(layer: tf.keras.layers.Layer, input_shape: List[int]) -&gt; None:\n    \"\"\"\n    Creates an model from a given layer to be able to call model.summary() and to plot a graphic\n    args:\n      layer: tf.keras.layer object to be ploted\n      input_shape: shape of the input data without batchsize -&gt; (height, width, channel)\n    \"\"\"\n    layer.build([None, *input_shape])\n    inputs = tf.keras.layers.Input(shape=input_shape)\n    model = tf.keras.Model(inputs=inputs, outputs=layer.call(inputs))\n    model.summary()\n    tf.keras.utils.plot_model(model, show_shapes=True, expand_nested=True, to_file=layer.name + \".png\")\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.pooling.FourierPooling2D","title":"FourierPooling2D","text":"<pre><code>FourierPooling2D(\n    is_channel_first: bool = False, **kwargs: Any\n)\n</code></pre> <p>             Bases: <code>tf.keras.layers.Layer</code></p> <p>Pooling in frequency domain by truncating high frequencies using a center crop operation.</p> <p>Layer input is asumed to be in frequency domain and shifted, such that the center frequency is in the center of the grid.</p> <p>If this is the case, the center represents the frequency of 0Hz (hence an offset). The further away from the center the higher the frequency component. Center cropping removes high frequency components, hence can be seen as a low pass filter</p> <p>Initializes an instance of <code>FourierPooling2D</code>.</p> <p>Parameters:</p> Name Type Description Default <code>is_channel_first</code> <code>bool</code> <p>If True, input shape is assumed to be (<code>batch</code>,<code>channel</code>,<code>height</code>,<code>width</code>). If False, input shape is assumed to be (<code>batch</code>,<code>height</code>,<code>width</code>,<code>channel</code>). Defaults to False.</p> <code>False</code> <code>kwargs</code> <code>Any</code> <p>Additional key word arguments passed to the base class.</p> <code>{}</code> Source code in <code>DeepSaki/layers/pooling.py</code> <pre><code>def __init__(self, is_channel_first: bool = False, **kwargs: Any) -&gt; None:\n    \"\"\"Initializes an instance of `FourierPooling2D`.\n\n    Args:\n        is_channel_first (bool, optional): If True, input shape is assumed to be (`batch`,`channel`,`height`,`width`).\n            If False, input shape is assumed to be (`batch`,`height`,`width`,`channel`). Defaults to False.\n        kwargs (Any): Additional key word arguments passed to the base class.\n    \"\"\"\n    super(FourierPooling2D, self).__init__(**kwargs)\n    self.is_channel_first = is_channel_first\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.pooling.FourierPooling2D.call","title":"call","text":"<pre><code>call(inputs: tf.Tensor) -&gt; tf.Tensor\n</code></pre> <p>Calls the <code>FourierPooling2D</code> layer.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>tf.Tensor</code> <p>Tensor of shape (<code>batch</code>,<code>height</code>,<code>width</code>,<code>channel</code>) or (<code>batch</code>,<code>channel</code>,<code>height</code>,<code>width</code>). Tensor is asumed to be in frequency domain of type <code>tf.complex64</code></p> required <p>Returns:</p> Type Description <code>tf.Tensor</code> <p>Pooled tensor of shape (<code>batch</code>,<code>channel</code>,<code>height/2</code>,<code>width/2</code>) or (<code>batch</code>,<code>height/2</code>,<code>width/2</code>,<code>channel</code>)</p> Source code in <code>DeepSaki/layers/pooling.py</code> <pre><code>def call(self, inputs: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"Calls the `FourierPooling2D` layer.\n\n    Args:\n        inputs (tf.Tensor): Tensor of shape (`batch`,`height`,`width`,`channel`) or\n            (`batch`,`channel`,`height`,`width`). Tensor is asumed to be in frequency domain of type `tf.complex64`\n        or `tf.complex128`.\n\n    Returns:\n        Pooled tensor of shape (`batch`,`channel`,`height/2`,`width/2`) or (`batch`,`height/2`,`width/2`,`channel`)\n    \"\"\"\n    if self.is_channel_first:\n        inputs = tf.einsum(\"bchw-&gt;bhwc\", inputs)\n\n    outputs = tf.image.central_crop(inputs, 0.5)  # assumes channel last\n\n    # reverse to previous channel config!\n    if self.is_channel_first:\n        outputs = tf.einsum(\"bhwc-&gt;bchw\", outputs)\n    return outputs\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.pooling.FourierPooling2D.get_config","title":"get_config","text":"<pre><code>get_config() -&gt; Dict[str, Any]\n</code></pre> <p>Serialization of the object.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with the class' variable names as keys.</p> Source code in <code>DeepSaki/layers/pooling.py</code> <pre><code>def get_config(self) -&gt; Dict[str, Any]:\n    \"\"\"Serialization of the object.\n\n    Returns:\n        Dictionary with the class' variable names as keys.\n    \"\"\"\n    config = super(FourierPooling2D, self).get_config()\n    config.update({\"is_channel_first\": self.is_channel_first})\n    return config\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.pooling.FrequencyFilter","title":"FrequencyFilter","text":"<p>             Bases: <code>Enum</code></p> <p><code>Enum</code> used to define valid filters for <code>rFFT2DFilter</code>.</p> <p>Attributes:</p> Name Type Description <code>LOW_PASS</code> <code>int</code> <p>Indicates that low frequency components shall be kept and high frequency components shall be filtered.</p> <code>HIGH_PASS</code> <code>int</code> <p>Indicates that high frequency components shall be kept and low frequency components shall be filtered.</p>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.pooling.GlobalSumPooling2D","title":"GlobalSumPooling2D","text":"<pre><code>GlobalSumPooling2D(**kwargs: Any)\n</code></pre> <p>             Bases: <code>tf.keras.layers.Layer</code></p> <p>Global sum pooling operation for spatial data.</p> Tips <p>Similar to tensorflow's GlobalMaxPooling2D and GlobalAveragePooling2D</p> <p>Initialize the <code>GlobalSumPooling2D</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>kwargs</code> <code>Any</code> <p>Additional key word arguments passed to the base class.</p> <code>{}</code> Source code in <code>DeepSaki/layers/pooling.py</code> <pre><code>def __init__(self, **kwargs: Any) -&gt; None:\n    \"\"\"Initialize the `GlobalSumPooling2D` object.\n\n    Args:\n        kwargs (Any): Additional key word arguments passed to the base class.\n    \"\"\"\n    super(GlobalSumPooling2D, self).__init__(**kwargs)\n    self.data_format = \"channels_last\"\n    self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.pooling.GlobalSumPooling2D.call","title":"call","text":"<pre><code>call(inputs: tf.Tensor) -&gt; tf.Tensor\n</code></pre> <p>Calls the <code>GlobalSumPooling2D</code> layer.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>tf.Tensor</code> <p>Tensor of shape (<code>batch</code>,<code>height</code>,<code>width</code>,<code>channel</code>) or (<code>batch</code>,<code>channel</code>,<code>height</code>,<code>width</code>).</p> required <p>Returns:</p> Type Description <code>tf.Tensor</code> <p>Tensor of shape (<code>batch</code>,<code>channel</code>) where the elements are summed to reduce the axis.</p> Source code in <code>DeepSaki/layers/pooling.py</code> <pre><code>def call(self, inputs: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"Calls the `GlobalSumPooling2D` layer.\n\n    Args:\n        inputs (tf.Tensor): Tensor of shape (`batch`,`height`,`width`,`channel`) or\n            (`batch`,`channel`,`height`,`width`).\n\n    Returns:\n        Tensor of shape (`batch`,`channel`) where the elements are summed to reduce the axis.\n    \"\"\"\n    return tf.reduce_sum(input_tensor=inputs, axis=[1, 2], keepdims=False)\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.pooling.GlobalSumPooling2D.compute_output_shape","title":"compute_output_shape","text":"<pre><code>compute_output_shape(\n    input_shape: tf.TensorShape,\n) -&gt; Optional[tf.TensorShape]\n</code></pre> <p>Computes the output shape of the layer.</p> <p>This method will cause the layer's state to be built, if that has not happened before. This requires that the layer will later be used with inputs that match the input shape provided here.</p> <p>Parameters:</p> Name Type Description Default <code>input_shape</code> <code>tf.TensorShape</code> <p>Shape of the input tensor to this layer.</p> required <p>Returns:</p> Type Description <code>Optional[tf.TensorShape]</code> <p>A TensorShape instance representing the shape of the layer's output Tensor.</p> Source code in <code>DeepSaki/layers/pooling.py</code> <pre><code>def compute_output_shape(self, input_shape: tf.TensorShape) -&gt; Optional[tf.TensorShape]:\n    \"\"\"Computes the output shape of the layer.\n\n    This method will cause the layer's state to be built, if that has not happened before. This requires that the\n    layer will later be used with inputs that match the input shape provided here.\n\n    Args:\n        input_shape (tf.TensorShape): Shape of the input tensor to this layer.\n\n    Returns:\n        A TensorShape instance representing the shape of the layer's output Tensor.\n    \"\"\"\n    input_shape = tf.TensorShape(input_shape).as_list()\n    if self.data_format == \"channels_last\":\n        return tf.TensorShape([input_shape[0], input_shape[3]])\n    return None\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.pooling.GlobalSumPooling2D.get_config","title":"get_config","text":"<pre><code>get_config() -&gt; Dict[str, Any]\n</code></pre> <p>Serialization of the object.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with the class' variable names as keys.</p> Source code in <code>DeepSaki/layers/pooling.py</code> <pre><code>def get_config(self) -&gt; Dict[str, Any]:\n    \"\"\"Serialization of the object.\n\n    Returns:\n        Dictionary with the class' variable names as keys.\n    \"\"\"\n    config = super(GlobalSumPooling2D, self).get_config()\n    config.update({\"data_format\": self.data_format})\n    return config\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.pooling.LearnedPooling","title":"LearnedPooling","text":"<pre><code>LearnedPooling(pool_size: int = 2, **kwargs: Any)\n</code></pre> <p>             Bases: <code>tf.keras.layers.Layer</code></p> <p>Layer that learns a pooling operation.</p> <p>Instead of using MaxPooling2D or AveragePooling2D the layer learns a pooling operation.</p> Info <p>Under the hood this layer simply performs a non-overlapping convolution operation.</p> <p>Initializes an instance of <code>LearnedPooling</code>.</p> <p>Parameters:</p> Name Type Description Default <code>pool_size</code> <code>int</code> <p>Size of the pooling window and the stride of the convolution operation. If the input is of shape (b, h, w, c), the output is (b,h/pool_size,w/pool_size,c). Defaults to 2.</p> <code>2</code> <code>kwargs</code> <code>Any</code> <p>Additional key word arguments passed to the base class.</p> <code>{}</code> Source code in <code>DeepSaki/layers/pooling.py</code> <pre><code>def __init__(self, pool_size: int = 2, **kwargs: Any) -&gt; None:\n    \"\"\"Initializes an instance of `LearnedPooling`.\n\n    Args:\n        pool_size (int, optional): Size of the pooling window and the stride of the convolution operation. If the\n            input is of shape (b, h, w, c), the output is (b,h/pool_size,w/pool_size,c). Defaults to 2.\n        kwargs (Any): Additional key word arguments passed to the base class.\n    \"\"\"\n    super(LearnedPooling, self).__init__(**kwargs)\n    self.pool_size = pool_size\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.pooling.LearnedPooling.build","title":"build","text":"<pre><code>build(input_shape: tf.TensorShape) -&gt; None\n</code></pre> <p>Build layer depending on the <code>input_shape</code> (output shape of the previous layer).</p> <p>Parameters:</p> Name Type Description Default <code>input_shape</code> <code>tf.TensorShape</code> <p>Shape of the input tensor to this layer.</p> required Source code in <code>DeepSaki/layers/pooling.py</code> <pre><code>def build(self, input_shape: tf.TensorShape) -&gt; None:\n    \"\"\"Build layer depending on the `input_shape` (output shape of the previous layer).\n\n    Args:\n        input_shape (tf.TensorShape): Shape of the input tensor to this layer.\n    \"\"\"\n    self.pooling = tf.keras.layers.Conv2D(\n        kernel_size=self.pool_size,\n        strides=self.pool_size,\n        filters=input_shape[-1],\n        use_bias=False,\n        padding=\"same\",\n    )\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.pooling.LearnedPooling.call","title":"call","text":"<pre><code>call(x: tf.Tensor) -&gt; tf.Tensor\n</code></pre> <p>Calls the <code>LearnedPooling</code> layer.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>tf.Tensor</code> <p>Tensor of shape (<code>batch</code>,<code>height</code>,<code>width</code>,<code>channel</code>).</p> required <p>Returns:</p> Type Description <code>tf.Tensor</code> <p>Pooled tensor of shape (<code>batch</code>,<code>height/pool_size</code>,<code>width/pool_size</code>,<code>channel</code>)</p> Source code in <code>DeepSaki/layers/pooling.py</code> <pre><code>def call(self, x: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"Calls the `LearnedPooling` layer.\n\n    Args:\n        x (tf.Tensor): Tensor of shape (`batch`,`height`,`width`,`channel`).\n\n    Returns:\n        Pooled tensor of shape (`batch`,`height/pool_size`,`width/pool_size`,`channel`)\n    \"\"\"\n    return self.pooling(x)\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.pooling.LearnedPooling.get_config","title":"get_config","text":"<pre><code>get_config() -&gt; Dict[str, Any]\n</code></pre> <p>Serialization of the object.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with the class' variable names as keys.</p> Source code in <code>DeepSaki/layers/pooling.py</code> <pre><code>def get_config(self) -&gt; Dict[str, Any]:\n    \"\"\"Serialization of the object.\n\n    Returns:\n        Dictionary with the class' variable names as keys.\n    \"\"\"\n    config = super(LearnedPooling, self).get_config()\n    config.update({\"pool_size\": self.pool_size})\n    return config\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.pooling.rFFT2DFilter","title":"rFFT2DFilter","text":"<pre><code>rFFT2DFilter(\n    is_channel_first: bool = False,\n    filter_type: Literal[\n        FrequencyFilter.LOW_PASS, FrequencyFilter.HIGH_PASS\n    ] = FrequencyFilter.LOW_PASS,\n    **kwargs: Any\n)\n</code></pre> <p>             Bases: <code>tf.keras.layers.Layer</code></p> <p>Low or high pass filtering by truncating higher or lower frequencies in the frequency domain.</p> <p>Layer input is asumed to be in spatial domain. It is transformed into the frequency domain applying a 2D real FFT. Then the center-crop operation is performed and depending of the shift, either low or high frequencies are removed. Afterwards, the cropped region is zero padded and then the inverse real 2D FFT is calculated to transform back into the spatial domain.</p> <p>Initialize the <code>rFFT2DFilter</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>is_channel_first</code> <code>bool</code> <p>If True, input shape is assumed to be (<code>batch</code>,<code>channel</code>,<code>height</code>,<code>width</code>). If False, input shape is assumed to be (<code>batch</code>,<code>height</code>,<code>width</code>,<code>channel</code>). Defaults to False.</p> <code>False</code> <code>filter_type</code> <code>Literal[Frequency_Filter.LOW_PASS, Frequency_Filter.HIGH_PASS]</code> <p>If <code>Frequency_Filter.LOW_PASS</code>, high frequency values are truncated, if <code>Frequency_Filter.HIGH_PASS</code>, low frequencies are truncated. Defaults to <code>Frequency_Filter.LOW_PASS</code>.</p> <code>FrequencyFilter.LOW_PASS</code> <code>kwargs</code> <code>Any</code> <p>Additional key word arguments passed to the base class.</p> <code>{}</code> Source code in <code>DeepSaki/layers/pooling.py</code> <pre><code>def __init__(\n    self,\n    is_channel_first: bool = False,\n    filter_type: Literal[FrequencyFilter.LOW_PASS, FrequencyFilter.HIGH_PASS] = FrequencyFilter.LOW_PASS,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Initialize the `rFFT2DFilter` object.\n\n    Args:\n        is_channel_first (bool, optional): If True, input shape is assumed to be (`batch`,`channel`,`height`,`width`).\n            If False, input shape is assumed to be (`batch`,`height`,`width`,`channel`). Defaults to False.\n        filter_type (Literal[Frequency_Filter.LOW_PASS,Frequency_Filter.HIGH_PASS], optional): If\n            `Frequency_Filter.LOW_PASS`, high frequency values are truncated, if `Frequency_Filter.HIGH_PASS`, low\n            frequencies are truncated. Defaults to `Frequency_Filter.LOW_PASS`.\n        kwargs (Any): Additional key word arguments passed to the base class.\n    \"\"\"\n    super(rFFT2DFilter, self).__init__(**kwargs)\n    self.is_channel_first = is_channel_first\n    self.filter_type = filter_type\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.pooling.rFFT2DFilter.build","title":"build","text":"<pre><code>build(input_shape: tf.TensorShape) -&gt; None\n</code></pre> <p>Build layer depending on the <code>input_shape</code> (output shape of the previous layer).</p> <p>Parameters:</p> Name Type Description Default <code>input_shape</code> <code>tf.TensorShape</code> <p>Shape of the input tensor to this layer.</p> required Source code in <code>DeepSaki/layers/pooling.py</code> <pre><code>def build(self, input_shape: tf.TensorShape) -&gt; None:\n    \"\"\"Build layer depending on the `input_shape` (output shape of the previous layer).\n\n    Args:\n        input_shape (tf.TensorShape): Shape of the input tensor to this layer.\n    \"\"\"\n    super(rFFT2DFilter, self).build(input_shape)\n    if self.is_channel_first:\n        batch_size, inp_filter, inp_height, inp_width = input_shape\n    else:\n        batch_size, inp_height, inp_width, inp_filter = input_shape\n    self.offset_height = inp_height // 2\n    self.offset_width = 0\n    self.target_height = inp_height // 2\n    self.target_width = int(\n        inp_width / 4 + 1\n    )  # 1/4 because real spectrum has allready half width and filter only applies to positive frequencies in width\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.pooling.rFFT2DFilter.call","title":"call","text":"<pre><code>call(inputs: tf.Tensor) -&gt; tf.Tensor\n</code></pre> <p>Calls the <code>rFFT2DFilter</code> layer.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>tf.Tensor</code> <p>Tensor of shape (<code>batch</code>,<code>height</code>,<code>width</code>,<code>channel</code>) or (<code>batch</code>,<code>channel</code>,<code>height</code>,<code>width</code>).</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If Layer has not been built.</p> <p>Returns:</p> Type Description <code>tf.Tensor</code> <p>Filtered tensor with shape (<code>batch</code>,<code>channel</code>,<code>height</code>,<code>width</code>).</p> Source code in <code>DeepSaki/layers/pooling.py</code> <pre><code>def call(self, inputs: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"Calls the `rFFT2DFilter` layer.\n\n    Args:\n        inputs (tf.Tensor): Tensor of shape (`batch`,`height`,`width`,`channel`) or\n            (`batch`,`channel`,`height`,`width`).\n\n    Raises:\n        ValueError: If Layer has not been built.\n\n    Returns:\n        Filtered tensor with shape (`batch`,`channel`,`height`,`width`).\n    \"\"\"\n    if not self.built:\n        raise ValueError(\"This model has not yet been built.\")\n\n    if not self.is_channel_first:  # layer assumes channel first due to FFT\n        inputs = tf.einsum(\"bhwc-&gt;bchw\", inputs)\n\n    inputs_f_domain = tf.signal.rfft2d(inputs)\n\n    if self.filter_type == FrequencyFilter.LOW_PASS:\n        inputs_f_domain = tf.signal.fftshift(\n            inputs_f_domain, axes=[-2]\n        )  # shift frequencies to be able to crop in center\n    shape = tf.shape(inputs_f_domain)\n    outputs_f_domain = tf.slice(\n        inputs_f_domain,\n        begin=[0, 0, self.offset_height, self.offset_width],\n        size=[shape[0], shape[1], self.target_height, self.target_width],\n    )  # Tf.slice instead of tf.image.crop, because the latter assumes channel last\n    if self.filter_type == FrequencyFilter.LOW_PASS:\n        outputs_f_domain = tf.signal.ifftshift(outputs_f_domain, axes=[-2])  # reverse shift\n    outputs = tf.signal.irfft2d(outputs_f_domain)\n\n    # reverse to previous channel config!\n    if not self.is_channel_first:\n        outputs = tf.einsum(\"bchw-&gt;bhwc\", outputs)\n    return outputs\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.pooling.rFFT2DFilter.get_config","title":"get_config","text":"<pre><code>get_config() -&gt; Dict[str, Any]\n</code></pre> <p>Serialization of the object.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with the class' variable names as keys.</p> Source code in <code>DeepSaki/layers/pooling.py</code> <pre><code>def get_config(self) -&gt; Dict[str, Any]:\n    \"\"\"Serialization of the object.\n\n    Returns:\n        Dictionary with the class' variable names as keys.\n    \"\"\"\n    config = super(rFFT2DFilter, self).get_config()\n    config.update({\"is_channel_first\": self.is_channel_first, \"filter_type\": self.filter_type})\n    return config\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.fourier_layer.FFT2D","title":"FFT2D","text":"<pre><code>FFT2D(\n    is_channel_first: bool = False,\n    applyRealFFT: bool = False,\n    shiftFFT: bool = True,\n    **kwargs: Any\n)\n</code></pre> <p>             Bases: <code>tf.keras.layers.Layer</code></p> <p>Calculates the 2D descrete fourier transform over the 2 innermost channels (height, width) over a 4 channel input (batch, height, width, channel) args: - is_channel_first: True or False. If True, input shape is assumed to be [batch,channel,height,width]. If False, input shape is assumed to be [batch,height,width,channel] - applyRealFFT: True or False. If True, rfft2D is applied, which assumes real valued inputs and halves the width of the output. If False, fft2D is applied, which assumes complex input. - shiftFFT: True or False. If true, low frequency componentes are centered. - **kwargs: keyword arguments passed to the parent class tf.keras.layers.Layer.</p> Source code in <code>DeepSaki/layers/fourier_layer.py</code> <pre><code>def __init__(\n    self,\n    is_channel_first: bool = False,\n    applyRealFFT: bool = False,\n    shiftFFT: bool = True,\n    **kwargs: Any,\n) -&gt; None:\n    super(FFT2D, self).__init__(**kwargs)\n    self.is_channel_first = is_channel_first\n    self.applyRealFFT = applyRealFFT\n    self.shiftFFT = shiftFFT\n    self.policy_compute_dtype = tf.keras.mixed_precision.global_policy().compute_dtype\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.fourier_layer.FFT2D.get_config","title":"get_config","text":"<pre><code>get_config() -&gt; Dict[str, Any]\n</code></pre> <p>Serialization of the object.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with the class' variable names as keys.</p> Source code in <code>DeepSaki/layers/fourier_layer.py</code> <pre><code>def get_config(self) -&gt; Dict[str, Any]:\n    \"\"\"Serialization of the object.\n\n    Returns:\n        Dictionary with the class' variable names as keys.\n    \"\"\"\n    config = super(FFT2D, self).get_config()\n    config.update(\n        {\n            \"is_channel_first\": self.is_channel_first,\n            \"applyRealFFT\": self.applyRealFFT,\n            \"shiftFFT\": self.shiftFFT,\n            \"policy_compute_dtype\": self.policy_compute_dtype,\n        }\n    )\n    return config\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.fourier_layer.FFT3D","title":"FFT3D","text":"<pre><code>FFT3D(\n    applyRealFFT: bool = False,\n    shiftFFT: bool = True,\n    **kwargs: Any\n)\n</code></pre> <p>             Bases: <code>tf.keras.layers.Layer</code></p> <p>Calculates the 3D descrete fourier transform over the 3 innermost channels (height, width, channel) over a 4 channel input (batch, height, width, channel) args: - applyRealFFT: True or False. If True, rfft3D is applied, which assumes real valued inputs and halves the width of the output. If False, fft3D is applied, which assumes complex input. - shiftFFT: True or False. If true, low frequency componentes are centered. - **kwargs: keyword arguments passed to the parent class tf.keras.layers.Layer.</p> Source code in <code>DeepSaki/layers/fourier_layer.py</code> <pre><code>def __init__(self, applyRealFFT: bool = False, shiftFFT: bool = True, **kwargs: Any) -&gt; None:\n    super(FFT3D, self).__init__(**kwargs)\n    self.applyRealFFT = applyRealFFT\n    self.shiftFFT = shiftFFT\n    self.policy_compute_dtype = tf.keras.mixed_precision.global_policy().compute_dtype\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.fourier_layer.FFT3D.get_config","title":"get_config","text":"<pre><code>get_config() -&gt; Dict[str, Any]\n</code></pre> <p>Serialization of the object.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with the class' variable names as keys.</p> Source code in <code>DeepSaki/layers/fourier_layer.py</code> <pre><code>def get_config(self) -&gt; Dict[str, Any]:\n    \"\"\"Serialization of the object.\n\n    Returns:\n        Dictionary with the class' variable names as keys.\n    \"\"\"\n    config = super(FFT3D, self).get_config()\n    config.update(\n        {\n            \"applyRealFFT\": self.applyRealFFT,\n            \"shiftFFT\": self.shiftFFT,\n            \"policy_compute_dtype\": self.policy_compute_dtype,\n        }\n    )\n    return config\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.fourier_layer.FourierConvolution2D","title":"FourierConvolution2D","text":"<pre><code>FourierConvolution2D(\n    filters: int,\n    kernels: Optional[Tuple[int, int]] = None,\n    use_bias: bool = True,\n    kernel_initializer: tf.keras.initializers.Initializer = tf.keras.initializers.RandomUniform(\n        -0.05, 0.05\n    ),\n    bias_initializer: tf.keras.initializers.Initializer = tf.keras.initializers.Zeros(),\n    is_channel_first: bool = False,\n    apply_conjugate: bool = False,\n    pad_to_power_2: bool = True,\n    method: MultiplicationType = MultiplicationType.ELEMENT_WISE,\n    **kwargs: Any\n)\n</code></pre> <p>             Bases: <code>tf.keras.layers.Layer</code></p> <p>Performs a convolution by transforming into fourier domain. Layer input is asumed to be in spatial domain.</p> <p>Initialize the <code>FourierConvolution2D</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>filters</code> <code>int</code> <p>Number of individual filters.</p> required <code>kernels</code> <code>Optional[Tuple[int, int]]</code> <p>Kernel of the spatial convolution. Expected input <code>[height,width]</code>. If <code>None</code>, kernel size is set to the input height and width. Defaults to <code>None</code>.</p> <code>None</code> <code>use_bias</code> <code>bool</code> <p>Whether or not to us bias weights. Defaults to <code>True</code>.</p> <code>True</code> <code>kernel_initializer</code> <code>tf.keras.initializers.Initializer</code> <p>Initializer to initialize the kernels of the convolution layer. Defaults to <code>tf.keras.initializers.RandomUniform(-0.05, 0.05)</code>.</p> <code>tf.keras.initializers.RandomUniform(-0.05, 0.05)</code> <code>bias_initializer</code> <code>tf.keras.initializers.Initializer</code> <p>Initializer to initialize the bias weights of the convolution layer. Defaults to <code>tf.keras.initializers.Zeros()</code>.</p> <code>tf.keras.initializers.Zeros()</code> <code>is_channel_first</code> <code>bool</code> <p>Set true if input shape is (b,c,h,w) and false if input shape is (b,h,w,c). Defaults to <code>False</code>.</p> <code>False</code> <code>apply_conjugate</code> <code>bool</code> <p>If true, the kernels are conjugated. If so, a multiplication in the frequency domain corresponds to a cross correlation in the spatial domain, which is actually what a convolution layer is doing. Defaults to <code>False</code>.</p> <code>False</code> <code>pad_to_power_2</code> <code>bool</code> <p>If true, input tensor is padded. FFT algorithm runs faster for lengths of power of two. Defaults to <code>True</code>.</p> <code>True</code> <code>method</code> <code>MultiplicationType</code> <p>Type of multiplication of the input and the weights: [<code>MultiplicationType.ELEMENT_WISE</code> | <code>MultiplicationType.MATRIX_PRODUCT</code>]. Defaults to <code>MultiplicationType.ELEMENT_WISE</code>.</p> <code>MultiplicationType.ELEMENT_WISE</code> <code>kwargs</code> <code>Any</code> <p>Additional key word arguments passed to the base class.</p> <code>{}</code> Source code in <code>DeepSaki/layers/fourier_layer.py</code> <pre><code>def __init__(\n    self,\n    filters: int,\n    kernels: Optional[Tuple[int, int]] = None,\n    use_bias: bool = True,\n    kernel_initializer: tf.keras.initializers.Initializer = tf.keras.initializers.RandomUniform(-0.05, 0.05),\n    bias_initializer: tf.keras.initializers.Initializer = tf.keras.initializers.Zeros(),\n    is_channel_first: bool = False,\n    apply_conjugate: bool = False,\n    pad_to_power_2: bool = True,\n    method: MultiplicationType = MultiplicationType.ELEMENT_WISE,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Initialize the `FourierConvolution2D` object.\n\n    Args:\n        filters (int): Number of individual filters.\n        kernels (Optional[Tuple[int, int]], optional): Kernel of the spatial convolution. Expected input\n            `[height,width]`. If `None`, kernel size is set to the input height and width. Defaults to `None`.\n        use_bias (bool, optional): Whether or not to us bias weights. Defaults to `True`.\n        kernel_initializer (tf.keras.initializers.Initializer, optional): Initializer to initialize the kernels of\n            the convolution layer. Defaults to `tf.keras.initializers.RandomUniform(-0.05, 0.05)`.\n        bias_initializer (tf.keras.initializers.Initializer, optional): Initializer to initialize the bias weights\n            of the convolution layer. Defaults to `tf.keras.initializers.Zeros()`.\n        is_channel_first (bool, optional): Set true if input shape is (b,c,h,w) and false if input shape is\n            (b,h,w,c). Defaults to `False`.\n        apply_conjugate (bool, optional): If true, the kernels are conjugated. If so, a multiplication in the\n            frequency domain corresponds to a cross correlation in the spatial domain, which is actually what a\n            convolution layer is doing. Defaults to `False`.\n        pad_to_power_2 (bool, optional): If true, input tensor is padded. FFT algorithm runs faster for lengths of\n            power of two. Defaults to `True`.\n        method (MultiplicationType, optional): Type of multiplication of the input and the weights:\n            [`MultiplicationType.ELEMENT_WISE` | `MultiplicationType.MATRIX_PRODUCT`]. Defaults to\n            `MultiplicationType.ELEMENT_WISE`.\n        kwargs (Any): Additional key word arguments passed to the base class.\n    \"\"\"\n    super(FourierConvolution2D, self).__init__(**kwargs)\n    self.filters = filters\n    self.kernels = kernels\n    self.use_bias = use_bias\n    self.kernel_initializer = kernel_initializer\n    self.bias_initializer = bias_initializer\n    self.is_channel_first = is_channel_first\n    self.apply_conjugate = apply_conjugate\n    self.pad_to_power_2 = pad_to_power_2\n    self.method = method\n    if method == MultiplicationType.MATRIX_PRODUCT:\n        self.multiply = self._matrix_product\n    elif method == MultiplicationType.ELEMENT_WISE:\n        self.multiply = self._elementwise_product\n    else:\n        raise ValueError(f'Entered method: {self.method.name} unkown. Use \"MATRIX_PRODUCT\" or \"ELEMENT_WISE\".')\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.fourier_layer.FourierConvolution2D.build","title":"build","text":"<pre><code>build(input_shape: tf.TensorShape) -&gt; None\n</code></pre> <p>Build layer depending on the <code>input_shape</code> (output shape of the previous layer).</p> <p>Parameters:</p> Name Type Description Default <code>input_shape</code> <code>tf.TensorShape</code> <p>Shape of the input tensor to this layer.</p> required Source code in <code>DeepSaki/layers/fourier_layer.py</code> <pre><code>def build(self, input_shape: tf.TensorShape) -&gt; None:\n    \"\"\"Build layer depending on the `input_shape` (output shape of the previous layer).\n\n    Args:\n        input_shape (tf.TensorShape): Shape of the input tensor to this layer.\n    \"\"\"\n    super(FourierConvolution2D, self).build(input_shape)\n    if self.is_channel_first:\n        self.batch_size, self.inp_filter, self.inp_height, self.inp_width = input_shape\n    else:\n        self.batch_size, self.inp_height, self.inp_width, self.inp_filter = input_shape\n\n    if self.kernels is None:\n        self.kernels = (self.inp_height, self.inp_width)\n\n    # weights are independent from batch size [out_filter,inp_filter,kernel,kernel]. I leave the two kernels last, since I then can easily calculate the 2d FFT at once!\n    self.kernel = self.add_weight(\n        name=\"kernel\",\n        shape=[self.filters, self.inp_filter, self.kernels[0], self.kernels[1]],\n        initializer=self.kernel_initializer,\n        trainable=True,\n    )\n    self.padding = self._get_image_padding()\n    self.paddedImageShape = (\n        self.batch_size,\n        self.inp_filter,\n        self.inp_height + 2 * self.padding,\n        self.inp_width + 2 * self.padding,\n    )\n\n    if self.use_bias:\n        self.bias = self.add_weight(\n            name=\"bias\", shape=[self.filters, 1, 1], initializer=self.bias_initializer, trainable=True\n        )\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.fourier_layer.FourierConvolution2D.call","title":"call","text":"<pre><code>call(inputs: tf.Tensor) -&gt; tf.Tensor\n</code></pre> <p>Calls the <code>FourierConvolution2D</code> layer.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>tf.Tensor</code> <p>Tensor of data in spatial domain of shape <code>(b,h,w,c)</code> or <code>(b,c,h,w)</code> depending on <code>is_channel_first</code></p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If Layer has not been built.</p> <p>Returns:</p> Type Description <code>tf.Tensor</code> <p>Tensor in spatial domain of same shape as input.</p> Source code in <code>DeepSaki/layers/fourier_layer.py</code> <pre><code>def call(self, inputs: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"Calls the `FourierConvolution2D` layer.\n\n    Args:\n        inputs (tf.Tensor): Tensor of data in spatial domain of shape `(b,h,w,c)` or `(b,c,h,w)` depending on\n            `is_channel_first`\n\n    Raises:\n        ValueError: If Layer has not been built.\n\n    Returns:\n        Tensor in spatial domain of same shape as input.\n    \"\"\"\n    if not self.built:\n        raise ValueError(\"This model has not yet been built.\")\n\n    # FFT2D is calculated over last two dimensions!\n    if not self.is_channel_first:\n        inputs = tf.einsum(\"bhwc-&gt;bchw\", inputs)\n\n    # Optionally pad to power of 2, to speed up FFT\n    if self.pad_to_power_2:\n        image_shape = self._fill_image_shape_power_2()\n\n    # Compute DFFTs for both inputs and kernel weights\n    inputs_f_domain = tf.signal.rfft2d(\n        inputs, fft_length=[self.paddedImageShape[-2], self.paddedImageShape[-1]]\n    )  # [batch,height,width,channel]\n    kernels_f_domain = tf.signal.rfft2d(\n        self.kernel, fft_length=[self.paddedImageShape[-2], self.paddedImageShape[-1]]\n    )\n    if self.apply_conjugate:\n        kernels_f_domain = tf.math.conj(kernels_f_domain)  # to be equvivalent to the cross correlation\n\n    outputs_f_domain = self.multiply(inputs_f_domain, kernels_f_domain)\n\n    # Inverse rDFFT\n    output = tf.signal.irfft2d(outputs_f_domain, fft_length=[self.paddedImageShape[-2], self.paddedImageShape[-1]])\n    output = tf.roll(\n        output, shift=[2 * self.padding, 2 * self.padding], axis=[-2, -1]\n    )  # shift the samples to obtain linear conv from circular conv\n    output = tf.slice(\n        output,\n        begin=[0, 0, self.padding, self.padding],\n        size=[self.batch_size, self.filters, self.inp_height, self.inp_width],\n    )\n\n    # Optionally add bias\n    if self.use_bias:\n        output += self.bias\n\n    # reverse the channel configuration to its initial config\n    if not self.is_channel_first:\n        output = tf.einsum(\"bchw-&gt;bhwc\", output)\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.fourier_layer.FourierConvolution2D.get_config","title":"get_config","text":"<pre><code>get_config() -&gt; Dict[str, Any]\n</code></pre> <p>Serialization of the object.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with the class' variable names as keys.</p> Source code in <code>DeepSaki/layers/fourier_layer.py</code> <pre><code>def get_config(self) -&gt; Dict[str, Any]:\n    \"\"\"Serialization of the object.\n\n    Returns:\n        Dictionary with the class' variable names as keys.\n    \"\"\"\n    config = super(FourierConvolution2D, self).get_config()\n    config.update(\n        {\n            \"filters\": self.filters,\n            \"kernels\": self.kernels,\n            \"use_bias\": self.use_bias,\n            \"kernel_initializer\": self.kernel_initializer,\n            \"bias_initializer\": self.bias_initializer,\n            \"is_channel_first\": self.is_channel_first,\n            \"apply_conjugate\": self.apply_conjugate,\n            \"pad_to_power_2\": self.pad_to_power_2,\n            \"method\": self.method,\n        }\n    )\n    return config\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.fourier_layer.FourierFilter2D","title":"FourierFilter2D","text":"<pre><code>FourierFilter2D(\n    filters: int,\n    use_bias: bool = True,\n    filter_initializer: tf.keras.initializers.Initializer = tf.keras.initializers.RandomUniform(\n        -0.05, 0.05\n    ),\n    bias_initializer: tf.keras.initializers.Initializer = tf.keras.initializers.Zeros(),\n    is_channel_first: bool = False,\n    **kwargs: Any\n)\n</code></pre> <p>             Bases: <code>tf.keras.layers.Layer</code></p> <p>Complex-valued learnable filter in frequency domain. Expects input data to be in the fourier domain.</p> <p>To transform an image into the frequency domain you can use <code>DeepSaki.layers.FFT2D</code>.</p> <p>Example: <pre><code>import DeepSaki as dsk\n# pseudo code to load data\nimage_dataset = load_data(data_path)\nx = dsk.layers.FFT2D()(image_dataset)\nx = dsk.layers.FourierFilter2D(filters=64)(x)\nx = dsk.layers.iFFT2D()(x)\n</code></pre></p> <p>Initialize the <code>FourierFilter2D</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>filters</code> <code>int</code> <p>Number of independent filters</p> required <code>use_bias</code> <code>bool</code> <p>Whether or not to us bias weights. Defaults to <code>True</code>.</p> <code>True</code> <code>filter_initializer</code> <code>tf.keras.initializers.Initializer</code> <p>Initializer to initialize the wheights of the filter layer. Defaults to <code>tf.keras.initializers.RandomUniform(-0.05, 0.05)</code>.</p> <code>tf.keras.initializers.RandomUniform(-0.05, 0.05)</code> <code>bias_initializer</code> <code>tf.keras.initializers.Initializer</code> <p>Initializer to initialize the wheights of the bias weights. Defaults to <code>tf.keras.initializers.Zeros()</code>.</p> <code>tf.keras.initializers.Zeros()</code> <code>is_channel_first</code> <code>bool</code> <p>Set true if input shape is (b,c,h,w) and false if input shape is (b,h,w,c). Defaults to <code>False</code>.</p> <code>False</code> <code>kwargs</code> <code>Any</code> <p>Additional key word arguments passed to the base class.</p> <code>{}</code> Source code in <code>DeepSaki/layers/fourier_layer.py</code> <pre><code>def __init__(\n    self,\n    filters: int,\n    use_bias: bool = True,\n    filter_initializer: tf.keras.initializers.Initializer = tf.keras.initializers.RandomUniform(-0.05, 0.05),\n    bias_initializer: tf.keras.initializers.Initializer = tf.keras.initializers.Zeros(),\n    is_channel_first: bool = False,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Initialize the `FourierFilter2D` object.\n\n    Args:\n        filters (int): Number of independent filters\n        use_bias (bool, optional): Whether or not to us bias weights. Defaults to `True`.\n        filter_initializer (tf.keras.initializers.Initializer, optional): Initializer to initialize the wheights of\n            the filter layer. Defaults to `tf.keras.initializers.RandomUniform(-0.05, 0.05)`.\n        bias_initializer (tf.keras.initializers.Initializer, optional): Initializer to initialize the wheights of\n            the bias weights. Defaults to `tf.keras.initializers.Zeros()`.\n        is_channel_first (bool, optional): Set true if input shape is (b,c,h,w) and false if input shape is\n            (b,h,w,c). Defaults to `False`.\n        kwargs (Any): Additional key word arguments passed to the base class.\n    \"\"\"\n    super(FourierFilter2D, self).__init__(**kwargs)\n    self.filters = filters\n    self.use_bias = use_bias\n    self.filter_initializer = make_initializer_complex(filter_initializer)\n    self.bias_initializer = make_initializer_complex(bias_initializer)\n    self.is_channel_first = is_channel_first\n\n    self.fourier_filter = None  # shape: batch, height, width, input_filters, output_filters\n    self.fourier_bias = None\n    self.out_shape = None\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.fourier_layer.FourierFilter2D.build","title":"build","text":"<pre><code>build(input_shape: tf.TensorShape) -&gt; None\n</code></pre> <p>Build layer depending on the <code>input_shape</code> (output shape of the previous layer).</p> <p>Parameters:</p> Name Type Description Default <code>input_shape</code> <code>tf.TensorShape</code> <p>Shape of the input tensor to this layer.</p> required Source code in <code>DeepSaki/layers/fourier_layer.py</code> <pre><code>def build(self, input_shape: tf.TensorShape) -&gt; None:\n    \"\"\"Build layer depending on the `input_shape` (output shape of the previous layer).\n\n    Args:\n        input_shape (tf.TensorShape): Shape of the input tensor to this layer.\n    \"\"\"\n    super(FourierFilter2D, self).build(input_shape)\n    if self.is_channel_first:\n        batch_size, inp_filter, inp_height, inp_width = input_shape\n    else:\n        batch_size, inp_height, inp_width, inp_filter = input_shape\n\n    # weights are independent from batch size. Filter dimensions differ from convolution, since FFT2D is calculated over last 2 dimensions\n    self.fourier_filter = self.add_weight(\n        name=\"filter\",\n        shape=[inp_filter, inp_height, inp_width, self.filters],\n        initializer=self.filter_initializer,\n        trainable=True,\n        dtype=tf.dtypes.complex64,\n    )\n\n    if (\n        self.use_bias\n    ):  # shape: [filter,1,1] so it can be broadcasted when adding to the output, since FFT asumes channel first!\n        self.fourier_bias = self.add_weight(\n            name=\"bias\",\n            shape=[self.filters, 1, 1],\n            initializer=self.bias_initializer,\n            trainable=True,\n            dtype=tf.dtypes.complex64,\n        )\n\n    # Output shape: batch_size, self.filters, inp_height, inp_width. Filters is zero, since concatenated later\n    self.out_shape = (batch_size, 0, inp_height, inp_width)\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.fourier_layer.FourierFilter2D.call","title":"call","text":"<pre><code>call(inputs: tf.Tensor) -&gt; tf.Tensor\n</code></pre> <p>I take advantage of broadcasting to calculate the batches: https://numpy.org/doc/stable/user/basics.broadcasting.html</p> Source code in <code>DeepSaki/layers/fourier_layer.py</code> <pre><code>def call(self, inputs: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"I take advantage of broadcasting to calculate the batches: https://numpy.org/doc/stable/user/basics.broadcasting.html\"\"\"\n    if not self.built:\n        raise ValueError(\"This model has not yet been built.\")\n\n    if not self.is_channel_first:  # FFT2D is calculated over last two dimensions!\n        inputs = tf.einsum(\"bhwc-&gt;bchw\", inputs)\n\n    output = np.ndarray(shape=self.out_shape)\n    for filter in range(self.filters):\n        output = tf.concat(\n            [\n                output,\n                tf.reduce_sum(\n                    inputs\n                    * self.fourier_filter[\n                        :, :, :, filter\n                    ],  # inputs:(batch, inp_filter, height, width ), fourier_filter:(...,inp_filter,height, width, out_filter)\n                    axis=-3,  # sum over all applied filters\n                    keepdims=True,\n                ),\n            ],\n            axis=-3,  # is the new filter count, since channel first\n        )\n\n    if self.use_bias:\n        output += self.fourier_bias\n\n    if not self.is_channel_first:  # reverse the channel configuration to its initial config\n        output = tf.einsum(\"bchw-&gt;bhwc\", output)\n\n    return output\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.fourier_layer.FourierFilter2D.get_config","title":"get_config","text":"<pre><code>get_config() -&gt; Dict[str, Any]\n</code></pre> <p>Serialization of the object.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with the class' variable names as keys.</p> Source code in <code>DeepSaki/layers/fourier_layer.py</code> <pre><code>def get_config(self) -&gt; Dict[str, Any]:\n    \"\"\"Serialization of the object.\n\n    Returns:\n        Dictionary with the class' variable names as keys.\n    \"\"\"\n    config = super(FourierFilter2D, self).get_config()\n    config.update(\n        {\n            \"filters\": self.filters,\n            \"use_bias\": self.use_bias,\n            \"kernel_initializer\": self.filter_initializer,\n            \"bias_initializer\": self.bias_initializer,\n            \"is_channel_first\": self.is_channel_first,\n        }\n    )\n    return config\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.fourier_layer.MultiplicationType","title":"MultiplicationType","text":"<p>             Bases: <code>Enum</code></p> <p><code>Enum</code> used to define how two matrices shall be multiplied.</p> <p>Attributes:</p> Name Type Description <code>ELEMENT_WISE</code> <code>int</code> <p>Indicates to apply an element-wise multiplication of 2 tensors.</p> <code>MATRIX_PRODUCT</code> <code>int</code> <p>Indicates to apply a matrix-product between 2 tensors.</p>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.fourier_layer.iFFT2D","title":"iFFT2D","text":"<pre><code>iFFT2D(\n    is_channel_first: bool = False,\n    applyRealFFT: bool = False,\n    shiftFFT: bool = True,\n    **kwargs: Any\n)\n</code></pre> <p>             Bases: <code>tf.keras.layers.Layer</code></p> <p>Calculates the 2D inverse FFT and reverses the center shift operation args: - is_channel_first: True or False. If True, input shape is assumed to be [batch,channel,height,width]. If False, input shape is assumed to be [batch,height,width,channel] - applyRealFFT: True or False. If True, rfft2D is applied, which assumes real valued inputs and halves the width of the output. If False, fft2D is applied, which assumes complex input. - shiftFFT: True or False. If True, shift operation of fourier transform is reversed before calculating the inverse fourier transformation - **kwargs: keyword arguments passed to the parent class tf.keras.layers.Layer.</p> Source code in <code>DeepSaki/layers/fourier_layer.py</code> <pre><code>def __init__(\n    self,\n    is_channel_first: bool = False,\n    applyRealFFT: bool = False,\n    shiftFFT: bool = True,\n    **kwargs: Any,\n) -&gt; None:\n    super(iFFT2D, self).__init__(**kwargs)\n    self.is_channel_first = is_channel_first\n    self.applyRealFFT = applyRealFFT\n    self.shiftFFT = shiftFFT\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.fourier_layer.iFFT2D.get_config","title":"get_config","text":"<pre><code>get_config() -&gt; Dict[str, Any]\n</code></pre> <p>Serialization of the object.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with the class' variable names as keys.</p> Source code in <code>DeepSaki/layers/fourier_layer.py</code> <pre><code>def get_config(self) -&gt; Dict[str, Any]:\n    \"\"\"Serialization of the object.\n\n    Returns:\n        Dictionary with the class' variable names as keys.\n    \"\"\"\n    config = super(iFFT2D, self).get_config()\n    config.update(\n        {\"is_channel_first\": self.is_channel_first, \"applyRealFFT\": self.applyRealFFT, \"shiftFFT\": self.shiftFFT}\n    )\n    return config\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.sub_model_composites.Bottleneck","title":"Bottleneck","text":"<pre><code>Bottleneck(\n    n_bottleneck_blocks: int = 3,\n    kernels: int = 3,\n    split_kernels: bool = False,\n    number_of_convs: int = 2,\n    use_residual_Conv2DBlock: bool = True,\n    useResidualIdentityBlock: bool = False,\n    activation: str = \"leaky_relu\",\n    dropout_rate: float = 0.2,\n    channelList: Optional[List[int]] = None,\n    use_spec_norm: bool = False,\n    use_bias: bool = True,\n    residual_cardinality: int = 1,\n    padding: PaddingType = PaddingType.ZERO,\n    kernel_initializer: tf.keras.initializers.Initializer = HeAlphaUniform(),\n    gamma_initializer: tf.keras.initializers.Initializer = HeAlphaUniform(),\n)\n</code></pre> <p>             Bases: <code>tf.keras.layers.Layer</code></p> <p>Bottlenecks are sub-model blocks in auto-encoder-like models such as UNet or ResNet. It is composed of multiple convolution blocks which might have residuals args:   - n_bottleneck_blocks (optional, default: 3): Number of consecutive convolution blocks   - kernels: size of the convolutions kernels   - split_kernels (optional, default: False): to decrease the number of parameters, a convolution with the kernel_size (kernel,kernel) can be splitted into two consecutive convolutions with the kernel_size (kernel,1) and (1,kernel) respectivly   - number_of_convs (optional, default: 2): number of consecutive convolutional building blocks, i.e. Conv2DBlock.   - use_residual_Conv2DBlock (optional, default: True): ads a residual connection in parallel to the Conv2DBlock   - useResidualIdentityBlock (optional, default: False): Whether or not to use the ResidualIdentityBlock instead of the Conv2DBlock   - activation (optional, default: \"leaky_relu\"): string literal or tensorflow activation function object to obtain activation function   - dropout_rate (optional, default: 0): probability of the dropout layer. If the preceeding layer has more than one channel, spatial dropout is applied, otherwise standard dropout   - channelList (optional, default:None): alternativly to number_of_layers and filters, a list with the disired filters for each block can be provided. e.g. channel_list = [64, 128, 256] results in a 3-staged Bottleneck with 64, 128, 256 filters for stage 1, 2 and 3 respectivly.   - use_spec_norm (optional, default: False): applies spectral normalization to convolutional and dense layers   - use_bias (optional, default: True): determines whether convolutions and dense layers include a bias or not   - residual_cardinality (optional, default: 1): cardinality for the ResidualIdentityBlock   - padding (optional, default: \"none\"): padding type. Options are \"none\", \"zero\" or \"reflection\"   - kernel_initializer (optional, default: HeAlphaUniform()): Initialization of the convolutions kernels.   - gamma_initializer (optional, default: HeAlphaUniform()): Initialization of the normalization layers.</p> Source code in <code>DeepSaki/layers/sub_model_composites.py</code> <pre><code>def __init__(\n    self,\n    n_bottleneck_blocks: int = 3,\n    kernels: int = 3,\n    split_kernels: bool = False,\n    number_of_convs: int = 2,\n    use_residual_Conv2DBlock: bool = True,\n    useResidualIdentityBlock: bool = False,\n    activation: str = \"leaky_relu\",\n    dropout_rate: float = 0.2,\n    channelList: Optional[List[int]] = None,\n    use_spec_norm: bool = False,\n    use_bias: bool = True,\n    residual_cardinality: int = 1,\n    padding: PaddingType = PaddingType.ZERO,\n    kernel_initializer: tf.keras.initializers.Initializer = HeAlphaUniform(),\n    gamma_initializer: tf.keras.initializers.Initializer = HeAlphaUniform(),\n) -&gt; None:\n    super(Bottleneck, self).__init__()\n    self.useResidualIdentityBlock = useResidualIdentityBlock\n    self.n_bottleneck_blocks = n_bottleneck_blocks\n    self.use_residual_Conv2DBlock = use_residual_Conv2DBlock\n    self.kernels = kernels\n    self.split_kernels = split_kernels\n    self.number_of_convs = number_of_convs\n    self.activation = activation\n    self.dropout_rate = dropout_rate\n    self.channelList = channelList\n    self.use_spec_norm = use_spec_norm\n    self.use_bias = use_bias\n    self.residual_cardinality = residual_cardinality\n    self.padding = padding\n    self.kernel_initializer = kernel_initializer\n    self.gamma_initializer = gamma_initializer\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.sub_model_composites.Decoder","title":"Decoder","text":"<pre><code>Decoder(\n    number_of_levels: int = 3,\n    upsampling: str = \"2D_upsample_and_conv\",\n    filters: int = 64,\n    limit_filters: int = 1024,\n    use_residual_Conv2DBlock: bool = False,\n    kernels: int = 3,\n    split_kernels: bool = False,\n    number_of_convs: int = 2,\n    activation: str = \"leaky_relu\",\n    dropout_rate: float = 0.2,\n    useResidualIdentityBlock: bool = False,\n    residual_cardinality: int = 1,\n    channelList: Optional[List[int]] = None,\n    use_spec_norm: bool = False,\n    use_bias: bool = True,\n    useSelfAttention: bool = False,\n    enableSkipConnectionsInput: bool = False,\n    padding: PaddingType = PaddingType.ZERO,\n    kernel_initializer: tf.keras.initializers.Initializer = HeAlphaUniform(),\n    gamma_initializer: tf.keras.initializers.Initializer = HeAlphaUniform(),\n)\n</code></pre> <p>             Bases: <code>tf.keras.layers.Layer</code></p> <p>Decoder sub-model combines convolutional blocks with up sample blocks. The spatial width is double with every level while the channel depth is halfed. args:   - number_of_levels (optional, default:3): number of conv2D -&gt; Upsampling pairs   - upsampling(optional, default: \"2D_upsample_and_conv\"): describes the upsampling method used   - filters (optional, default:64): defines the number of filters to which the input is exposed.   - limit_filters (optional, default:1024): limits the number of filters   - use_residual_Conv2DBlock (optional, default: False): ads a residual connection in parallel to the Conv2DBlock   - kernels: size of the convolutions kernels   - split_kernels (optional, default: False): to decrease the number of parameters, a convolution with the kernel_size (kernel,kernel) can be splitted into two consecutive convolutions with the kernel_size (kernel,1) and (1,kernel) respectivly   - number_of_convs (optional, default: 1): number of consecutive convolutional building blocks, i.e. Conv2DBlock.   - activation (optional, default: \"leaky_relu\"): string literal or tensorflow activation function object to obtain activation function   - dropout_rate (optional, default: 0): probability of the dropout layer. If the preceeding layer has more than one channel, spatial dropout is applied, otherwise standard dropout. In the decoder only applied to the first half of levels.   - useResidualIdentityBlock (optional, default: False): Whether or not to use the ResidualIdentityBlock instead of the Conv2DBlock   - residual_cardinality (optional, default: 1): cardinality for the ResidualIdentityBlock   - channelList (optional, default:None): alternativly to number_of_layers and filters, a list with the disired filters for each level can be provided. e.g. channel_list = [64, 128, 256] results in a 3-level Decoder with 64, 128, 256 filters for level 1, 2 and 3 respectivly.   - use_spec_norm (optional, default: False): applies spectral normalization to convolutional and dense layers   - use_bias (optional, default: True): determines whether convolutions and dense layers include a bias or not   - useSelfAttention (optional, default: False): Determines whether to apply self-attention after the encoder before branching.   - enableSkipConnectionsInput (optional, default: False): Whether or not to input skip connections at each level   - padding (optional, default: \"none\"): padding type. Options are \"none\", \"zero\" or \"reflection\"   - kernel_initializer (optional, default: HeAlphaUniform()): Initialization of the convolutions kernels.   - gamma_initializer (optional, default: HeAlphaUniform()): Initialization of the normalization layers.</p> Source code in <code>DeepSaki/layers/sub_model_composites.py</code> <pre><code>def __init__(\n    self,\n    number_of_levels: int = 3,\n    upsampling: str = \"2D_upsample_and_conv\",\n    filters: int = 64,\n    limit_filters: int = 1024,\n    use_residual_Conv2DBlock: bool = False,\n    kernels: int = 3,\n    split_kernels: bool = False,\n    number_of_convs: int = 2,\n    activation: str = \"leaky_relu\",\n    dropout_rate: float = 0.2,\n    useResidualIdentityBlock: bool = False,\n    residual_cardinality: int = 1,\n    channelList: Optional[List[int]] = None,\n    use_spec_norm: bool = False,\n    use_bias: bool = True,\n    useSelfAttention: bool = False,\n    enableSkipConnectionsInput: bool = False,\n    padding: PaddingType = PaddingType.ZERO,\n    kernel_initializer: tf.keras.initializers.Initializer = HeAlphaUniform(),\n    gamma_initializer: tf.keras.initializers.Initializer = HeAlphaUniform(),\n) -&gt; None:\n    super(Decoder, self).__init__()\n    self.number_of_levels = number_of_levels\n    self.filters = filters\n    self.upsampling = upsampling\n    self.limit_filters = limit_filters\n    self.use_residual_Conv2DBlock = use_residual_Conv2DBlock\n    self.kernels = kernels\n    self.split_kernels = split_kernels\n    self.number_of_convs = number_of_convs\n    self.activation = activation\n    self.useResidualIdentityBlock = useResidualIdentityBlock\n    self.channelList = channelList\n    self.use_spec_norm = use_spec_norm\n    self.use_bias = use_bias\n    self.dropout_rate = dropout_rate\n    self.useSelfAttention = useSelfAttention\n    self.enableSkipConnectionsInput = enableSkipConnectionsInput\n    self.residual_cardinality = residual_cardinality\n    self.padding = padding\n    self.kernel_initializer = kernel_initializer\n    self.gamma_initializer = gamma_initializer\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.sub_model_composites.Encoder","title":"Encoder","text":"<pre><code>Encoder(\n    number_of_levels: int = 3,\n    filters: int = 64,\n    limit_filters: int = 1024,\n    use_residual_Conv2DBlock: bool = False,\n    downsampling: str = \"conv_stride_2\",\n    kernels: int = 3,\n    split_kernels: bool = False,\n    number_of_convs: int = 2,\n    activation: str = \"leaky_relu\",\n    first_kernel: Optional[int] = None,\n    useResidualIdentityBlock: bool = False,\n    residual_cardinality: int = 1,\n    channelList: Optional[List[int]] = None,\n    use_spec_norm: bool = False,\n    use_bias: bool = True,\n    dropout_rate: float = 0.0,\n    useSelfAttention: bool = False,\n    omit_skips: int = 0,\n    padding: PaddingType = PaddingType.ZERO,\n    outputSkips: bool = False,\n    kernel_initializer: tf.keras.initializers.Initializer = HeAlphaUniform(),\n    gamma_initializer: tf.keras.initializers.Initializer = HeAlphaUniform(),\n)\n</code></pre> <p>             Bases: <code>tf.keras.layers.Layer</code></p> <p>Encoder sub-model combines convolutional blocks with down sample blocks. The spatial width is halfed with every level while the channel depth is doubled. args:   - number_of_levels (optional, default:3): number of conv2D -&gt; Downsampling pairs   - filters (optional, default:64): defines the number of filters to which the input is exposed.   - kernels: size of the convolutions kernels   - limit_filters (optional, default:1024): limits the number of filters, which is doubled with every downsampling block   - use_residual_Conv2DBlock (optional, default: False): ads a residual connection in parallel to the Conv2DBlock   - downsampling(optional, default: \"conv_stride_2\"): describes the downsampling method used   - split_kernels (optional, default: False): to decrease the number of parameters, a convolution with the kernel_size (kernel,kernel) can be splitted into two consecutive convolutions with the kernel_size (kernel,1) and (1,kernel) respectivly   - number_of_convs (optional, default: 1): number of consecutive convolutional building blocks, i.e. Conv2DBlock.   - activation (optional, default: \"leaky_relu\"): string literal or tensorflow activation function object to obtain activation function   - first_kernel (optional, default: 5): The first convolution can have a different kernel size, to e.g. increase the perceptive field, while the channel depth is still low.   - useResidualIdentityBlock (optional, default: False): Whether or not to use the ResidualIdentityBlock instead of the Conv2DBlock   - residual_cardinality (optional, default: 1): cardinality for the ResidualIdentityBlock   - channelList (optional, default:None): alternativly to number_of_layers and filters, a list with the disired filters for each level can be provided. e.g. channel_list = [64, 128, 256] results in a 3-level Encoder with 64, 128, 256 filters for level 1, 2 and 3 respectivly.   - use_spec_norm (optional, default: False): applies spectral normalization to convolutional and dense layers   - use_bias (optional, default: True): determines whether convolutions and dense layers include a bias or not   - dropout_rate (optional, default: 0): probability of the dropout layer. If the preceeding layer has more than one channel, spatial dropout is applied, otherwise standard dropout   - useSelfAttention (optional, default: False): Determines whether to apply self-attention after the encoder before branching.   - omit_skips (optional, default: 0): defines how many layers should not output a skip connection output. Requires outputSkips to be True. E.g. if omit_skips = 2, the first two levels do not output a skip connection, it starts at level 3.   - padding (optional, default: \"none\"): padding type. Options are \"none\", \"zero\" or \"reflection\"   - outputSkips (optional, default: False): Whether or not to output skip connections at each level   - kernel_initializer (optional, default: HeAlphaUniform()): Initialization of the convolutions kernels.   - gamma_initializer (optional, default: HeAlphaUniform()): Initialization of the normalization layers.</p> Source code in <code>DeepSaki/layers/sub_model_composites.py</code> <pre><code>def __init__(\n    self,\n    number_of_levels: int = 3,\n    filters: int = 64,\n    limit_filters: int = 1024,\n    use_residual_Conv2DBlock: bool = False,\n    downsampling: str = \"conv_stride_2\",\n    kernels: int = 3,\n    split_kernels: bool = False,\n    number_of_convs: int = 2,\n    activation: str = \"leaky_relu\",\n    first_kernel: Optional[int] = None,\n    useResidualIdentityBlock: bool = False,\n    residual_cardinality: int = 1,\n    channelList: Optional[List[int]] = None,\n    use_spec_norm: bool = False,\n    use_bias: bool = True,\n    dropout_rate: float = 0.0,\n    useSelfAttention: bool = False,\n    omit_skips: int = 0,\n    padding: PaddingType = PaddingType.ZERO,\n    outputSkips: bool = False,\n    kernel_initializer: tf.keras.initializers.Initializer = HeAlphaUniform(),\n    gamma_initializer: tf.keras.initializers.Initializer = HeAlphaUniform(),\n) -&gt; None:\n    super(Encoder, self).__init__()\n    self.number_of_levels = number_of_levels\n    self.filters = filters\n    self.limit_filters = limit_filters\n    self.use_residual_Conv2DBlock = use_residual_Conv2DBlock\n    self.downsampling = downsampling\n    self.kernels = kernels\n    self.split_kernels = split_kernels\n    self.number_of_convs = number_of_convs\n    self.activation = activation\n    self.first_kernel = first_kernel\n    self.useResidualIdentityBlock = useResidualIdentityBlock\n    self.residual_cardinality = residual_cardinality\n    self.channelList = channelList\n    self.use_spec_norm = use_spec_norm\n    self.dropout_rate = dropout_rate\n    self.useSelfAttention = useSelfAttention\n    self.omit_skips = omit_skips\n    self.padding = padding\n    self.outputSkips = outputSkips\n    self.use_bias = use_bias\n    self.kernel_initializer = kernel_initializer\n    self.gamma_initializer = gamma_initializer\n</code></pre>"},{"location":"reference/DeepSaki/loss/","title":"loss","text":"<p>Loss functions designed for image like data of the shape (<code>batch</code>, <code>height</code>, <code>width</code>, <code>channels</code>)</p>"},{"location":"reference/DeepSaki/loss/#DeepSaki.loss.image_based_losses.PixelDistanceLoss","title":"PixelDistanceLoss","text":"<pre><code>PixelDistanceLoss(\n    global_batch_size: int,\n    calculation_type: str = \"per_image\",\n    normalize_depth_channel: bool = False,\n    loss_type: str = \"mae\",\n    loss_reduction: tf.keras.losses.Reduction = tf.keras.losses.Reduction.AUTO,\n)\n</code></pre> <p>             Bases: <code>tf.keras.losses.Loss</code></p> <p>calculates a pixel distance loss (per pixel loss) of two images of the shape (batch, height, width, channels).</p> <p>Dunder method to initialize <code>PixelDistanceLoss</code>.</p> <p>Parameters:</p> Name Type Description Default <code>global_batch_size</code> <code>int</code> <p>Batch size considering all workers running in parallel in a data parallel setup</p> required <code>calculation_type</code> <code>str</code> <p>Determines how the loss is calculated: [\"per_image\" | \"per_channel\"]. Defaults to \"per_image\".</p> <code>'per_image'</code> <code>normalize_depth_channel</code> <code>bool</code> <p>For RGBD images, the weight of depth is increased by multiplying the depth by the number of color channels. Defaults to False.</p> <code>False</code> <code>loss_type</code> <code>str</code> <p>Loss to apply: [\"mae\" | \"mse\"]. Defaults to \"mae\".</p> <code>'mae'</code> <code>loss_reduction</code> <code>tf.keras.losses.Reduction</code> <p>Determines how the loss is reduced. Defaults to tf.keras.losses.Reduction.AUTO.</p> <code>tf.keras.losses.Reduction.AUTO</code> Source code in <code>DeepSaki/loss/image_based_losses.py</code> <pre><code>def __init__(\n    self,\n    global_batch_size: int,\n    calculation_type: str = \"per_image\",\n    normalize_depth_channel: bool = False,\n    loss_type: str = \"mae\",\n    loss_reduction: tf.keras.losses.Reduction = tf.keras.losses.Reduction.AUTO,\n) -&gt; None:\n    \"\"\"Dunder method to initialize `PixelDistanceLoss`.\n\n    Args:\n        global_batch_size (int): Batch size considering all workers running in parallel in a data parallel setup\n        calculation_type (str, optional): Determines how the loss is calculated: [\"per_image\" | \"per_channel\"].\n            Defaults to \"per_image\".\n        normalize_depth_channel (bool, optional): For RGBD images, the weight of depth is increased by multiplying\n            the depth by the number of color channels. Defaults to False.\n        loss_type (str, optional): Loss to apply: [\"mae\" | \"mse\"]. Defaults to \"mae\".\n        loss_reduction (tf.keras.losses.Reduction, optional): Determines how the loss is reduced. Defaults to\n            tf.keras.losses.Reduction.AUTO.\n    \"\"\"\n    super(PixelDistanceLoss, self).__init__(reduction=loss_reduction)\n    self.global_batch_size = global_batch_size\n    self.calculation_type = calculation_type\n    self.normalize_depth_channel = normalize_depth_channel\n    self.loss_type = loss_type\n</code></pre>"},{"location":"reference/DeepSaki/loss/#DeepSaki.loss.image_based_losses.PixelDistanceLoss.call","title":"call","text":"<pre><code>call(img1: tf.Tensor, img2: tf.Tensor) -&gt; tf.Tensor\n</code></pre> <p>Calculates the pixel distance between <code>img1</code> and <code>img2</code>.</p> <p>Parameters:</p> Name Type Description Default <code>img1</code> <code>tf.Tensor</code> <p>Image of shape (<code>batch_size</code>, <code>height</code>, <code>width</code>,<code>channel</code>).</p> required <code>img2</code> <code>tf.Tensor</code> <p>Image of shape (<code>batch_size</code>, <code>height</code>, <code>width</code>,<code>channel</code>).</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>self.loss_type</code> is not a valid option.</p> <code>ValueError</code> <p>if <code>self.calculation_type</code> is not a valid option.</p> <p>Returns:</p> Type Description <code>tf.Tensor</code> <p>Tensor containing the loss defined in <code>loss_type</code>.</p> Source code in <code>DeepSaki/loss/image_based_losses.py</code> <pre><code>def call(self, img1: tf.Tensor, img2: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"Calculates the pixel distance between `img1` and `img2`.\n\n    Args:\n        img1 (tf.Tensor): Image of shape (`batch_size`, `height`, `width`,`channel`).\n        img2 (tf.Tensor): Image of shape (`batch_size`, `height`, `width`,`channel`).\n\n    Raises:\n        ValueError: if `self.loss_type` is not a valid option.\n        ValueError: if `self.calculation_type` is not a valid option.\n\n    Returns:\n        Tensor containing the loss defined in `loss_type`.\n    \"\"\"\n    img1 = tf.cast(img1, tf.dtypes.float32)\n    img2 = tf.cast(img2, tf.dtypes.float32)\n    loss = 0.0\n\n    if self.loss_type == \"mae\":\n        error_func = tf.abs\n    elif self.loss_type == \"mse\":\n        error_func = tf.square\n    else:\n        raise ValueError(f\"Parameter loss_type={self.loss_type} is not defined. Use 'mae' or 'mse' instead.\")\n\n    if self.calculation_type == \"per_channel\":\n        # initialize all weights with 1\n        channel_weight = np.ones(img1.shape[-1])\n        if self.normalize_depth_channel:\n            # set weight of the depth channel according to the number of color channels: e.g. for RGB = 3\n            channel_weight[-1] = len(channel_weight) - 1\n            for i in range(img1.shape[-1]):\n                loss += (\n                    channel_weight[i]\n                    * tf.reduce_mean(error_func(img1[:, :, :, i] - img2[:, :, :, i]))\n                    * (1.0 / self.global_batch_size)\n                )\n\n    elif self.calculation_type == \"per_image\":\n        loss = tf.reduce_mean(error_func(img1 - img2)) * (1.0 / self.global_batch_size)\n\n    else:\n        raise ValueError(f\"Pixel distance type '{self.calculation_type}' is not defined.\")\n\n    return loss\n</code></pre>"},{"location":"reference/DeepSaki/loss/#DeepSaki.loss.image_based_losses.StructuralSimilarityLoss","title":"StructuralSimilarityLoss","text":"<pre><code>StructuralSimilarityLoss(\n    global_batch_size: int,\n    calculation_type: str = \"per_image\",\n    normalize_depth_channel: bool = False,\n    alpha: float = 1.0,\n    beta: float = 1.0,\n    gamma: float = 1.0,\n    c1: float = 0.0001,\n    c2: float = 0.0009,\n    loss_reduction: tf.keras.losses.Reduction = tf.keras.losses.Reduction.AUTO,\n)\n</code></pre> <p>             Bases: <code>tf.keras.losses.Loss</code></p> <p>Calculates the structural similarity (SSIM) loss of two images of the shape (batch, height, width, channels).</p> <p>The structural similarity loss between two images \\(x\\) and \\(y\\) is defined as: \\(\\mathcal{L}_{SSIM}=1-SSIM(x,y)\\).</p> <p>SSIM compares contrast, luminance, and structure of two images using statistical parameters i.e., the mean \\(\\mu\\), the variance \\(\\sigma\\), and the covariance \\(\\sigma_{x,y}\\) of both images. The SSIM of two images \\(x\\) and \\(y\\) is defined as:</p> \\[ SSIM(x,y)= \\underbrace{\\left[ \\frac{2\\mu_x\\mu_y+C_1}{\\mu_x^2+\\mu_y^2 +C_1}\\right]^{\\alpha}}_\\text{contrast} \\cdot \\underbrace{\\left[ \\frac{2\\sigma_x\\sigma_y+C_2}{\\sigma_x^2+\\sigma_y^2 +C_2}\\right]^{\\beta}}_\\text{luminance} \\cdot \\underbrace{\\left[ \\frac{\\sigma_{x,y}+C_3}{\\sigma_x\\sigma_y+C_3}\\right]^{\\gamma}}_\\text{structure}, \\] <p>where \\(\\alpha\\), \\(\\beta\\) and \\(\\gamma\\) are hyperparameters to give relative importance to individual terms and \\(C_1\\), \\(C_2\\) and \\(C_3\\) are constants that must be chosen.</p> <p>Dunder method to initialize <code>StructuralSimilarityLoss</code>.</p> <p>Parameters:</p> Name Type Description Default <code>global_batch_size</code> <code>int</code> <p>Batch size considering all workers running in parallel in a data parallel setup.</p> required <code>calculation_type</code> <code>str</code> <p>Determines how the loss is calculated: [\"per_image\" | \"per_channel\"]. Defaults to \"per_image\".</p> <code>'per_image'</code> <code>normalize_depth_channel</code> <code>bool</code> <p>For RGBD images, the weight of depth is increased by multiplying the depth by the number of color channels. Defaults to False.</p> <code>False</code> <code>alpha</code> <code>float</code> <p>Weighting factor for contrast. Defaults to 1.0.</p> <code>1.0</code> <code>beta</code> <code>float</code> <p>Weighting factor for luminance. Defaults to 1.0.</p> <code>1.0</code> <code>gamma</code> <code>float</code> <p>Weighting factor for structure. Defaults to 1.0.</p> <code>1.0</code> <code>c1</code> <code>float</code> <p>Constant considered in contrast calculation. Defaults to 0.0001.</p> <code>0.0001</code> <code>c2</code> <code>float</code> <p>Constant considered in luminance calculation. Defaults to 0.0009.</p> <code>0.0009</code> <code>loss_reduction</code> <code>tf.keras.losses.Reduction</code> <p>Determines how the loss is reduced. Defaults to tf.keras.losses.Reduction.AUTO.</p> <code>tf.keras.losses.Reduction.AUTO</code> Source code in <code>DeepSaki/loss/image_based_losses.py</code> <pre><code>def __init__(\n    self,\n    global_batch_size: int,\n    calculation_type: str = \"per_image\",\n    normalize_depth_channel: bool = False,\n    alpha: float = 1.0,\n    beta: float = 1.0,\n    gamma: float = 1.0,\n    c1: float = 0.0001,\n    c2: float = 0.0009,\n    loss_reduction: tf.keras.losses.Reduction = tf.keras.losses.Reduction.AUTO,\n) -&gt; None:\n    \"\"\"Dunder method to initialize `StructuralSimilarityLoss`.\n\n    Args:\n        global_batch_size (int): Batch size considering all workers running in parallel in a data parallel setup.\n        calculation_type (str, optional): Determines how the loss is calculated: [\"per_image\" | \"per_channel\"].\n            Defaults to \"per_image\".\n        normalize_depth_channel (bool, optional): For RGBD images, the weight of depth is increased by multiplying\n            the depth by the number of color channels. Defaults to False.\n        alpha (float, optional): Weighting factor for contrast. Defaults to 1.0.\n        beta (float, optional): Weighting factor for luminance. Defaults to 1.0.\n        gamma (float, optional): Weighting factor for structure. Defaults to 1.0.\n        c1 (float, optional): Constant considered in contrast calculation. Defaults to 0.0001.\n        c2 (float, optional): Constant considered in luminance calculation. Defaults to 0.0009.\n        loss_reduction (tf.keras.losses.Reduction, optional): Determines how the loss is reduced. Defaults to\n            tf.keras.losses.Reduction.AUTO.\n    \"\"\"\n    super(StructuralSimilarityLoss, self).__init__(reduction=loss_reduction)\n    self.global_batch_size = global_batch_size\n    self.calculation_type = calculation_type\n    self.normalize_depth_channel = normalize_depth_channel\n    self.alpha = alpha\n    self.beta = beta\n    self.gamma = gamma\n    self.c1 = c1\n    self.c2 = c2\n    self.c3 = c2 / 2\n</code></pre>"},{"location":"reference/DeepSaki/loss/#DeepSaki.loss.image_based_losses.StructuralSimilarityLoss.call","title":"call","text":"<pre><code>call(img1: tf.Tensor, img2: tf.Tensor) -&gt; tf.Tensor\n</code></pre> <p>Calculates the SSIM loss between <code>img1</code> and <code>img2</code>.</p> <p>Parameters:</p> Name Type Description Default <code>img1</code> <code>tf.Tensor</code> <p>Image of shape (<code>batch_size</code>, <code>height</code>, <code>width</code>,<code>channel</code>).</p> required <code>img2</code> <code>tf.Tensor</code> <p>Image of shape (<code>batch_size</code>, <code>height</code>, <code>width</code>,<code>channel</code>).</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>self.calculation_type</code> is not a valid option.</p> <p>Returns:</p> Type Description <code>tf.Tensor</code> <p>Tensor containing the loss value.</p> Source code in <code>DeepSaki/loss/image_based_losses.py</code> <pre><code>def call(self, img1: tf.Tensor, img2: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"Calculates the SSIM loss between `img1` and `img2`.\n\n    Args:\n        img1 (tf.Tensor): Image of shape (`batch_size`, `height`, `width`,`channel`).\n        img2 (tf.Tensor): Image of shape (`batch_size`, `height`, `width`,`channel`).\n\n    Raises:\n        ValueError: if `self.calculation_type` is not a valid option.\n\n    Returns:\n        Tensor containing the loss value.\n    \"\"\"\n    img1 = tf.cast(img1, tf.dtypes.float32)\n    img2 = tf.cast(img2, tf.dtypes.float32)\n    ssim_loss = 0.0\n\n    if self.calculation_type == \"per_image\":\n        ssim_loss = self._calc_ssim_loss(img1, img2)\n    elif self.calculation_type == \"per_channel\":\n        # initialize all weights with 1\n        channel_weight = np.ones(img1.shape[-1])\n        if self.normalize_depth_channel:\n            # set weight of the depth channel according to the number of color channels: e.g. for RGB = 3\n            channel_weight[-1] = len(channel_weight) - 1\n        # loop over all channels of the image\n        for i in range(img1.shape[-1]):\n            ssim_loss += channel_weight[i] * self._calc_ssim_loss(img1[:, :, :, i], img2[:, :, :, i])\n    else:\n        raise ValueError(f\"ssim calculation type '{self.calculation_type}' is not defined\")\n\n    return ssim_loss\n</code></pre>"},{"location":"reference/DeepSaki/models/","title":"models","text":""},{"location":"reference/DeepSaki/models/#DeepSaki.models.discriminators.LayoutContentDiscriminator","title":"LayoutContentDiscriminator","text":"<pre><code>LayoutContentDiscriminator(\n    filters=64,\n    downsampling=\"conv_stride_2\",\n    kernels=3,\n    first_kernel=5,\n    split_kernels=False,\n    number_of_convs=2,\n    activation=\"leaky_relu\",\n    dropout_rate=0.2,\n    use_spec_norm=False,\n    use_bias=True,\n    padding: dsk.layers.PaddingType = dsk.layers.PaddingType.NONE,\n    FullyConected=\"MLP\",\n    useSelfAttention=False,\n    kernel_initializer=dsk.initializers.HeAlphaUniform(),\n    gamma_initializer=dsk.initializers.HeAlphaUniform(),\n)\n</code></pre> <p>             Bases: <code>tf.keras.Model</code></p> <p>Discriminator/critic model with two outputs to enforce disentanglement. First, a layout output with (batch, height, width, 1) that focuses on the inputs layout by reducing its channel depth to 1. Seccond, a content output that discriminates a feature vector with an spatial width of 1. Inspired by: http://arxiv.org/abs/2103.13389 args:   - filters (optional): defines the number of filters to which the input is exposed.   - downsampling(optional): describes the downsampling method   - kernels (optional): size of the kernel for convolutional layers   - first_kernel (optional): The first convolution can have a different kernel size, to e.g. increase the perceptive field, while the channel depth is still low.   - split_kernels (optional): to decrease the number of parameters, a convolution with the kernel_size (kernel,kernel) can be splitted into two consecutive convolutions with the kernel_size (kernel,1) and (1,kernel) respectivly   - number_of_convs (optional): number of consecutive convolutional building blocks, i.e. Conv2DBlock.   - activation (optional): string literal or tensorflow activation function object to obtain activation function   - dropout_rate (optional): probability of the dropout layer. If the preceeding layer has more than one channel, spatial dropout is applied, otherwise standard dropout   - use_spec_norm (optional): applies spectral normalization to convolutional and dense layers   - use_bias (optional): determines whether convolutions and dense layers include a bias or not   - padding (optional): padding type. Options are \"none\", \"zero\" or \"reflection\"   - FullyConected (optional): determines whether 1x1 convolutions are replaced by linear layers, which gives the same result, but linear layers are faster. Option: \"MLP\" or \"1x1_conv\"   - useSelfAttention (optional): Determines whether to apply self-attention after the encoder before branching.   - kernel_initializer (optional): Initialization of the convolutions kernels.   - gamma_initializer (optional): Initialization of the normalization layers.</p> <p>output call():   - out1: content output   - out2: layout output</p> Example <p>import DeepSaki as dsk import tensorflow as tf inputs = tf.keras.layers.Input(shape = (256,256,4)) model = tf.keras.Model(inputs=inputs, outputs=dsk.models.LayoutContentDiscriminator().call(inputs)) model.summary() tf.keras.utils.plot_model(model, show_shapes=True, expand_nested=True, show_dtype=True, to_file='Unet_discriminator_model.png')</p> Source code in <code>DeepSaki/models/discriminators.py</code> <pre><code>def __init__(self,\n          filters = 64,\n          downsampling = \"conv_stride_2\",\n          kernels = 3,\n          first_kernel = 5,\n          split_kernels = False,\n          number_of_convs = 2,\n          activation = \"leaky_relu\",\n          dropout_rate = 0.2,\n          use_spec_norm=False,\n          use_bias = True,\n          padding:dsk.layers.PaddingType=dsk.layers.PaddingType.NONE,\n          FullyConected = \"MLP\",\n          useSelfAttention = False,\n          kernel_initializer = dsk.initializers.HeAlphaUniform(),\n          gamma_initializer =  dsk.initializers.HeAlphaUniform()\n          ):\n  super(LayoutContentDiscriminator, self).__init__()\n  self.encoder = dsk.layers.Encoder(3, filters, 1024, False, downsampling, kernels, split_kernels, number_of_convs,activation, first_kernel,False,channelList=[4*filters,4*filters,8*filters],use_spec_norm=use_spec_norm, padding = padding, use_bias = use_bias, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n  if useSelfAttention:\n      self.SA = dsk.layers.ScalarGatedSelfAttention(use_spec_norm=use_spec_norm, intermediate_channel=None, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n  else:\n    self.SA = None\n\n  if FullyConected == \"MLP\":\n    self.cont1 = dsk.layers.DenseBlock(units = filters * 8, use_spec_norm = use_spec_norm, numberOfLayers = number_of_convs, activation = activation, dropout_rate =dropout_rate, use_bias = use_bias, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n    self.cont2 = dsk.layers.DenseBlock(units = filters * 8, use_spec_norm = use_spec_norm, numberOfLayers = number_of_convs, activation = activation, dropout_rate =dropout_rate, use_bias = use_bias, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n    self.cont3 = dsk.layers.DenseBlock(units = filters * 8, use_spec_norm = use_spec_norm, numberOfLayers = number_of_convs, activation = activation, dropout_rate =0, final_activation=False, apply_final_normalization = False, use_bias = use_bias, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n  elif FullyConected == \"1x1_conv\":\n    self.cont1 = dsk.layers.Conv2DBlock(filters=filters * 8, kernels = 1, activation = activation, split_kernels = split_kernels,number_of_convs=number_of_convs, use_residual_Conv2DBlock=False,dropout_rate=dropout_rate,use_spec_norm=use_spec_norm, padding=padding,use_bias = use_bias, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n    self.cont2 = dsk.layers.Conv2DBlock(filters=filters * 8, kernels = 1, activation = activation, split_kernels = split_kernels,number_of_convs=number_of_convs, use_residual_Conv2DBlock=False,dropout_rate=dropout_rate,use_spec_norm=use_spec_norm, padding=padding,use_bias = use_bias, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n    self.cont3 = dsk.layers.Conv2DBlock(filters=filters * 8, kernels = 1, activation = activation, split_kernels = split_kernels,number_of_convs=number_of_convs, use_residual_Conv2DBlock=False,dropout_rate=0,use_spec_norm=use_spec_norm, final_activation=False, apply_final_normalization = False, padding=padding,use_bias = use_bias, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n  else:\n    raise Exception(\"FullyConected:{} is not defined\".format(FullyConected))\n\n  self.lay1 = dsk.layers.Conv2DBlock(filters=1, kernels = kernels, activation = activation, split_kernels = split_kernels,number_of_convs=number_of_convs, use_residual_Conv2DBlock=False,dropout_rate=0,use_spec_norm=use_spec_norm, padding=padding, use_bias = use_bias, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n  self.lay2 = dsk.layers.Conv2DBlock(filters=1, kernels = kernels, activation = activation, split_kernels = split_kernels,number_of_convs=number_of_convs, use_residual_Conv2DBlock=False,dropout_rate=dropout_rate,use_spec_norm=use_spec_norm, padding=padding,use_bias = use_bias, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n  self.lay3 = dsk.layers.Conv2DBlock(filters=1, kernels = kernels, activation = activation, split_kernels = split_kernels,number_of_convs=number_of_convs, use_residual_Conv2DBlock=False,dropout_rate=dropout_rate,use_spec_norm=use_spec_norm, padding=padding,use_bias = use_bias, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n  self.lay4 = dsk.layers.Conv2DBlock(filters=1, kernels = kernels, activation = activation, split_kernels = split_kernels,number_of_convs=number_of_convs, use_residual_Conv2DBlock=False,dropout_rate=0,use_spec_norm=use_spec_norm,final_activation=False, apply_final_normalization = False, padding=padding,use_bias = use_bias, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n  #To enable mixed precission support for matplotlib and distributed training and to increase training stability\n  self.linear_dtype = tf.keras.layers.Activation(\"linear\", dtype = tf.float32)\n</code></pre>"},{"location":"reference/DeepSaki/models/#DeepSaki.models.discriminators.PatchDiscriminator","title":"PatchDiscriminator","text":"<pre><code>PatchDiscriminator(\n    filters=64,\n    downsampling=\"average_pooling\",\n    kernels=3,\n    first_kernel=5,\n    split_kernels=False,\n    number_of_convs=2,\n    activation=\"leaky_relu\",\n    num_down_blocks=3,\n    dropout_rate=0.2,\n    use_spec_norm=False,\n    use_bias=True,\n    useSelfAttention=False,\n    padding: dsk.layers.PaddingType = dsk.layers.PaddingType.NONE,\n    kernel_initializer=dsk.initializers.HeAlphaUniform(),\n    gamma_initializer=dsk.initializers.HeAlphaUniform(),\n)\n</code></pre> <p>             Bases: <code>tf.keras.Model</code></p> <p>Discriminator/critic model with patched output. args:   - filters (optional): defines the number of filters to which the input is exposed.   - downsampling(optional): describes the downsampling method   - kernels (optional): size of the kernel for convolutional layers   - first_kernel (optional): The first convolution can have a different kernel size, to e.g. increase the perceptive field, while the channel depth is still low.   - split_kernels (optional): to decrease the number of parameters, a convolution with the kernel_size (kernel,kernel) can be splitted into two consecutive convolutions with the kernel_size (kernel,1) and (1,kernel) respectivly   - number_of_convs (optional): number of consecutive convolutional building blocks, i.e. Conv2DBlock.   - activation (optional): string literal or tensorflow activation function object to obtain activation function   - num_down_blocks (optional): Number of downsampling blocks in the encoder   - dropout_rate (optional): probability of the dropout layer. If the preceeding layer has more than one channel, spatial dropout is applied, otherwise standard dropout   - use_spec_norm (optional): applies spectral normalization to convolutional and dense layers   - use_bias (optional): determines whether convolutions and dense layers include a bias or not   - padding (optional): padding type. Options are \"none\", \"zero\" or \"reflection\"   - useSelfAttention (optional): Determines whether to apply self-attention after the encoder before branching.   - kernel_initializer (optional): Initialization of the convolutions kernels.   - gamma_initializer (optional): Initialization of the normalization layers.</p> <p>output call():   - out1: content output   - out2: layout output</p> Example <p>import DeepSaki as dsk import tensorflow as tf inputs = tf.keras.layers.Input(shape = (256,256,4)) model = tf.keras.Model(inputs=inputs, outputs=dsk.models.PatchDiscriminator().call(inputs)) model.summary() tf.keras.utils.plot_model(model, show_shapes=True, expand_nested=True, show_dtype=True, to_file='PatchDiscriminator_model.png')</p> Source code in <code>DeepSaki/models/discriminators.py</code> <pre><code>def __init__(self,\n          filters = 64,\n          downsampling = \"average_pooling\",\n          kernels = 3,\n          first_kernel = 5,\n          split_kernels = False,\n          number_of_convs = 2,\n          activation = \"leaky_relu\",\n          num_down_blocks = 3,\n          dropout_rate = 0.2,\n          use_spec_norm= False,\n          use_bias = True,\n          useSelfAttention=False,\n          padding:dsk.layers.PaddingType=dsk.layers.PaddingType.NONE,\n          kernel_initializer = dsk.initializers.HeAlphaUniform(),\n          gamma_initializer =  dsk.initializers.HeAlphaUniform()\n          ):\n  super(PatchDiscriminator, self).__init__()\n\n  self.encoder = dsk.layers.Encoder(number_of_levels=num_down_blocks, filters=filters, limit_filters=512, use_residual_Conv2DBlock=False, downsampling=downsampling, kernels=kernels, split_kernels=split_kernels,number_of_convs=number_of_convs,activation=activation,first_kernel=first_kernel,use_spec_norm=use_spec_norm,useSelfAttention=useSelfAttention, use_bias = use_bias,padding = padding, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n  self.conv1 = dsk.layers.Conv2DBlock(filters = filters * (2**(num_down_blocks)), use_residual_Conv2DBlock = False, kernels = kernels, split_kernels = split_kernels, number_of_convs = number_of_convs, activation = activation,dropout_rate=dropout_rate,use_spec_norm=use_spec_norm, use_bias = use_bias,padding = padding, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n  self.conv2 = dsk.layers.Conv2DBlock(filters = 1,use_residual_Conv2DBlock = False, kernels = 5, split_kernels  = False, number_of_convs = 1, activation = None,use_spec_norm=use_spec_norm, apply_final_normalization = False, use_bias = use_bias,padding = padding, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n  #To enable mixed precission support for matplotlib and distributed training and to increase training stability\n  self.linear_dtype = tf.keras.layers.Activation(\"linear\", dtype = tf.float32)\n</code></pre>"},{"location":"reference/DeepSaki/models/#DeepSaki.models.discriminators.UNetDiscriminator","title":"UNetDiscriminator","text":"<pre><code>UNetDiscriminator(\n    number_of_levels,\n    upsampling=\"transpose_conv\",\n    downsampling=\"average_pooling\",\n    kernels=3,\n    first_kernel=5,\n    split_kernels=False,\n    number_of_convs=2,\n    activation=\"leaky_relu\",\n    use_residual_Conv2DBlock=False,\n    useResidualIdentityBlock=False,\n    residual_cardinality=1,\n    limit_filters=512,\n    n_bottleneck_blocks=1,\n    filters=64,\n    dropout_rate=0.2,\n    useSelfAttention=False,\n    use_spec_norm=False,\n    use_bias=True,\n    FullyConected=\"MLP\",\n    padding: dsk.layers.PaddingType = dsk.layers.PaddingType.ZERO,\n    kernel_initializer=dsk.initializers.HeAlphaUniform(),\n    gamma_initializer=dsk.initializers.HeAlphaUniform(),\n)\n</code></pre> <p>             Bases: <code>tf.keras.Model</code></p> <p>U-Net based discriminator model with skip conections between encoder and decoder and two outputs; after the bottleneck and after the decoder.   inspired by Sch\u00f6nfeld et. al. http://arxiv.org/abs/2002.12655   args:   - number_of_levels (optional): number of down and apsampling levels of the model   - upsampling (optional): describes the upsampling method used   - downsampling (optional): describes the downsampling method - kernels (optional): size of the convolutions kernels - first_kernel (optional): The first convolution can have a different kernel size, to e.g. increase the perceptive field, while the channel depth is still low. - split_kernels (optional): to decrease the number of parameters, a convolution with the kernel_size (kernel,kernel) can be splitted into two consecutive convolutions with the kernel_size (kernel,1) and (1,kernel) respectivly   - number_of_convs (optional): number of consecutive convolutional building blocks, i.e. Conv2DBlock.   - activation (optional): string literal or tensorflow activation function object to obtain activation function   - use_residual_Conv2DBlock (optional): ads a residual connection in parallel to the Conv2DBlock   - useResidualIdentityBlock (optional): Whether or not to use the ResidualIdentityBlock instead of the Conv2DBlock   - residual_cardinality (optional): cardinality for the ResidualIdentityBlock   - limit_filters (optional): limits the number of filters, which is doubled with every downsampling block   - n_bottleneck_blocks (optional): Number of consecutive convolution blocks in the bottleneck   - filters (optional): defines the number of filters to which the input is exposed.   - dropout_rate (optional): probability of the dropout layer. If the preceeding layer has more than one channel, spatial dropout is applied, otherwise standard dropout   - useSelfAttention (optional): Determines whether to apply self-attention in the decoder.   - use_spec_norm (optional): applies spectral normalization to convolutional and dense layers   - use_bias (optional): determines whether convolutions and dense layers include a bias or not   - FullyConected (optional): determines whether 1x1 convolutions are replaced by linear layers, which gives the same result, but linear layers are faster. Option: \"MLP\" or \"1x1_conv\"   - padding (optional): padding type. Options are \"none\", \"zero\" or \"reflection\"   - kernel_initializer (optional): Initialization of the convolutions kernels.   - gamma_initializer (optional): Initialization of the normalization layers.</p> <p>Input Shape:     (batch, height, width, channel)</p> <p>Output Shape:     out1: (batch, 1)     out2: (batch, height, width, 1)</p> <p>Example:     &gt;&gt;&gt; import DeepSaki as dsk     &gt;&gt;&gt; import tensorflow as tf     &gt;&gt;&gt; inputs = tf.keras.layers.Input(shape = (256,256,4))     &gt;&gt;&gt; model = tf.keras.Model(inputs=inputs, outputs=dsk.models.UNetDiscriminator(5).call(inputs))     &gt;&gt;&gt; model.summary()     &gt;&gt;&gt; tf.keras.utils.plot_model(model, show_shapes=True, expand_nested=True, show_dtype=True, to_file='Unet_discriminator_model.png')</p> Source code in <code>DeepSaki/models/discriminators.py</code> <pre><code>def __init__(self,\n          number_of_levels,\n          upsampling = \"transpose_conv\",\n          downsampling = \"average_pooling\",\n          kernels = 3,\n          first_kernel = 5,\n          split_kernels = False,\n          number_of_convs = 2,\n          activation = \"leaky_relu\",\n          use_residual_Conv2DBlock = False,\n          useResidualIdentityBlock = False,\n          residual_cardinality = 1,\n          limit_filters = 512,\n          n_bottleneck_blocks = 1,\n          filters = 64,\n          dropout_rate = 0.2,\n          useSelfAttention=False,\n          use_spec_norm=False,\n          use_bias = True,\n          FullyConected = \"MLP\",\n          padding:dsk.layers.PaddingType=dsk.layers.PaddingType.ZERO,\n          kernel_initializer = dsk.initializers.HeAlphaUniform(),\n          gamma_initializer =  dsk.initializers.HeAlphaUniform()\n          ):\n  super(UNetDiscriminator, self).__init__()\n  ch = filters\n  self.encoder = dsk.layers.Encoder(number_of_levels=number_of_levels, filters=filters, limit_filters=limit_filters, use_residual_Conv2DBlock=use_residual_Conv2DBlock, downsampling=downsampling, kernels=kernels, split_kernels=split_kernels, number_of_convs=number_of_convs,activation=activation, first_kernel=first_kernel, useResidualIdentityBlock=useResidualIdentityBlock, channelList=[ch,2*ch,4*ch,8*ch,8*ch], use_spec_norm=use_spec_norm,useSelfAttention=useSelfAttention,outputSkips=True, use_bias = use_bias,residual_cardinality=residual_cardinality,padding = padding, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n  self.bottleNeck = dsk.layers.Bottleneck(useResidualIdentityBlock=useResidualIdentityBlock, n_bottleneck_blocks=n_bottleneck_blocks,use_residual_Conv2DBlock=use_residual_Conv2DBlock, kernels=kernels, split_kernels=split_kernels,number_of_convs=number_of_convs, activation = activation,dropout_rate=dropout_rate, channelList=[16*ch], use_spec_norm=use_spec_norm, use_bias = use_bias,residual_cardinality=residual_cardinality,padding = padding, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n  self.decoder = dsk.layers.Decoder(number_of_levels=number_of_levels, upsampling=upsampling, filters=filters, limit_filters=limit_filters, use_residual_Conv2DBlock=use_residual_Conv2DBlock, kernels=kernels, split_kernels=split_kernels,number_of_convs=number_of_convs,activation=activation,dropout_rate=dropout_rate, useResidualIdentityBlock=useResidualIdentityBlock, channelList=[8*ch,8*ch,4*ch,2*ch,ch], use_spec_norm=use_spec_norm, use_bias = use_bias,residual_cardinality=residual_cardinality,padding = padding, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer,enableSkipConnectionsInput=True)\n  if FullyConected == \"MLP\":\n    self.img_reconstruction = dsk.layers.DenseBlock(units = 1, use_spec_norm = use_spec_norm, numberOfLayers = 1, activation = None, apply_final_normalization = False, use_bias = use_bias, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n  elif FullyConected == \"1x1_conv\":\n    self.img_reconstruction =dsk.layers.Conv2DBlock(filters = 1, use_residual_Conv2DBlock = False, kernels = 1, split_kernels  = False, number_of_convs = 1, activation = None,use_spec_norm=use_spec_norm, apply_final_normalization = False, use_bias = use_bias,padding = padding, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n  self.linear = dsk.layers.DenseBlock(units = 1, use_spec_norm = use_spec_norm, numberOfLayers = 1, activation = None, apply_final_normalization = False, use_bias = use_bias, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n  #To enable mixed precission support for matplotlib and distributed training and to increase training stability\n  self.linear_dtype = tf.keras.layers.Activation(\"linear\", dtype = tf.float32)\n</code></pre>"},{"location":"reference/DeepSaki/models/#DeepSaki.models.autoencoders.ResNet","title":"ResNet","text":"<pre><code>ResNet(\n    input_shape,\n    number_of_levels=3,\n    filters=64,\n    split_kernels=False,\n    kernels=3,\n    first_kernel=5,\n    number_of_convs=2,\n    activation=\"leaky_relu\",\n    final_activation=\"hard_sigmoid\",\n    use_residual_Conv2DBlock=False,\n    useResidualIdentityBlock=True,\n    residual_cardinality=32,\n    limit_filters=512,\n    n_bottleneck_blocks=5,\n    upsampling=\"transpose_conv\",\n    downsampling=\"average_pooling\",\n    dropout_rate=0.2,\n    use_spec_norm=False,\n    use_bias=True,\n    useSelfAttention=False,\n    FullyConected=\"MLP\",\n    padding: dsk.layers.PaddingType = dsk.layers.PaddingType.ZERO,\n    kernel_initializer=dsk.initializers.HeAlphaUniform(),\n    gamma_initializer=dsk.initializers.HeAlphaUniform(),\n)\n</code></pre> <p>             Bases: <code>tf.keras.Model</code></p> <p>ResNet model in autoencoder architecture (encoder, bottleneck, decoder). Input_shape = Output_shape args: - input_shape: Shape of the input data. E.g. (batch, height, width, channel) - number_of_levels (optional): number of down and apsampling levels of the model - filters (optional): defines the number of filters to which the input is exposed. - split_kernels (optional): to decrease the number of parameters, a convolution with the kernel_size (kernel,kernel) can be splitted into two consecutive convolutions with the kernel_size (kernel,1) and (1,kernel) respectivly - kernels (optional): size of the convolutions kernels - first_kernel (optional): The first convolution can have a different kernel size, to e.g. increase the perceptive field, while the channel depth is still low. - number_of_convs (optional): number of consecutive convolutional building blocks, i.e. Conv2DBlock. - activation (optional): string literal or tensorflow activation function object to obtain activation function - final_activation (optional): string literal or tensorflow activation function object to obtain activation function for the model's output activation - use_residual_Conv2DBlock (optional): ads a residual connection in parallel to the Conv2DBlock - useResidualIdentityBlock (optional): Whether or not to use the ResidualIdentityBlock instead of the Conv2DBlock - residual_cardinality (optional): cardinality for the ResidualIdentityBlock - limit_filters (optional): limits the number of filters, which is doubled with every downsampling block - n_bottleneck_blocks (optional): Number of consecutive convolution blocks in the bottleneck - upsampling(optional): describes the upsampling method used - downsampling(optional): describes the downsampling method - dropout_rate (optional): probability of the dropout layer. If the preceeding layer has more than one channel, spatial dropout is applied, otherwise standard dropout - use_spec_norm (optional): applies spectral normalization to convolutional and dense layers - use_bias (optional): determines whether convolutions and dense layers include a bias or not - useSelfAttention (optional): Determines whether to apply self-attention in the decoder. - FullyConected (optional): determines whether 1x1 convolutions are replaced by linear layers, which gives the same result, but linear layers are faster. Option: \"MLP\" or \"1x1_conv\" - padding (optional): padding type. Options are \"none\", \"zero\" or \"reflection\" - kernel_initializer (optional): Initialization of the convolutions kernels. - gamma_initializer (optional): Initialization of the normalization layers.</p> Input Shape <p>(batch, height, width, channel)</p> Output Shape <p>(batch, height, width, channel)</p> Example <p>import DeepSaki as dsk import tensorflow as tf inputs = tf.keras.layers.Input(shape = (256,256,4)) model = tf.keras.Model(inputs=inputs, outputs=dsk.model.ResNet((256,256,4), 5,residual_cardinality=1).call(inputs)) model.summary() tf.keras.utils.plot_model(model, show_shapes=True, expand_nested=True, show_dtype=True, to_file='ResNet_model.png')</p> Source code in <code>DeepSaki/models/autoencoders.py</code> <pre><code>def __init__(self,\n          input_shape,\n          number_of_levels = 3,\n          filters=64,\n          split_kernels = False,\n          kernels = 3,\n          first_kernel = 5,\n          number_of_convs = 2,\n          activation = \"leaky_relu\",\n          final_activation = \"hard_sigmoid\",\n          use_residual_Conv2DBlock = False,\n          useResidualIdentityBlock = True,\n          residual_cardinality = 32,\n          limit_filters = 512,\n          n_bottleneck_blocks = 5,\n          upsampling = \"transpose_conv\",\n          downsampling = \"average_pooling\",\n          dropout_rate = 0.2,\n          use_spec_norm=False,\n          use_bias = True,\n          useSelfAttention= False,\n          FullyConected = \"MLP\",\n          padding:dsk.layers.PaddingType=dsk.layers.PaddingType.ZERO,\n          kernel_initializer = dsk.initializers.HeAlphaUniform(),\n          gamma_initializer =  dsk.initializers.HeAlphaUniform()\n          ):\n  super(ResNet, self).__init__()\n\n  self.encoder = dsk.layers.Encoder(number_of_levels=number_of_levels, filters=filters, limit_filters=limit_filters, use_residual_Conv2DBlock=use_residual_Conv2DBlock, downsampling=downsampling, kernels=kernels, split_kernels=split_kernels, number_of_convs=number_of_convs,activation=activation, first_kernel=first_kernel,useResidualIdentityBlock=useResidualIdentityBlock,use_spec_norm=use_spec_norm, use_bias = use_bias, residual_cardinality=residual_cardinality,padding = padding, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n  self.bottleNeck = dsk.layers.Bottleneck(useResidualIdentityBlock=useResidualIdentityBlock, n_bottleneck_blocks=n_bottleneck_blocks,use_residual_Conv2DBlock=use_residual_Conv2DBlock, kernels=kernels, split_kernels=split_kernels,number_of_convs=number_of_convs , activation = activation,dropout_rate=dropout_rate,use_spec_norm=use_spec_norm, use_bias = use_bias, residual_cardinality=residual_cardinality,padding = padding, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n  self.decoder = dsk.layers.Decoder(number_of_levels=number_of_levels, upsampling=upsampling, filters=filters, limit_filters=limit_filters, use_residual_Conv2DBlock=use_residual_Conv2DBlock, kernels=kernels, split_kernels=split_kernels,number_of_convs=number_of_convs,activation=activation,dropout_rate=dropout_rate, useResidualIdentityBlock=useResidualIdentityBlock,use_spec_norm=use_spec_norm,useSelfAttention=useSelfAttention, use_bias = use_bias, residual_cardinality=residual_cardinality,padding = padding, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n  if FullyConected == \"MLP\":\n    self.img_reconstruction = dsk.layers.DenseBlock(units = input_shape[-1], use_spec_norm = use_spec_norm, numberOfLayers = 1, activation = final_activation, apply_final_normalization = False, use_bias = use_bias, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n  elif FullyConected == \"1x1_conv\":\n    self.img_reconstruction = dsk.layers.Conv2DBlock(filters = input_shape[-1],use_residual_Conv2DBlock = False, kernels = 1, split_kernels  = False, number_of_convs = 1, activation = final_activation, use_spec_norm=use_spec_norm, apply_final_normalization = False,use_bias = use_bias,padding = padding, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n  #To enable mixed precission support for matplotlib and distributed training and to increase training stability\n  self.linear_dtype = tf.keras.layers.Activation(\"linear\", dtype = tf.float32)\n</code></pre>"},{"location":"reference/DeepSaki/models/#DeepSaki.models.autoencoders.UNet","title":"UNet","text":"<pre><code>UNet(\n    input_shape,\n    number_of_levels=3,\n    upsampling=\"transpose_conv\",\n    downsampling=\"conv_stride_2\",\n    final_activation=\"hard_sigmoid\",\n    filters=64,\n    kernels=3,\n    first_kernel=5,\n    split_kernels=False,\n    number_of_convs=2,\n    activation=\"leaky_relu\",\n    limit_filters=512,\n    use_residual_Conv2DBlock=False,\n    useResidualIdentityBlock=False,\n    residual_cardinality=1,\n    n_bottleneck_blocks=1,\n    dropout_rate=0.2,\n    use_spec_norm=False,\n    use_bias=True,\n    useSelfAttention=False,\n    omit_skips=0,\n    FullyConected=\"MLP\",\n    padding: dsk.layers.PaddingType = dsk.layers.PaddingType.ZERO,\n    kernel_initializer=dsk.initializers.HeAlphaUniform(),\n    gamma_initializer=dsk.initializers.HeAlphaUniform(),\n)\n</code></pre> <p>             Bases: <code>tf.keras.Model</code></p> <p>U-Net model with skip conections between encoder and decoder. Input_shape = Output_shape args: - input_shape: Shape of the input data. E.g. (batch, height, width, channel) - number_of_levels (optional): number of down and apsampling levels of the model - upsampling (optional): describes the upsampling method used - downsampling (optional): describes the downsampling method - final_activation (optional): string literal or tensorflow activation function object to obtain activation function for the model's output activation - filters (optional): defines the number of filters to which the input is exposed. - kernels (optional): size of the convolutions kernels - first_kernel (optional): The first convolution can have a different kernel size, to e.g. increase the perceptive field, while the channel depth is still low. - useResidualIdentityBlock (optional): Whether or not to use the ResidualIdentityBlock instead of the Conv2DBlock - split_kernels (optional): to decrease the number of parameters, a convolution with the kernel_size (kernel,kernel) can be splitted into two consecutive convolutions with the kernel_size (kernel,1) and (1,kernel) respectivly - number_of_convs (optional): number of consecutive convolutional building blocks, i.e. Conv2DBlock. - activation (optional): string literal or tensorflow activation function object to obtain activation function - limit_filters (optional): limits the number of filters, which is doubled with every downsampling block - use_residual_Conv2DBlock (optional): ads a residual connection in parallel to the Conv2DBlock - useResidualIdentityBlock (optional): Whether or not to use the ResidualIdentityBlock instead of the Conv2DBlock - residual_cardinality (optional): cardinality for the ResidualIdentityBlock - n_bottleneck_blocks (optional): Number of consecutive convolution blocks in the bottleneck - dropout_rate (optional): probability of the dropout layer. If the preceeding layer has more than one channel, spatial dropout is applied, otherwise standard dropout - use_spec_norm (optional): applies spectral normalization to convolutional and dense layers - use_bias (optional): determines whether convolutions and dense layers include a bias or not - useSelfAttention (optional): Determines whether to apply self-attention in the decoder. - omit_skips (optional): defines how many layers should not output a skip connection output. Requires outputSkips to be True. E.g. if omit_skips = 2, the first two levels do not output a skip connection, it starts at level 3. - FullyConected (optional): determines whether 1x1 convolutions are replaced by linear layers, which gives the same result, but linear layers are faster. Option: \"MLP\" or \"1x1_conv\" - padding (optional): padding type. Options are \"none\", \"zero\" or \"reflection\" - kernel_initializer (optional): Initialization of the convolutions kernels. - gamma_initializer (optional): Initialization of the normalization layers.</p> Input Shape <p>(batch, height, width, channel)</p> Output Shape <p>(batch, height, width, channel)</p> Example <p>import DeepSaki as dsk import tensorflow as tf inputs = tf.keras.layers.Input(shape = (256,256,4)) model = tf.keras.Model(inputs=inputs, outputs=dsk.model.UNet((256,256,4),5).call(inputs)) model.summary() tf.keras.utils.plot_model(model, show_shapes=True, expand_nested=True, show_dtype=True, to_file='Unet_model.png')</p> Source code in <code>DeepSaki/models/autoencoders.py</code> <pre><code>def __init__(self,\n          input_shape,\n          number_of_levels = 3,\n          upsampling = \"transpose_conv\",\n          downsampling = \"conv_stride_2\",\n          final_activation = \"hard_sigmoid\",\n          filters = 64,\n          kernels = 3,\n          first_kernel = 5,\n          split_kernels = False,\n          number_of_convs = 2,\n          activation = \"leaky_relu\",\n          limit_filters = 512,\n          use_residual_Conv2DBlock = False,\n          useResidualIdentityBlock = False,\n          residual_cardinality = 1,\n          n_bottleneck_blocks = 1,\n          dropout_rate = 0.2,\n          use_spec_norm = False,\n          use_bias = True,\n          useSelfAttention=False,\n          omit_skips = 0,\n          FullyConected = \"MLP\",\n          padding:dsk.layers.PaddingType=dsk.layers.PaddingType.ZERO,\n          kernel_initializer = dsk.initializers.HeAlphaUniform(),\n          gamma_initializer =  dsk.initializers.HeAlphaUniform()\n          ):\n  super(UNet, self).__init__()\n\n  self.encoder = dsk.layers.Encoder(number_of_levels=number_of_levels, filters=filters, limit_filters=limit_filters, use_residual_Conv2DBlock=use_residual_Conv2DBlock, downsampling=downsampling, kernels=kernels, split_kernels=split_kernels, number_of_convs=number_of_convs,activation=activation, first_kernel=first_kernel,useResidualIdentityBlock=useResidualIdentityBlock,use_spec_norm=use_spec_norm, omit_skips=omit_skips, outputSkips=True, use_bias = use_bias, residual_cardinality=residual_cardinality,padding = padding, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n  self.bottleNeck = dsk.layers.Bottleneck(useResidualIdentityBlock=useResidualIdentityBlock, n_bottleneck_blocks=n_bottleneck_blocks,use_residual_Conv2DBlock=use_residual_Conv2DBlock, kernels=kernels, split_kernels=split_kernels,number_of_convs=number_of_convs,activation = activation, dropout_rate=dropout_rate, use_spec_norm=use_spec_norm, use_bias = use_bias, residual_cardinality=residual_cardinality,padding = padding, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n  self.decoder = dsk.layers.Decoder(number_of_levels=number_of_levels, upsampling=upsampling, filters=filters, limit_filters=limit_filters, use_residual_Conv2DBlock=use_residual_Conv2DBlock, kernels=kernels, split_kernels=split_kernels,number_of_convs=number_of_convs,activation=activation,dropout_rate=dropout_rate, useResidualIdentityBlock=useResidualIdentityBlock,use_spec_norm=use_spec_norm,useSelfAttention=useSelfAttention, use_bias = use_bias, residual_cardinality=residual_cardinality,padding = padding, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer,enableSkipConnectionsInput=True)\n  if FullyConected == \"MLP\":\n    self.img_reconstruction = dsk.layers.DenseBlock(units = input_shape[-1], use_spec_norm = use_spec_norm, numberOfLayers = 1, activation = final_activation, apply_final_normalization = False, use_bias = use_bias, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n  elif FullyConected == \"1x1_conv\":\n    self.img_reconstruction = dsk.layers.Conv2DBlock(filters = input_shape[-1],use_residual_Conv2DBlock = False, kernels = 1, split_kernels  = False, number_of_convs = 1, activation = final_activation, use_spec_norm=use_spec_norm, apply_final_normalization = False, use_bias = use_bias,padding = padding, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n  #To enable mixed precission support for matplotlib and distributed training and to increase training stability\n  self.linear_dtype = tf.keras.layers.Activation(\"linear\", dtype = tf.float32)\n</code></pre>"},{"location":"reference/DeepSaki/optimizer/","title":"optimizer","text":""},{"location":"reference/DeepSaki/utils/","title":"utils","text":"<p>Collection of methods for setting-up the compute environment.</p> Tips <ul> <li>Overview on distributed training with TensorFlow.</li> <li>Tutorial of using tf.distrubute on custom     training.</li> </ul>"},{"location":"reference/DeepSaki/utils/#DeepSaki.utils.environment.detect_accelerator","title":"detect_accelerator","text":"<pre><code>detect_accelerator(\n    gpu_memory_groth: bool = False,\n) -&gt; Tuple[\n    tf.distribute.Strategy,\n    str,\n    Optional[\n        Union[\n            tf.distribute.cluster_resolver.TPUClusterResolver,\n            List[tf.config.LogicalDevice],\n        ]\n    ],\n]\n</code></pre> <p>Detects the availability of TPUs and GPUs and connects to all available devices.</p> <p>Parameters:</p> Name Type Description Default <code>gpu_memory_groth</code> <code>bool</code> <p>If true, memory is allocated on demand. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>tf.distribute.Strategy</code> <p><code>strategy</code>: pointer to the distribution strategy configuration object</p> <code>str</code> <p><code>runtime_environment</code>: Info string describing the HW that might be used for conditions, i.e. \"TPU, \"GPU\", \"CPU\"</p> <code>Optional[Union[tf.distribute.cluster_resolver.TPUClusterResolver, List[tf.config.LogicalDevice]]]</code> <p><code>hw_accelerator_handle</code>: pointer to the HW accelerator</p> Source code in <code>DeepSaki/utils/environment.py</code> <pre><code>def detect_accelerator(\n    gpu_memory_groth: bool = False,\n) -&gt; Tuple[\n    tf.distribute.Strategy,\n    str,\n    Optional[Union[tf.distribute.cluster_resolver.TPUClusterResolver, List[tf.config.LogicalDevice]]],\n]:\n    \"\"\"Detects the availability of TPUs and GPUs and connects to all available devices.\n\n    Args:\n        gpu_memory_groth (bool, optional): If true, memory is allocated on demand. Defaults to False.\n\n    Returns:\n        `strategy`: pointer to the distribution strategy configuration object\n        `runtime_environment`: Info string describing the HW that might be used for conditions, i.e. \"TPU, \"GPU\", \"CPU\"\n        `hw_accelerator_handle`: pointer to the HW accelerator\n    \"\"\"\n    hw_accelerator_handle = None\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n        hw_accelerator_handle = tpu\n    except ValueError:\n        tpu = None\n        if gpu_memory_groth:\n            for gpu in tf.config.experimental.list_physical_devices(\"GPU\"):\n                tf.config.experimental.set_memory_growth(gpu, True)\n        gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n        hw_accelerator_handle = gpus\n\n    # Select appropriate distribution strategy\n    if tpu:\n        runtime_environment = \"TPU\"\n        tf.config.experimental_connect_to_cluster(tpu)\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        strategy = tf.distribute.TPUStrategy(\n            tpu\n        )  # Going back and forth between TPU and host is expensive. Better to run 128 batches on the TPU before reporting back.\n        print(\"Running on TPU \", tpu.cluster_spec().as_dict()[\"worker\"])\n    elif len(gpus) &gt; 1:\n        runtime_environment = \"GPU\"\n        strategy = tf.distribute.MirroredStrategy([gpu.name for gpu in gpus])\n        print(\"Running on multiple GPUs \", [gpu.name for gpu in gpus])\n    elif len(gpus) == 1:\n        runtime_environment = \"GPU\"\n        strategy = tf.distribute.get_strategy()  # default strategy that works on CPU and single GPU\n        print(\"Running on single GPU \", gpus[0].name)\n    else:\n        runtime_environment = \"CPU\"\n        strategy = tf.distribute.get_strategy()  # default strategy that works on CPU and single GPU\n        print(\"Running on CPU\")\n\n    print(\"Number of accelerators: \", strategy.num_replicas_in_sync)\n    print(\"____________________________________________________________________________________\")\n    print(\"Device List: \")\n    print(device_lib.list_local_devices())\n\n    return strategy, runtime_environment, hw_accelerator_handle\n</code></pre>"},{"location":"reference/DeepSaki/utils/#DeepSaki.utils.environment.enable_mixed_precision","title":"enable_mixed_precision","text":"<pre><code>enable_mixed_precision() -&gt; None\n</code></pre> <p>Set mixed precission policy depending on the available HW accelerator. TPU:<code>mixed_bfloat16</code>. GPU:<code>mixed_float16</code>.</p> Source code in <code>DeepSaki/utils/environment.py</code> <pre><code>def enable_mixed_precision() -&gt; None:\n    \"\"\"Set mixed precission policy depending on the available HW accelerator. TPU:`mixed_bfloat16`. GPU:`mixed_float16`.\"\"\"\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n    except ValueError:\n        tpu = None\n\n    policy_config = \"mixed_bfloat16\" if tpu else \"mixed_float16\"\n    policy = tf.keras.mixed_precision.Policy(policy_config)\n    tf.keras.mixed_precision.set_global_policy(policy)\n    print(\"Mixed precision enabled to {}\".format(policy_config))\n</code></pre>"},{"location":"reference/DeepSaki/utils/#DeepSaki.utils.environment.enable_xla_acceleration","title":"enable_xla_acceleration","text":"<pre><code>enable_xla_acceleration() -&gt; None\n</code></pre> <p>Enable compiler acceleration for linear algebra operations.</p> Source code in <code>DeepSaki/utils/environment.py</code> <pre><code>def enable_xla_acceleration() -&gt; None:\n    \"\"\"Enable compiler acceleration for linear algebra operations.\"\"\"\n    tf.config.optimizer.set_jit(True)\n    print(\"Linear algebra acceleration enabled\")\n</code></pre>"}]}