{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"DeepSaki","text":"<p>Custom deep learning package for TensorFlow by Sascha Kirch.</p>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>DeepSaki<ul> <li>activations</li> <li>augmentations</li> <li>constraints</li> <li>initializers</li> <li>layers</li> <li>losses</li> <li>models</li> <li>optimizers</li> <li>utils</li> </ul> </li> </ul>"},{"location":"reference/DeepSaki/activations/","title":"activations","text":"<p>Activation functions applicable to complex-valued and real-valued inputs.</p>"},{"location":"reference/DeepSaki/activations/#DeepSaki.activations.complex_valued_activations.ComplexActivation","title":"ComplexActivation","text":"<pre><code>ComplexActivation(\n    activation: tf.keras.layers.Layer, **kwargs: Any\n)\n</code></pre> <p>             Bases: <code>tf.keras.layers.Layer</code></p> <p>Wrapper to apply a given <code>activation</code> to a complex input individually for the real and imaginary part.</p> Inherits from <p>tf.keras.layers.Layer</p> <p>Initialize ComplexActivation.</p> <p>Parameters:</p> Name Type Description Default <code>activation</code> <code>tf.keras.layers.Layer</code> <p>Activation function to complexyfy.</p> required <code>kwargs</code> <code>Any</code> <p>keyword arguments passed to the parent class tf.keras.layers.Layer.</p> <code>{}</code> Source code in <code>DeepSaki/activations/complex_valued_activations.py</code> <pre><code>def __init__(self, activation: tf.keras.layers.Layer, **kwargs: Any) -&gt; None:\n    \"\"\"Initialize ComplexActivation.\n\n    Args:\n        activation (tf.keras.layers.Layer): Activation function to complexyfy.\n        kwargs: keyword arguments passed to the parent class tf.keras.layers.Layer.\n    \"\"\"\n    super(ComplexActivation, self).__init__(**kwargs)\n    self.activation = activation\n</code></pre>"},{"location":"reference/DeepSaki/activations/#DeepSaki.activations.complex_valued_activations.ComplexActivation.call","title":"call","text":"<pre><code>call(\n    inputs: tf.Tensor,\n) -&gt; Union[tf.complex64, tf.complex128]\n</code></pre> <p>Splits its intput <code>inputs</code>into a real and imaginary part, applies <code>activation</code> and constructs a complex number.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>tf.Tensor</code> <p>Input tensor to be activated. Might be a complex or real valued tensor.</p> required <p>Returns:</p> Type Description <code>Union[tf.complex64, tf.complex128]</code> <p>tf.complex64 | tf.complex128: Complex tensor with activated real and imaginary part.</p> Source code in <code>DeepSaki/activations/complex_valued_activations.py</code> <pre><code>def call(self, inputs: tf.Tensor) -&gt; Union[tf.complex64, tf.complex128]:\n    \"\"\"Splits its intput `inputs`into a real and imaginary part, applies `activation` and constructs a complex number.\n\n    Args:\n        inputs (tf.Tensor): Input tensor to be activated. Might be a complex or real valued tensor.\n\n    Returns:\n        tf.complex64 | tf.complex128: Complex tensor with activated real and imaginary part.\n    \"\"\"\n    real = self.activation(tf.math.real(inputs))\n    imag = self.activation(tf.math.imag(inputs))\n    return tf.complex(real, imag)\n</code></pre>"},{"location":"reference/DeepSaki/activations/#DeepSaki.activations.complex_valued_activations.ComplexActivation.get_config","title":"get_config","text":"<pre><code>get_config() -&gt; Dict[str, Any]\n</code></pre> <p>Returns configuration of class instance.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict[str,Any]: Dictionary containing the class' configuration.</p> Source code in <code>DeepSaki/activations/complex_valued_activations.py</code> <pre><code>def get_config(self) -&gt; Dict[str, Any]:\n    \"\"\"Returns configuration of class instance.\n\n    Returns:\n        Dict[str,Any]: Dictionary containing the class' configuration.\n    \"\"\"\n    config = super(ComplexActivation, self).get_config()\n    config.update({\"activation\": self.activation})\n    return config\n</code></pre>"},{"location":"reference/DeepSaki/augmentations/","title":"augmentations","text":"<p>Cutting operations performed on batched 3D grid-shaped data types like images.</p>"},{"location":"reference/DeepSaki/augmentations/#DeepSaki.augmentations.grid_cutting.cut_mix","title":"cut_mix","text":"<pre><code>cut_mix(\n    batch1: tf.Tensor,\n    batch2: tf.Tensor,\n    ignore_background: bool = False,\n    invert_mask: bool = False,\n    mask: Optional[tf.Tensor] = None,\n) -&gt; Tuple[tf.Tensor, tf.Tensor]\n</code></pre> <p>Performs the cutmix operation of two image batches.</p> <p>A random image patch from <code>batch2</code> is taken and inserted into <code>batch1.</code></p> <p>Parameters:</p> Name Type Description Default <code>batch1</code> <code>tf.Tensor</code> <p>Batch of grid-shaped data of shape (<code>batch</code>, <code>height</code>, <code>width</code>, <code>channel</code>).</p> required <code>batch2</code> <code>tf.Tensor</code> <p>Batch of grid-shaped data of shape (<code>batch</code>, <code>height</code>, <code>width</code>, <code>channel</code>).</p> required <code>ignore_background</code> <code>bool</code> <p>If true, pixels belonging to the backgroud are ignored. Only applicable for images where the background is represented as 0. Defaults to False.</p> <code>False</code> <code>invert_mask</code> <code>bool</code> <p>If true, the mask is inverted. 1-&gt;0 and 0-&gt;1. Defaults to False.</p> <code>False</code> <code>mask</code> <code>Optional[tf.Tensor]</code> <p>Binary mask that requires same shape as <code>batch1</code> and <code>batch2</code>. If <code>None</code> mask is generated randomly. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>ground_truth_mask</code> <code>tf.Tensor</code> <p>Actual mask that has been applied</p> <code>new_batch</code> <code>tf.Tensor</code> <p>Batch with applied cutmix opperation</p> Source code in <code>DeepSaki/augmentations/grid_cutting.py</code> <pre><code>def cut_mix(\n    batch1: tf.Tensor,\n    batch2: tf.Tensor,\n    ignore_background: bool = False,\n    invert_mask: bool = False,\n    mask: Optional[tf.Tensor] = None,\n) -&gt; Tuple[tf.Tensor, tf.Tensor]:\n    \"\"\"Performs the cutmix operation of two image batches.\n\n    A random image patch from `batch2` is taken and inserted into `batch1.`\n\n    Args:\n        batch1 (tf.Tensor): Batch of grid-shaped data of shape (`batch`, `height`, `width`, `channel`).\n        batch2 (tf.Tensor): Batch of grid-shaped data of shape (`batch`, `height`, `width`, `channel`).\n        ignore_background (bool, optional): If true, pixels belonging to the backgroud are ignored. Only applicable for\n            images where the background is represented as 0. Defaults to False.\n        invert_mask (bool, optional): If true, the mask is inverted. 1-&gt;0 and 0-&gt;1. Defaults to False.\n        mask (Optional[tf.Tensor], optional): Binary mask that requires same shape as `batch1` and `batch2`. If `None`\n            mask is generated randomly. Defaults to None.\n\n    Returns:\n        ground_truth_mask: Actual mask that has been applied\n        new_batch: Batch with applied cutmix opperation\n    \"\"\"\n    batch1 = tf.cast(batch1, tf.float32)\n    batch2 = tf.cast(batch2, tf.float32)\n\n    if mask is None:  # generate mask\n        mask = _get_mask(shape=batch1.shape)\n\n    if ignore_background:  # check where in image are no background pixels (value = 1)\n        batch1_mask = tf.cast(tf.where(batch1 &gt; 0, 1, 0), tf.int32)\n        batch2_mask = tf.cast(tf.where(batch2 &gt; 0, 1, 0), tf.int32)\n        mutal_person_mask = tf.cast(tf.clip_by_value((batch1_mask + batch2_mask), 0, 1), tf.float32)\n        ground_truth_mask = 1 - (1 - mask) * mutal_person_mask\n\n    else:\n        ground_truth_mask = mask\n\n    if invert_mask:\n        ground_truth_mask = _invert_mask(ground_truth_mask)\n\n    new_batch = batch1 * ground_truth_mask + batch2 * _invert_mask(ground_truth_mask)\n\n    return ground_truth_mask, new_batch\n</code></pre>"},{"location":"reference/DeepSaki/augmentations/#DeepSaki.augmentations.grid_cutting.cut_out","title":"cut_out","text":"<pre><code>cut_out(\n    batch: tf.Tensor,\n    invert_mask: bool = False,\n    mask: Optional[tf.Tensor] = None,\n) -&gt; Tuple[tf.Tensor, tf.Tensor]\n</code></pre> <p>Performs the cutout operation of a batch of images.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>tf.Tensor</code> <p>Batch of grid-shaped data of shape (<code>batch</code>, <code>height</code>, <code>width</code>, <code>channel</code>).</p> required <code>invert_mask</code> <code>bool</code> <p>If true, the mask is inverted. 1-&gt;0 and 0-&gt;1. Defaults to False.</p> <code>False</code> <code>mask</code> <code>Optional[tf.Tensor]</code> <p>Binary mask that requires same shape as <code>batch1</code> and <code>batch2</code>. If <code>None</code> mask is generated randomly. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>mask</code> <code>tf.Tensor</code> <p>Actual mask that has been applied</p> <code>new_batch</code> <code>tf.Tensor</code> <p>Batch with applied cutout opperation</p> Source code in <code>DeepSaki/augmentations/grid_cutting.py</code> <pre><code>def cut_out(\n    batch: tf.Tensor, invert_mask: bool = False, mask: Optional[tf.Tensor] = None\n) -&gt; Tuple[tf.Tensor, tf.Tensor]:\n    \"\"\"Performs the cutout operation of a batch of images.\n\n    Args:\n        batch (tf.Tensor): Batch of grid-shaped data of shape (`batch`, `height`, `width`, `channel`).\n        invert_mask (bool, optional):  If true, the mask is inverted. 1-&gt;0 and 0-&gt;1. Defaults to False.\n        mask (Optional[tf.Tensor], optional): Binary mask that requires same shape as `batch1` and `batch2`. If `None`\n            mask is generated randomly. Defaults to None.\n\n    Returns:\n        mask: Actual mask that has been applied\n        new_batch: Batch with applied cutout opperation\n    \"\"\"\n    batch = tf.cast(batch, tf.float32)\n\n    if mask is None:  # generate mask\n        mask = _get_mask(shape=batch.shape)\n\n    if invert_mask:\n        mask = _invert_mask(mask)\n\n    new_batch = batch * mask\n    return mask, new_batch\n</code></pre>"},{"location":"reference/DeepSaki/constraints/","title":"constraints","text":"<p>Collection of custom constraints.</p> <p>Description of TensorFlow's <code>tf.keras.constraints.Constraint</code> base class:     A Constraint instance works like a stateless function. Users who subclass this class should override the     <code>__call__</code> method, which takes a single weight parameter and return a projected version of that parameter (e.g.     normalized or clipped). Constraints can be used with various Keras layers via the <code>kernel_constraint</code> or     <code>bias_constraint</code> arguments.</p>"},{"location":"reference/DeepSaki/constraints/#DeepSaki.constraints.constraints.NonNegative","title":"NonNegative","text":"<p>             Bases: <code>tf.keras.constraints.Constraint</code></p> <p>Constraint that enforces positive activations.</p>"},{"location":"reference/DeepSaki/constraints/#DeepSaki.constraints.constraints.NonNegative.__call__","title":"__call__","text":"<pre><code>__call__(w: tf.Tensor) -&gt; tf.Tensor\n</code></pre> <p>Clips negative values of a provided weight tensor <code>w</code> to 0.0 and leaves positive values unchanged.</p> <p>Parameters:</p> Name Type Description Default <code>w</code> <code>tf.Tensor</code> <p>Tensor containing the wehights of a layer.</p> required <p>Returns:</p> Type Description <code>tf.Tensor</code> <p>Tensor where negative values are clipped to 0.0.</p> Source code in <code>DeepSaki/constraints/constraints.py</code> <pre><code>def __call__(self, w: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"Clips negative values of a provided weight tensor `w` to 0.0 and leaves positive values unchanged.\n\n    Args:\n        w (tf.Tensor): Tensor containing the wehights of a layer.\n\n    Returns:\n        Tensor where negative values are clipped to 0.0.\n    \"\"\"\n    return w * tf.cast(tf.math.greater_equal(w, 0.0), w.dtype)\n</code></pre>"},{"location":"reference/DeepSaki/initializers/","title":"initializers","text":"<p>Set of initializers based on the He initializer.</p> <p>In contrast to the tensorflow implementation, an alpha value can be set to consider the non-zero slope of a LeakyReLU activation.</p>"},{"location":"reference/DeepSaki/initializers/#DeepSaki.initializers.he_alpha.HeAlpha","title":"HeAlpha","text":"<pre><code>HeAlpha(alpha: float = 0.3, seed: Optional[int] = None)\n</code></pre> <p>             Bases: <code>tf.keras.initializers.Initializer</code>, <code>ABC</code></p> <p>Abstract base class for HeAlpha initializers. Can not be instanciated, must be inherited from.</p> <p>HeAlpha is a He initializer that considers the negative slope of the LeakyReLU activation.</p> <p>Dunder method to initialize HeAlpha object.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>float</code> <p>Variable to control the width of the distribution. Should be set according the alpha value of the LeakyReLU activation. Defaults to 0.3.</p> <code>0.3</code> <code>seed</code> <code>Optional[int]</code> <p>Seed for the random distribution. Defaults to None.</p> <code>None</code> Source code in <code>DeepSaki/initializers/he_alpha.py</code> <pre><code>def __init__(self, alpha: float = 0.3, seed: Optional[int] = None) -&gt; None:\n    \"\"\"Dunder method to initialize HeAlpha object.\n\n    Args:\n        alpha (float, optional): Variable to control the width of the distribution. Should be set according the\n            alpha value of the LeakyReLU activation. Defaults to 0.3.\n        seed (Optional[int], optional): Seed for the random distribution. Defaults to None.\n    \"\"\"\n    self.alpha = alpha\n    self.seed = seed\n</code></pre>"},{"location":"reference/DeepSaki/initializers/#DeepSaki.initializers.he_alpha.HeAlpha.__call__","title":"__call__","text":"<pre><code>__call__(\n    shape: List[int],\n    dtype: Optional[Union[tf.DType, np.dtype]] = None,\n) -&gt; tf.Tensor\n</code></pre> <p>Abstract dunder method to call the object instance that must be overridden by child classes.</p> <p>Parameters:</p> Name Type Description Default <code>shape</code> <code>List[int]</code> <p>Shape of the tensor that shall be initialized.</p> required <code>dtype</code> <code>Optional[tf.DType | np.dtype]</code> <p>dtype to which the data should be casted to. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>tf.Tensor</code> <p>Tensor containing the weights sampled from a initialization function <code>_call_initializer</code> overriden by a subclass.</p> Source code in <code>DeepSaki/initializers/he_alpha.py</code> <pre><code>def __call__(self, shape: List[int], dtype: Optional[Union[tf.DType, np.dtype]] = None) -&gt; tf.Tensor:\n    \"\"\"Abstract dunder method to call the object instance that must be overridden by child classes.\n\n    Args:\n        shape (List[int]): Shape of the tensor that shall be initialized.\n        dtype (Optional[tf.DType | np.dtype], optional): dtype to which the data should be casted to.\n            Defaults to None.\n\n    Returns:\n        Tensor containing the weights sampled from a initialization function `_call_initializer` overriden by a\n            subclass.\n    \"\"\"\n    return self._call_initializer(shape, dtype)\n</code></pre>"},{"location":"reference/DeepSaki/initializers/#DeepSaki.initializers.he_alpha.HeAlpha.compute_fans","title":"compute_fans","text":"<pre><code>compute_fans(shape: List[int]) -&gt; Tuple[int, int]\n</code></pre> <p>Computes the number of input and output units for a weight shape.</p> <p>Parameters:</p> Name Type Description Default <code>shape</code> <code>List[int]</code> <p>Shape of the input tensor representing the weights of a neuronal network.</p> required <p>Returns:</p> Type Description <code>Tuple[int, int]</code> <p>Tuple[int,int]: (fan_in, fan_out)</p> Source code in <code>DeepSaki/initializers/he_alpha.py</code> <pre><code>def compute_fans(self, shape: List[int]) -&gt; Tuple[int, int]:\n    \"\"\"Computes the number of input and output units for a weight shape.\n\n    Args:\n        shape (List[int]): Shape of the input tensor representing the weights of a neuronal network.\n\n    Returns:\n        Tuple[int,int]: (fan_in, fan_out)\n    \"\"\"\n    if len(shape) &lt; 1:  # Just to avoid errors for constants.\n        fan_in = fan_out = 1\n    elif len(shape) == 1:\n        fan_in = fan_out = shape[0]\n    elif len(shape) == 2:\n        fan_in = shape[0]\n        fan_out = shape[1]\n    else:\n        # Assuming convolution kernels (2D, 3D, or more).\n        # kernel shape: (..., input_depth, depth)\n        receptive_field_size = 1\n        for dim in shape[:-2]:\n            receptive_field_size *= dim\n        fan_in = shape[-2] * receptive_field_size\n        fan_out = shape[-1] * receptive_field_size\n    return int(fan_in), int(fan_out)\n</code></pre>"},{"location":"reference/DeepSaki/initializers/#DeepSaki.initializers.he_alpha.HeAlpha.get_config","title":"get_config","text":"<pre><code>get_config() -&gt; Dict[str, Any]\n</code></pre> <p>Serialize object and return dictionary containing member variables.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict[str,Any]: {\"alpha\": self.alpha, \"seed\": self.seed}</p> Source code in <code>DeepSaki/initializers/he_alpha.py</code> <pre><code>def get_config(self) -&gt; Dict[str, Any]:\n    \"\"\"Serialize object and return dictionary containing member variables.\n\n    Returns:\n        Dict[str,Any]: {\"alpha\": self.alpha, \"seed\": self.seed}\n    \"\"\"\n    return {\"alpha\": self.alpha, \"seed\": self.seed}\n</code></pre>"},{"location":"reference/DeepSaki/initializers/#DeepSaki.initializers.he_alpha.HeAlphaNormal","title":"HeAlphaNormal","text":"<pre><code>HeAlphaNormal(\n    alpha: float = 0.3, seed: Optional[int] = None\n)\n</code></pre> <p>             Bases: <code>HeAlpha</code></p> <p>HeAlpha initializer drawing values from an normal distribution distribution.</p> <p>$$ W^{[l]} \\sim \\mathcal{N}\\left(\\mu = 0, \\sigma^{2}= \\frac{2}{(1+\\alpha^{2})n[l]}\\right), $$ where \\(\\mu\\) is the mean, \\(\\sigma^2\\) is the variance, \\(\\alpha\\) is a configurable variable and \\(n[l]\\) is the number of parameters in layer \\(l\\)</p> <p>Dunder method to initialize HeAlphaUniform object.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>float</code> <p>Variable to control the width of the distribution. Should be set according the alpha value of the LeakyReLU activation. Defaults to 0.3.</p> <code>0.3</code> <code>seed</code> <code>Optional[int]</code> <p>Seed for the random distribution. Defaults to None.</p> <code>None</code> Source code in <code>DeepSaki/initializers/he_alpha.py</code> <pre><code>def __init__(self, alpha: float = 0.3, seed: Optional[int] = None) -&gt; None:\n    \"\"\"Dunder method to initialize HeAlphaUniform object.\n\n    Args:\n        alpha (float, optional): Variable to control the width of the distribution. Should be set according the\n            alpha value of the LeakyReLU activation. Defaults to 0.3.\n        seed (Optional[int], optional): Seed for the random distribution. Defaults to None.\n    \"\"\"\n    super(HeAlphaNormal, self).__init__(alpha, seed)\n</code></pre>"},{"location":"reference/DeepSaki/initializers/#DeepSaki.initializers.he_alpha.HeAlphaUniform","title":"HeAlphaUniform","text":"<pre><code>HeAlphaUniform(\n    alpha: float = 0.3, seed: Optional[int] = None\n)\n</code></pre> <p>             Bases: <code>HeAlpha</code></p> <p>HeAlpha initializer drawing values from an uniform distribution.</p> <p>$$ W^{[l]} \\sim \\mathcal{U}\\left(a = -\\sqrt{\\frac{6}{n^{[l]}+n^{[l+1]}}}, b = \\sqrt{\\frac{6}{n^{[l]}+n^{[l+1]}}}\\right), $$ where \\(\\alpha\\) is a configurable variable and \\(n[l]\\) is the number of parameters in layer \\(l\\)</p> <p>Dunder method to initialize HeAlphaUniform object.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>float</code> <p>Variable to control the width of the distribution. Should be set according the alpha value of the LeakyReLU activation. Defaults to 0.3.</p> <code>0.3</code> <code>seed</code> <code>Optional[int]</code> <p>Seed for the random distribution. Defaults to None.</p> <code>None</code> Source code in <code>DeepSaki/initializers/he_alpha.py</code> <pre><code>def __init__(self, alpha: float = 0.3, seed: Optional[int] = None) -&gt; None:\n    \"\"\"Dunder method to initialize HeAlphaUniform object.\n\n    Args:\n        alpha (float, optional): Variable to control the width of the distribution. Should be set according the\n            alpha value of the LeakyReLU activation. Defaults to 0.3.\n        seed (Optional[int], optional): Seed for the random distribution. Defaults to None.\n    \"\"\"\n    super(HeAlphaUniform, self).__init__(alpha, seed)\n</code></pre>"},{"location":"reference/DeepSaki/initializers/#DeepSaki.initializers.initializer_helper.make_initializer_complex","title":"make_initializer_complex","text":"<pre><code>make_initializer_complex(\n    initializer: tf.keras.initializers.Initializer,\n) -&gt; Callable[[List[int], tf.DType], tf.complex]\n</code></pre> <p>Returns a function that applies a given <code>initializer</code> to generate a complex-valued tensor for initialization.</p> <p>The function applies the initializer twice, once for the <code>real</code> part and once for the <code>imaginary</code> part and then constructs a complex-valued tensor of the provided <code>shape</code>.</p> <p>Examples: <pre><code># Standalone usage:\nimport DeepSaki as dsk\ninitializer = dsk.initializers.make_initializer_complex(tf.keras.initializers.GlorotUniform())\nvalues = initializer(shape=(2, 2))\n</code></pre> <pre><code># Usage in a Keras layer:\nimport DeepSaki as dsk\ninitializer = dsk.initializers.make_initializer_complex(tf.keras.initializers.GlorotUniform())\nlayer = tf.keras.layers.Dense(3, kernel_initializer=initializer)\n</code></pre></p> <p>Parameters:</p> Name Type Description Default <code>initializer</code> <code>tf.keras.initializers.Initializer</code> <p>Any real valued initializer object.</p> required <p>Returns:</p> Type Description <code>Callable[[List[int], tf.DType], tf.complex]</code> <p>Wrapper function with same function signature as a <code>tf.keras.initializers.Initializer</code> object.</p> Source code in <code>DeepSaki/initializers/initializer_helper.py</code> <pre><code>def make_initializer_complex(\n    initializer: tf.keras.initializers.Initializer,\n) -&gt; Callable[[List[int], tf.DType], tf.complex]:\n    \"\"\"Returns a function that applies a given `initializer` to generate a complex-valued tensor for initialization.\n\n    The function applies the initializer twice, once for the `real` part and once for the `imaginary` part and then\n    constructs a complex-valued tensor of the provided `shape`.\n\n\n    **Examples:**\n    ```python\n    # Standalone usage:\n    import DeepSaki as dsk\n    initializer = dsk.initializers.make_initializer_complex(tf.keras.initializers.GlorotUniform())\n    values = initializer(shape=(2, 2))\n    ```\n    ```python\n    # Usage in a Keras layer:\n    import DeepSaki as dsk\n    initializer = dsk.initializers.make_initializer_complex(tf.keras.initializers.GlorotUniform())\n    layer = tf.keras.layers.Dense(3, kernel_initializer=initializer)\n    ```\n\n    Args:\n        initializer (tf.keras.initializers.Initializer): Any real valued initializer object.\n\n    Returns:\n        Wrapper function with same function signature as a `tf.keras.initializers.Initializer` object.\n    \"\"\"\n\n    def complex_initializer(shape: List[int], dtype: tf.DType = tf.complex64) -&gt; tf.complex:\n        \"\"\"Function that applies a given `initializer` to generate a complex-valued tensor for initialization.\n\n        Args:\n            shape (List[int]): Shape of the tensor to be initialized.\n            dtype (tf.DType, optional): dtype of the individual terms of the complex number. Defaults to `tf.complex64`.\n\n        Returns:\n            Complex-valued tensor with values drawn from the `initializer`, seperatly for `real` and `imaginary` part.\n        \"\"\"\n        if dtype == tf.complex64:\n            dtype = tf.float32\n        elif dtype == tf.complex128:\n            dtype = tf.float64\n        real = initializer(shape, dtype)\n        imag = initializer(shape, dtype)\n        return tf.dtypes.complex(real, imag)\n\n    return complex_initializer\n</code></pre>"},{"location":"reference/DeepSaki/layers/","title":"layers","text":"<p>Collection of functions to simplify the code in various layers.</p> <p>Collection of padding layer operations.</p> <p>Collection of pooling layer operations to reduce the spatial dimensionality of a feature map.</p>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.fourier_layer.FFT2D","title":"FFT2D","text":"<pre><code>FFT2D(\n    is_channel_first: bool = False,\n    apply_real_fft: bool = False,\n    shift_fft: bool = True,\n    **kwargs: Any\n)\n</code></pre> <p>             Bases: <code>FourierLayer</code></p> <p>Calculates the 2D descrete fourier transform over the 2 last dimensions.</p> <p>For a 4D input of shape (batch, channel, height, width), the 2DFFT would be calculated over (height, width).</p> Know what to expect input shape input dtype apply_real_fft output dtype output shape (1,8,8,3) real True complex (1,8,5,3) (1,8,8,3) real false n.a. n.a. (1,8,8,3) complex True(Value Error) n.a. n.a. (1,8,8,3) complex False complex (1,8,8,3) Limitations <p>Height and width are expected to be equal for now.</p> <p>Initializes the <code>FFT2D</code> layer.</p> <p>Parameters:</p> Name Type Description Default <code>is_channel_first</code> <code>bool</code> <p>Set true if input shape is (b,c,h,w) and false if input shape is (b,h,w,c). Defaults to <code>False</code>.</p> <code>False</code> <code>apply_real_fft</code> <code>bool</code> <p>If True, rfft2D is applied, which assumes real valued inputs and halves the width of the output(width/2+1 because center frequency is kept). If False, fft2D is applied, which assumes complex input. Defaults to False.</p> <code>False</code> <code>shift_fft</code> <code>bool</code> <p>If true, low frequency components are centered. Defaults to True.</p> <code>True</code> <code>kwargs</code> <code>Any</code> <p>keyword arguments passed to the parent class tf.keras.layers.Layer.</p> <code>{}</code> Source code in <code>DeepSaki/layers/fourier_layer.py</code> <pre><code>def __init__(\n    self,\n    is_channel_first: bool = False,\n    apply_real_fft: bool = False,\n    shift_fft: bool = True,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Initializes the `FFT2D` layer.\n\n    Args:\n        is_channel_first (bool, optional): Set true if input shape is (b,c,h,w) and false if input shape is\n            (b,h,w,c). Defaults to `False`.\n        apply_real_fft (bool, optional): If True, rfft2D is applied, which assumes real valued inputs and halves the\n            width of the output(width/2+1 because center frequency is kept). If False, fft2D is applied, which\n            assumes complex input. Defaults to False.\n        shift_fft (bool, optional): If true, low frequency components are centered. Defaults to True.\n        kwargs (Any): keyword arguments passed to the parent class tf.keras.layers.Layer.\n    \"\"\"\n    super(FFT2D, self).__init__(**kwargs)\n    self.is_channel_first = is_channel_first\n    self.apply_real_fft = apply_real_fft\n    self.shift_fft = shift_fft\n    self.policy_compute_dtype = tf.keras.mixed_precision.global_policy().compute_dtype\n\n    dtype = tf.float32 if self.apply_real_fft else tf.complex64\n    self.input_spec = tf.keras.layers.InputSpec(ndim=4, dtype=dtype)\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.fourier_layer.FFT2D.call","title":"call","text":"<pre><code>call(inputs: tf.Tensor) -&gt; tf.Tensor\n</code></pre> <p>Calls the <code>FFT2D</code> layer.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>tf.Tensor</code> <p>Tensor of shape (b,h,w,c) if <code>is_channel_first=False</code> or Tensor of shape (b,c,h,w) if <code>is_channel_first=True</code>. <code>h</code> and <code>w</code> should be equal for now.</p> required <p>Returns:</p> Type Description <code>tf.Tensor</code> <p>Tensor of shape (b,h,Wo,c) if <code>is_channel_first=False</code> or  Tensor of shape (b,c,h,Wo) if <code>is_channel_first=True</code>. If <code>apply_real_fft=True</code> \\(Wo=\\frac{w}{2}+1\\).</p> Source code in <code>DeepSaki/layers/fourier_layer.py</code> <pre><code>def call(self, inputs: tf.Tensor) -&gt; tf.Tensor:\n    r\"\"\"Calls the `FFT2D` layer.\n\n    Args:\n        inputs (tf.Tensor): Tensor of shape (b,h,w,c) if `is_channel_first=False` or Tensor of shape (b,c,h,w) if\n            `is_channel_first=True`. `h` and `w` should be equal for now.\n\n    Returns:\n        Tensor of shape (b,h,Wo,c) if `is_channel_first=False` or  Tensor of shape (b,c,h,Wo) if\n            `is_channel_first=True`. If `apply_real_fft=True` $Wo=\\frac{w}{2}+1$.\n    \"\"\"\n    if not self.is_channel_first:\n        inputs = self._change_to_channel_first(inputs)\n\n    if self.apply_real_fft:\n        x = tf.signal.rfft2d(inputs)\n        if self.shift_fft:\n            x = tf.signal.fftshift(x, axes=[-2])\n    else:\n        if inputs.dtype not in [tf.complex64, tf.complex128]:\n            imag = tf.zeros_like(inputs)\n            inputs = tf.complex(inputs, imag)  # fft2d requires complex inputs -&gt; create complex with 0 imaginary\n        x = tf.signal.fft2d(inputs)\n        if self.shift_fft:\n            x = tf.signal.fftshift(x)\n\n    if not self.is_channel_first:  # reverse the channel configuration to its initial config\n        x = self._change_to_channel_last(x)\n\n    return x\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.fourier_layer.FFT2D.get_config","title":"get_config","text":"<pre><code>get_config() -&gt; Dict[str, Any]\n</code></pre> <p>Serialization of the object.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with the class' variable names as keys.</p> Source code in <code>DeepSaki/layers/fourier_layer.py</code> <pre><code>def get_config(self) -&gt; Dict[str, Any]:\n    \"\"\"Serialization of the object.\n\n    Returns:\n        Dictionary with the class' variable names as keys.\n    \"\"\"\n    config = super(FFT2D, self).get_config()\n    config.update(\n        {\n            \"is_channel_first\": self.is_channel_first,\n            \"apply_real_fft\": self.apply_real_fft,\n            \"shift_fft\": self.shift_fft,\n            \"policy_compute_dtype\": self.policy_compute_dtype,\n        }\n    )\n    return config\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.fourier_layer.FFT3D","title":"FFT3D","text":"<pre><code>FFT3D(\n    is_channel_first: bool = False,\n    apply_real_fft: bool = False,\n    shift_fft: bool = True,\n    **kwargs: Any\n)\n</code></pre> <p>             Bases: <code>FourierLayer</code></p> <p>Calculates the 3D descrete fourier transform over the 3 last dimensions.</p> <p>For a 4D input like a batch of images of shape (batch, channel, height, width), the 3DFFT would be calculated over (channel, height, width). For a 5D input, like a batch of videos of shape (batch, channel, frame, height, width), the 3DFFT would be calculated over (frame, height, width).</p> <p>Initializes the <code>FFT3D</code> layer.</p> <p>Parameters:</p> Name Type Description Default <code>is_channel_first</code> <code>bool</code> <p>Set true if input shape is (b,c,h,w) or (b,c,f,w,h) and false if input shape is (b,h,w,c) or (b,f,w,h,c). Defaults to <code>False</code>.</p> <code>False</code> <code>apply_real_fft</code> <code>bool</code> <p>If True, rfft3D is applied, which assumes real valued inputs and halves the width of the output. If False, fft3D is applied, which assumes complex input. Defaults to False.</p> <code>False</code> <code>shift_fft</code> <code>bool</code> <p>If true, low frequency components are centered. Defaults to True.</p> <code>True</code> <code>kwargs</code> <code>Any</code> <p>keyword arguments passed to the parent class tf.keras.layers.Layer.</p> <code>{}</code> Source code in <code>DeepSaki/layers/fourier_layer.py</code> <pre><code>def __init__(\n    self,\n    is_channel_first: bool = False,\n    apply_real_fft: bool = False,\n    shift_fft: bool = True,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Initializes the `FFT3D` layer.\n\n    Args:\n        is_channel_first (bool, optional): Set true if input shape is (b,c,h,w) or (b,c,f,w,h) and false if input\n            shape is (b,h,w,c) or (b,f,w,h,c). Defaults to `False`.\n        apply_real_fft (bool, optional): If True, rfft3D is applied, which assumes real valued inputs and halves the\n            width of the output. If False, fft3D is applied, which assumes complex input. Defaults to False.\n        shift_fft (bool, optional): If true, low frequency components are centered. Defaults to True.\n        kwargs (Any): keyword arguments passed to the parent class tf.keras.layers.Layer.\n    \"\"\"\n    super(FFT3D, self).__init__(**kwargs)\n    self.is_channel_first = is_channel_first\n    self.apply_real_fft = apply_real_fft\n    self.shift_fft = shift_fft\n    self.policy_compute_dtype = tf.keras.mixed_precision.global_policy().compute_dtype\n    dtype = tf.float32 if self.apply_real_fft else tf.complex64\n    self.input_spec = tf.keras.layers.InputSpec(min_ndim=4, max_ndim=5, dtype=dtype)\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.fourier_layer.FFT3D.call","title":"call","text":"<pre><code>call(inputs: tf.Tensor) -&gt; tf.Tensor\n</code></pre> <p>Calls the <code>FFT3D</code> layer.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>tf.Tensor</code> <p>Tensor of shape (b,h,w,c) or (b,f,w,h,c) if <code>is_channel_first=False</code> or  Tensor of shape (b,c,h,w) or (b,c,f,w,h) if <code>is_channel_first=True</code>. <code>h</code> and <code>w</code> should be equal for now.</p> required <p>Returns:</p> Type Description <code>tf.Tensor</code> <p>Tensor of shape (b,h,Wo,c) or (b,f,h,Wo,c) if <code>is_channel_first=False</code> or Tensor of shape (b,c,h,Wo) or (b,f,c,h,Wo) if <code>is_channel_first=True</code>. If <code>apply_real_fft=True</code> \\(Wo=\\frac{w}{2}+1\\).</p> Source code in <code>DeepSaki/layers/fourier_layer.py</code> <pre><code>def call(self, inputs: tf.Tensor) -&gt; tf.Tensor:\n    r\"\"\"Calls the `FFT3D` layer.\n\n    Args:\n        inputs (tf.Tensor): Tensor of shape (b,h,w,c) or (b,f,w,h,c) if `is_channel_first=False` or  Tensor of\n            shape (b,c,h,w) or (b,c,f,w,h) if `is_channel_first=True`. `h` and `w` should be equal for now.\n\n    Returns:\n        Tensor of shape (b,h,Wo,c) or (b,f,h,Wo,c) if `is_channel_first=False` or Tensor of shape (b,c,h,Wo) or\n            (b,f,c,h,Wo) if `is_channel_first=True`. If `apply_real_fft=True` $Wo=\\frac{w}{2}+1$.\n    \"\"\"\n    if not self.is_channel_first:\n        inputs = self._change_to_channel_first(inputs)\n\n    if self.apply_real_fft:\n        x = tf.signal.rfft3d(inputs)\n        if self.shift_fft:\n            x = tf.signal.fftshift(x, axes=[-2])\n    else:\n        if inputs.dtype not in [tf.complex64, tf.complex128]:\n            imag = tf.zeros_like(inputs)\n            inputs = tf.complex(inputs, imag)  # fft3d requires complex inputs -&gt; create complex with 0 imaginary\n        x = tf.signal.fft3d(inputs)\n        if self.shift_fft:\n            x = tf.signal.fftshift(x)\n\n    if not self.is_channel_first:\n        x = self._change_to_channel_last(x)\n\n    return x\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.fourier_layer.FFT3D.get_config","title":"get_config","text":"<pre><code>get_config() -&gt; Dict[str, Any]\n</code></pre> <p>Serialization of the object.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with the class' variable names as keys.</p> Source code in <code>DeepSaki/layers/fourier_layer.py</code> <pre><code>def get_config(self) -&gt; Dict[str, Any]:\n    \"\"\"Serialization of the object.\n\n    Returns:\n        Dictionary with the class' variable names as keys.\n    \"\"\"\n    config = super(FFT3D, self).get_config()\n    config.update(\n        {\n            \"is_channel_first\": self.is_channel_first,\n            \"apply_real_fft\": self.apply_real_fft,\n            \"shift_fft\": self.shift_fft,\n            \"policy_compute_dtype\": self.policy_compute_dtype,\n        }\n    )\n    return config\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.fourier_layer.FourierConvolution2D","title":"FourierConvolution2D","text":"<pre><code>FourierConvolution2D(\n    filters: int = 3,\n    kernels: Optional[Tuple[int, int]] = None,\n    use_bias: bool = True,\n    is_channel_first: bool = False,\n    apply_conjugate: bool = False,\n    pad_to_power_2: bool = True,\n    multiplication_type: MultiplicationType = MultiplicationType.ELEMENT_WISE,\n    kernel_initializer: Optional[\n        tf.keras.initializers.Initializer\n    ] = None,\n    bias_initializer: Optional[\n        tf.keras.initializers.Initializer\n    ] = None,\n    **kwargs: Any\n)\n</code></pre> <p>             Bases: <code>FourierLayer</code></p> <p>Performs a convolution by transforming into fourier domain. Layer input is asumed to be in spatial domain.</p> <p>Initialize the <code>FourierConvolution2D</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>filters</code> <code>int</code> <p>Number of individual filters. Defaults to 3.</p> <code>3</code> <code>kernels</code> <code>Optional[Tuple[int, int]]</code> <p>Kernel of the spatial convolution. Expected input <code>[height,width]</code>. If <code>None</code>, kernel size is set to the input height and width. Defaults to <code>None</code>.</p> <code>None</code> <code>use_bias</code> <code>bool</code> <p>Whether or not to us bias weights. Defaults to <code>True</code>.</p> <code>True</code> <code>is_channel_first</code> <code>bool</code> <p>Set true if input shape is (b,c,h,w) and false if input shape is (b,h,w,c). Defaults to <code>False</code>.</p> <code>False</code> <code>apply_conjugate</code> <code>bool</code> <p>If true, the kernels are conjugated. If so, a multiplication in the frequency domain corresponds to a cross correlation in the spatial domain, which is actually what a convolution layer is doing. Defaults to <code>False</code>.</p> <code>False</code> <code>pad_to_power_2</code> <code>bool</code> <p>If true, input tensor is padded. FFT algorithm runs faster for lengths of power of two. Defaults to <code>True</code>.</p> <code>True</code> <code>multiplication_type</code> <code>MultiplicationType</code> <p>Type of algo used for the element wise multiplication and reduction of the input and the convolution kernel. [<code>MultiplicationType.ELEMENT_WISE</code> | <code>MultiplicationType.MATRIX_PRODUCT</code>]. MATRIX_PRODUCT is faster, but requires more memory. ELEMENT_WISE is slower but requires less memory. Defaults to <code>MultiplicationType.ELEMENT_WISE</code>.</p> <code>MultiplicationType.ELEMENT_WISE</code> <code>kernel_initializer</code> <code>tf.keras.initializers.Initializer</code> <p>Initializer to initialize the kernels of the convolution layer. Defaults to <code>None</code>.</p> <code>None</code> <code>bias_initializer</code> <code>tf.keras.initializers.Initializer</code> <p>Initializer to initialize the bias weights of the convolution layer. Defaults to <code>None</code>.</p> <code>None</code> <code>kwargs</code> <code>Any</code> <p>Additional key word arguments passed to the base class.</p> <code>{}</code> Source code in <code>DeepSaki/layers/fourier_layer.py</code> <pre><code>def __init__(\n    self,\n    filters: int = 3,\n    kernels: Optional[Tuple[int, int]] = None,\n    use_bias: bool = True,\n    is_channel_first: bool = False,\n    apply_conjugate: bool = False,\n    pad_to_power_2: bool = True,\n    multiplication_type: MultiplicationType = MultiplicationType.ELEMENT_WISE,\n    kernel_initializer: Optional[tf.keras.initializers.Initializer] = None,\n    bias_initializer: Optional[tf.keras.initializers.Initializer] = None,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Initialize the `FourierConvolution2D` object.\n\n    Args:\n        filters (int, optional): Number of individual filters. Defaults to 3.\n        kernels (Optional[Tuple[int, int]], optional): Kernel of the spatial convolution. Expected input\n            `[height,width]`. If `None`, kernel size is set to the input height and width. Defaults to `None`.\n        use_bias (bool, optional): Whether or not to us bias weights. Defaults to `True`.\n        is_channel_first (bool, optional): Set true if input shape is (b,c,h,w) and false if input shape is\n            (b,h,w,c). Defaults to `False`.\n        apply_conjugate (bool, optional): If true, the kernels are conjugated. If so, a multiplication in the\n            frequency domain corresponds to a cross correlation in the spatial domain, which is actually what a\n            convolution layer is doing. Defaults to `False`.\n        pad_to_power_2 (bool, optional): If true, input tensor is padded. FFT algorithm runs faster for lengths of\n            power of two. Defaults to `True`.\n        multiplication_type (MultiplicationType, optional): Type of algo used for the element wise multiplication\n            and reduction of the input and the convolution kernel. [`MultiplicationType.ELEMENT_WISE` |\n            `MultiplicationType.MATRIX_PRODUCT`]. MATRIX_PRODUCT is faster, but requires more memory. ELEMENT_WISE\n            is slower but requires less memory. Defaults to `MultiplicationType.ELEMENT_WISE`.\n        kernel_initializer (tf.keras.initializers.Initializer, optional): Initializer to initialize the kernels of\n            the convolution layer. Defaults to `None`.\n        bias_initializer (tf.keras.initializers.Initializer, optional): Initializer to initialize the bias weights\n            of the convolution layer. Defaults to `None`.\n        kwargs (Any): Additional key word arguments passed to the base class.\n    \"\"\"\n    super(FourierConvolution2D, self).__init__(**kwargs)\n    self.filters = filters\n    self.kernels = kernels\n    self.use_bias = use_bias\n    self.kernel_initializer = (\n        tf.keras.initializers.RandomUniform(-0.05, 0.05) if kernel_initializer is None else kernel_initializer\n    )\n    self.bias_initializer = tf.keras.initializers.Zeros() if bias_initializer is None else bias_initializer\n    self.is_channel_first = is_channel_first\n    self.apply_conjugate = apply_conjugate\n    self.pad_to_power_2 = pad_to_power_2\n    self.multiplication_type = multiplication_type\n\n    self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n\n    self.multiply = self._get_multiplication_function(multiplication_type)\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.fourier_layer.FourierConvolution2D.build","title":"build","text":"<pre><code>build(input_shape: tf.TensorShape) -&gt; None\n</code></pre> <p>Build layer depending on the <code>input_shape</code> (output shape of the previous layer).</p> <p>Parameters:</p> Name Type Description Default <code>input_shape</code> <code>tf.TensorShape</code> <p>Shape of the input tensor to this layer.</p> required Source code in <code>DeepSaki/layers/fourier_layer.py</code> <pre><code>def build(self, input_shape: tf.TensorShape) -&gt; None:\n    \"\"\"Build layer depending on the `input_shape` (output shape of the previous layer).\n\n    Args:\n        input_shape (tf.TensorShape): Shape of the input tensor to this layer.\n    \"\"\"\n    super(FourierConvolution2D, self).build(input_shape)\n    if self.is_channel_first:\n        self.batch_size, self.inp_filter, self.inp_height, self.inp_width = input_shape\n    else:\n        self.batch_size, self.inp_height, self.inp_width, self.inp_filter = input_shape\n\n    if self.kernels is None:\n        self.kernels = (self.inp_height, self.inp_width)\n\n    # weights are independent from batch size [out_filter,inp_filter,kernel,kernel]. I leave the two kernels last, since I then can easily calculate the 2d FFT at once!\n    self.kernel = self.add_weight(\n        name=\"kernel\",\n        shape=[self.filters, self.inp_filter, self.kernels[0], self.kernels[1]],\n        initializer=self.kernel_initializer,\n        trainable=True,\n    )\n    self.padding = self._get_image_padding(self.kernels)\n    self.paddedImageShape = (\n        self.batch_size,\n        self.inp_filter,\n        self.inp_height + 2 * self.padding[0],\n        self.inp_width + 2 * self.padding[1],\n    )\n\n    if self.use_bias:\n        self.bias = self.add_weight(\n            name=\"bias\", shape=[self.filters, 1, 1], initializer=self.bias_initializer, trainable=True\n        )\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.fourier_layer.FourierConvolution2D.call","title":"call","text":"<pre><code>call(inputs: tf.Tensor) -&gt; tf.Tensor\n</code></pre> <p>Calls the <code>FourierConvolution2D</code> layer.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>tf.Tensor</code> <p>Tensor of data in spatial domain of shape <code>(b,h,w,c)</code> or <code>(b,c,h,w)</code> depending on <code>is_channel_first</code></p> required <p>Returns:</p> Type Description <code>tf.Tensor</code> <p>Tensor in spatial domain of same shape as input.</p> Source code in <code>DeepSaki/layers/fourier_layer.py</code> <pre><code>def call(self, inputs: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"Calls the `FourierConvolution2D` layer.\n\n    Args:\n        inputs (tf.Tensor): Tensor of data in spatial domain of shape `(b,h,w,c)` or `(b,c,h,w)` depending on\n            `is_channel_first`\n\n    Returns:\n        Tensor in spatial domain of same shape as input.\n    \"\"\"\n    # FFT2D is calculated over last two dimensions!\n    if not self.is_channel_first:\n        inputs = self._change_to_channel_first(inputs)\n\n    # Optionally pad to power of 2, to speed up FFT\n    if self.pad_to_power_2:\n        self.paddedImageShape = self._fill_image_shape_power_2(self.paddedImageShape)\n\n    # Compute DFFTs for both inputs and kernel weights\n    inputs_f_domain = tf.signal.rfft2d(\n        inputs, fft_length=[self.paddedImageShape[-2], self.paddedImageShape[-1]]\n    )  # [batch,height,width,channel]\n    kernels_f_domain = tf.signal.rfft2d(\n        self.kernel, fft_length=[self.paddedImageShape[-2], self.paddedImageShape[-1]]\n    )\n    if self.apply_conjugate:\n        kernels_f_domain = tf.math.conj(kernels_f_domain)  # to be equvivalent to the cross correlation\n\n    outputs_f_domain = self.multiply(inputs_f_domain, kernels_f_domain)\n\n    # Inverse rDFFT\n    output = tf.signal.irfft2d(outputs_f_domain, fft_length=[self.paddedImageShape[-2], self.paddedImageShape[-1]])\n    # shift the samples to obtain linear conv from circular conv\n    output = tf.roll(output, shift=[2 * self.padding[0], 2 * self.padding[1]], axis=[-2, -1])\n\n    # obtain initial shape by removing padding\n    output = tf.slice(\n        output,\n        begin=[0, 0, self.padding[0], self.padding[1]],\n        size=[self.batch_size, self.filters, self.inp_height, self.inp_width],\n    )\n\n    # Optionally add bias\n    if self.use_bias:\n        output += self.bias\n\n    # reverse the channel configuration to its initial config\n    if not self.is_channel_first:\n        output = self._change_to_channel_last(output)\n\n    return output\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.fourier_layer.FourierConvolution2D.get_config","title":"get_config","text":"<pre><code>get_config() -&gt; Dict[str, Any]\n</code></pre> <p>Serialization of the object.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with the class' variable names as keys.</p> Source code in <code>DeepSaki/layers/fourier_layer.py</code> <pre><code>def get_config(self) -&gt; Dict[str, Any]:\n    \"\"\"Serialization of the object.\n\n    Returns:\n        Dictionary with the class' variable names as keys.\n    \"\"\"\n    config = super(FourierConvolution2D, self).get_config()\n    config.update(\n        {\n            \"filters\": self.filters,\n            \"kernels\": self.kernels,\n            \"use_bias\": self.use_bias,\n            \"kernel_initializer\": self.kernel_initializer,\n            \"bias_initializer\": self.bias_initializer,\n            \"is_channel_first\": self.is_channel_first,\n            \"apply_conjugate\": self.apply_conjugate,\n            \"pad_to_power_2\": self.pad_to_power_2,\n            \"multiplication_type\": self.multiplication_type,\n        }\n    )\n    return config\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.fourier_layer.FourierFilter2D","title":"FourierFilter2D","text":"<pre><code>FourierFilter2D(\n    filters: int = 3,\n    use_bias: bool = True,\n    is_channel_first: bool = False,\n    multiplication_type: MultiplicationType = MultiplicationType.ELEMENT_WISE,\n    filter_initializer: Optional[\n        tf.keras.initializers.Initializer\n    ] = None,\n    bias_initializer: Optional[\n        tf.keras.initializers.Initializer\n    ] = None,\n    **kwargs: Any\n)\n</code></pre> <p>             Bases: <code>FourierLayer</code></p> <p>Complex-valued learnable filter in frequency domain. Expects input data to be in the fourier domain.</p> <p>The filter has the same size as the input and can hence act as any type of filter: low-pass, high-pass, band-pass, band-stop or any combination.</p> <p>To transform an image into the frequency domain you can use <code>DeepSaki.layers.FFT2D</code>.</p> <p>Example: <pre><code>import DeepSaki as dsk\n# pseudo code to load data\nimage_dataset = load_data(data_path)\nx = dsk.layers.FFT2D()(image_dataset)\nx = dsk.layers.FourierFilter2D(filters=32)(x)\nx = dsk.layers.FourierFilter2D(filters=64)(x)\nx = dsk.layers.FourierFilter2D(filters=128)(x)\nx = dsk.layers.iFFT2D()(x)\n</code></pre></p> <p>Initialize the <code>FourierFilter2D</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>filters</code> <code>int</code> <p>Number of independent filters. Defaults to 3.</p> <code>3</code> <code>use_bias</code> <code>bool</code> <p>Whether or not to us bias weights. Defaults to <code>True</code>.</p> <code>True</code> <code>is_channel_first</code> <code>bool</code> <p>Set true if input shape is (b,c,h,w) and false if input shape is (b,h,w,c). Defaults to <code>False</code>.</p> <code>False</code> <code>multiplication_type</code> <code>MultiplicationType</code> <p>Type of algo used for the element wise multiplication and reduction of the input and the filter weights. [<code>MultiplicationType.ELEMENT_WISE</code> | <code>MultiplicationType.MATRIX_PRODUCT</code>]. MATRIX_PRODUCT is faster, but requires more memory. ELEMENT_WISE is slower but requires less memory. Defaults to <code>MultiplicationType.ELEMENT_WISE</code>.</p> <code>MultiplicationType.ELEMENT_WISE</code> <code>filter_initializer</code> <code>tf.keras.initializers.Initializer</code> <p>Initializer to initialize the wheights of the filter layer. Defaults to <code>None</code>.</p> <code>None</code> <code>bias_initializer</code> <code>tf.keras.initializers.Initializer</code> <p>Initializer to initialize the wheights of the bias weights. Defaults to <code>None</code>.</p> <code>None</code> <code>kwargs</code> <code>Any</code> <p>Additional key word arguments passed to the base class.</p> <code>{}</code> Source code in <code>DeepSaki/layers/fourier_layer.py</code> <pre><code>def __init__(\n    self,\n    filters: int = 3,\n    use_bias: bool = True,\n    is_channel_first: bool = False,\n    multiplication_type: MultiplicationType = MultiplicationType.ELEMENT_WISE,\n    filter_initializer: Optional[tf.keras.initializers.Initializer] = None,\n    bias_initializer: Optional[tf.keras.initializers.Initializer] = None,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Initialize the `FourierFilter2D` object.\n\n    Args:\n        filters (int, optional): Number of independent filters. Defaults to 3.\n        use_bias (bool, optional): Whether or not to us bias weights. Defaults to `True`.\n        is_channel_first (bool, optional): Set true if input shape is (b,c,h,w) and false if input shape is\n            (b,h,w,c). Defaults to `False`.\n        multiplication_type (MultiplicationType, optional): Type of algo used for the element wise multiplication\n            and reduction of the input and the filter weights. [`MultiplicationType.ELEMENT_WISE` |\n            `MultiplicationType.MATRIX_PRODUCT`]. MATRIX_PRODUCT is faster, but requires more memory. ELEMENT_WISE\n            is slower but requires less memory. Defaults to `MultiplicationType.ELEMENT_WISE`.\n        filter_initializer (tf.keras.initializers.Initializer, optional): Initializer to initialize the wheights of\n            the filter layer. Defaults to `None`.\n        bias_initializer (tf.keras.initializers.Initializer, optional): Initializer to initialize the wheights of\n            the bias weights. Defaults to `None`.\n        kwargs (Any): Additional key word arguments passed to the base class.\n    \"\"\"\n    super(FourierFilter2D, self).__init__(**kwargs)\n    self.filters = filters\n    self.use_bias = use_bias\n    self.is_channel_first = is_channel_first\n    self.multiplication_type = multiplication_type\n\n    filter_initializer = (\n        tf.keras.initializers.RandomUniform(-0.05, 0.05) if filter_initializer is None else filter_initializer\n    )\n    bias_initializer = tf.keras.initializers.Zeros() if bias_initializer is None else bias_initializer\n    self.filter_initializer = make_initializer_complex(filter_initializer)\n    self.bias_initializer = make_initializer_complex(bias_initializer)\n    self.multiply = self._get_multiplication_function(multiplication_type)\n\n    self.input_spec = tf.keras.layers.InputSpec(ndim=4, dtype=tf.complex64)\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.fourier_layer.FourierFilter2D.build","title":"build","text":"<pre><code>build(input_shape: tf.TensorShape) -&gt; None\n</code></pre> <p>Build layer depending on the <code>input_shape</code> (output shape of the previous layer).</p> <p>Parameters:</p> Name Type Description Default <code>input_shape</code> <code>tf.TensorShape</code> <p>Shape of the input tensor to this layer.</p> required Source code in <code>DeepSaki/layers/fourier_layer.py</code> <pre><code>def build(self, input_shape: tf.TensorShape) -&gt; None:\n    \"\"\"Build layer depending on the `input_shape` (output shape of the previous layer).\n\n    Args:\n        input_shape (tf.TensorShape): Shape of the input tensor to this layer.\n    \"\"\"\n    super(FourierFilter2D, self).build(input_shape)\n    if self.is_channel_first:\n        _, channel, height, width = input_shape\n    else:\n        _, height, width, channel = input_shape\n\n    self.fourier_filter = self.add_weight(\n        name=\"filter\",\n        shape=[self.filters, channel, height, width],\n        initializer=self.filter_initializer,\n        trainable=True,\n        dtype=tf.dtypes.complex64,\n    )\n\n    if self.use_bias:\n        self.fourier_bias = self.add_weight(\n            name=\"bias\",\n            shape=[self.filters, 1, 1],\n            initializer=self.bias_initializer,\n            trainable=True,\n            dtype=tf.dtypes.complex64,\n        )\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.fourier_layer.FourierFilter2D.call","title":"call","text":"<pre><code>call(inputs: tf.Tensor) -&gt; tf.Tensor\n</code></pre> <p>Calls the <code>FourierFilter2D</code> layer.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>tf.Tensor</code> <p>Complex valued tensor of shape (b,h,w,c) if <code>is_channel_first=False</code> or Tensor of shape</p> required <p>Returns:</p> Type Description <code>tf.Tensor</code> <p>Complex valued tensor of shape (b,h,w,<code>filters</code>) if <code>is_channel_first=False</code> or Tensor of shape (b,<code>filters</code>,h,w) if <code>is_channel_first=True</code>.</p> Source code in <code>DeepSaki/layers/fourier_layer.py</code> <pre><code>def call(self, inputs: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"Calls the `FourierFilter2D` layer.\n\n    Args:\n        inputs (tf.Tensor): Complex valued tensor of shape (b,h,w,c) if `is_channel_first=False` or Tensor of shape\n        (b,c,h,w) if `is_channel_first=True`.\n\n    Returns:\n        Complex valued tensor of shape (b,h,w,`filters`) if `is_channel_first=False` or Tensor of shape\n            (b,`filters`,h,w) if `is_channel_first=True`.\n    \"\"\"\n    if not self.is_channel_first:  # FFT2D is calculated over last two dimensions!\n        inputs = self._change_to_channel_first(inputs)\n\n    output = self.multiply(inputs, self.fourier_filter)\n\n    if self.use_bias:\n        output += self.fourier_bias\n\n    if not self.is_channel_first:  # reverse the channel configuration to its initial config\n        output = self._change_to_channel_last(output)\n\n    return output\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.fourier_layer.FourierFilter2D.get_config","title":"get_config","text":"<pre><code>get_config() -&gt; Dict[str, Any]\n</code></pre> <p>Serialization of the object.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with the class' variable names as keys.</p> Source code in <code>DeepSaki/layers/fourier_layer.py</code> <pre><code>def get_config(self) -&gt; Dict[str, Any]:\n    \"\"\"Serialization of the object.\n\n    Returns:\n        Dictionary with the class' variable names as keys.\n    \"\"\"\n    config = super(FourierFilter2D, self).get_config()\n    config.update(\n        {\n            \"filters\": self.filters,\n            \"use_bias\": self.use_bias,\n            \"filter_initializer\": self.filter_initializer,\n            \"bias_initializer\": self.bias_initializer,\n            \"is_channel_first\": self.is_channel_first,\n            \"multiplication_type\": self.multiplication_type,\n        }\n    )\n    return config\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.fourier_layer.FourierLayer","title":"FourierLayer","text":"<p>             Bases: <code>tf.keras.layers.Layer</code></p> <p>Base Class for Fourier Layers.</p>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.fourier_layer.FourierPooling2D","title":"FourierPooling2D","text":"<pre><code>FourierPooling2D(\n    is_channel_first: bool = False,\n    input_from_rfft: bool = False,\n    **kwargs: Any\n)\n</code></pre> <p>             Bases: <code>FourierLayer</code></p> <p>Pooling in frequency domain by truncating high frequencies using a center crop operation.</p> <p>Layer input is asumed to be in frequency domain and shifted, such that the center frequency is in the center of the grid.</p> <p>If this is the case, the center represents the frequency of 0Hz (hence an offset). The further away from the center the higher the frequency component. Center cropping removes high frequency components, hence can be seen as a low pass filter</p> <p>Initializes an instance of <code>FourierPooling2D</code>.</p> <p>Parameters:</p> Name Type Description Default <code>is_channel_first</code> <code>bool</code> <p>If True, input shape is assumed to be (<code>batch</code>,<code>channel</code>,<code>height</code>,<code>width</code>). If False, input shape is assumed to be (<code>batch</code>,<code>height</code>,<code>width</code>,<code>channel</code>). Defaults to False.</p> <code>False</code> <code>input_from_rfft</code> <code>bool</code> <p>If true, the input spectrum is assumed to be originated from an rFFT2D operation.</p> <code>False</code> <code>kwargs</code> <code>Any</code> <p>Additional key word arguments passed to the base class.</p> <code>{}</code> Source code in <code>DeepSaki/layers/fourier_layer.py</code> <pre><code>def __init__(\n    self,\n    is_channel_first: bool = False,\n    input_from_rfft: bool = False,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Initializes an instance of `FourierPooling2D`.\n\n    Args:\n        is_channel_first (bool, optional): If True, input shape is assumed to be (`batch`,`channel`,`height`,`width`).\n            If False, input shape is assumed to be (`batch`,`height`,`width`,`channel`). Defaults to False.\n        input_from_rfft (bool, optional): If true, the input spectrum is assumed to be originated from an rFFT2D\n            operation.\n        kwargs (Any): Additional key word arguments passed to the base class.\n    \"\"\"\n    super(FourierPooling2D, self).__init__(**kwargs)\n    self.is_channel_first = is_channel_first\n    self.input_from_rfft = input_from_rfft\n    self.input_spec = tf.keras.layers.InputSpec(ndim=4, dtype=tf.complex64)\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.fourier_layer.FourierPooling2D.build","title":"build","text":"<pre><code>build(input_shape: tf.TensorShape) -&gt; None\n</code></pre> <p>Build layer depending on the <code>input_shape</code> (output shape of the previous layer).</p> <p>Parameters:</p> Name Type Description Default <code>input_shape</code> <code>tf.TensorShape</code> <p>Shape of the input tensor to this layer.</p> required Source code in <code>DeepSaki/layers/fourier_layer.py</code> <pre><code>def build(self, input_shape: tf.TensorShape) -&gt; None:\n    \"\"\"Build layer depending on the `input_shape` (output shape of the previous layer).\n\n    Args:\n        input_shape (tf.TensorShape): Shape of the input tensor to this layer.\n    \"\"\"\n    super(FourierPooling2D, self).build(input_shape)\n    if self.is_channel_first:\n        _, channels, height, width = input_shape\n    else:\n        _, height, width, channels = input_shape\n\n    offset_height = height // 4\n    offset_width = 0 if self.input_from_rfft else width // 4\n    target_height = height // 2\n    # + 1 is important. if real FFT width is usually odd.\n    target_width = (width + 1) // 2\n\n    if self.is_channel_first:\n        self.slice_begin = [0, 0, offset_height, offset_width]\n        self.slice_size = [-1, channels, target_height, target_width]\n    else:\n        self.slice_begin = [0, offset_height, offset_width, 0]\n        self.slice_size = [-1, target_height, target_width, channels]\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.fourier_layer.FourierPooling2D.call","title":"call","text":"<pre><code>call(inputs: tf.Tensor) -&gt; tf.Tensor\n</code></pre> <p>Calls the <code>FourierPooling2D</code> layer.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>tf.Tensor</code> <p>Complex valued tensor of shape (<code>batch</code>,<code>height</code>,<code>width</code>,<code>channel</code>) or (<code>batch</code>,<code>channel</code>,<code>height</code>,<code>width</code>). Tensor is asumed to be in frequency domain of type <code>tf.complex64</code> or <code>tf.complex128</code>.</p> required <p>Returns:</p> Type Description <code>tf.Tensor</code> <p>Pooled tensor of shape (<code>batch</code>,<code>channel</code>,<code>height/2</code>,<code>width/2</code>) or (<code>batch</code>,<code>height/2</code>,<code>width/2</code>,<code>channel</code>)</p> Source code in <code>DeepSaki/layers/fourier_layer.py</code> <pre><code>def call(self, inputs: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"Calls the `FourierPooling2D` layer.\n\n    Args:\n        inputs (tf.Tensor): Complex valued tensor of shape (`batch`,`height`,`width`,`channel`) or\n            (`batch`,`channel`,`height`,`width`). Tensor is asumed to be in frequency domain of type `tf.complex64`\n            or `tf.complex128`.\n\n    Returns:\n        Pooled tensor of shape (`batch`,`channel`,`height/2`,`width/2`) or (`batch`,`height/2`,`width/2`,`channel`)\n    \"\"\"\n    return tf.slice(inputs, begin=self.slice_begin, size=self.slice_size)\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.fourier_layer.FourierPooling2D.get_config","title":"get_config","text":"<pre><code>get_config() -&gt; Dict[str, Any]\n</code></pre> <p>Serialization of the object.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with the class' variable names as keys.</p> Source code in <code>DeepSaki/layers/fourier_layer.py</code> <pre><code>def get_config(self) -&gt; Dict[str, Any]:\n    \"\"\"Serialization of the object.\n\n    Returns:\n        Dictionary with the class' variable names as keys.\n    \"\"\"\n    config = super(FourierPooling2D, self).get_config()\n    config.update(\n        {\n            \"is_channel_first\": self.is_channel_first,\n            \"input_from_rfft\": self.input_from_rfft,\n        }\n    )\n    return config\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.fourier_layer.FrequencyFilter","title":"FrequencyFilter","text":"<p>             Bases: <code>Enum</code></p> <p><code>Enum</code> used to define valid filters for <code>rFFT2DFilter</code>.</p> <p>Attributes:</p> Name Type Description <code>LOW_PASS</code> <code>int</code> <p>Indicates that low frequency components shall be kept and high frequency components shall be filtered.</p> <code>HIGH_PASS</code> <code>int</code> <p>Indicates that high frequency components shall be kept and low frequency components shall be filtered.</p>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.fourier_layer.MultiplicationType","title":"MultiplicationType","text":"<p>             Bases: <code>Enum</code></p> <p><code>Enum</code> used to define how two matrices shall be multiplied.</p> <p>Attributes:</p> Name Type Description <code>ELEMENT_WISE</code> <code>int</code> <p>Indicates to apply an element-wise multiplication of 2 tensors.</p> <code>MATRIX_PRODUCT</code> <code>int</code> <p>Indicates to apply a matrix-product between 2 tensors.</p>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.fourier_layer.iFFT2D","title":"iFFT2D","text":"<pre><code>iFFT2D(\n    is_channel_first: bool = False,\n    apply_real_fft: bool = False,\n    shift_fft: bool = True,\n    fft_length: Optional[Tuple[int, int]] = None,\n    **kwargs: Any\n)\n</code></pre> <p>             Bases: <code>FourierLayer</code></p> <p>Calculates the 2D inverse FFT.</p> Know what to expect apply_real_fft input generated by input shape input dtype output dtype output shape True FFT2D(apply_real_fft=True) (1,8,8,3) complex real (1,8,5,3) false FFT2D(apply_real_fft=False) (1,8,8,3) complex complex (1,8,8,3) <p>Examples: <pre><code>import DeepSaki as dsk\nimport tensorflow as tf\n\nreal_data = tf.random.normal(shape=(8,64,64,3))\ncomplex_data = tf.complex(real_data,real_data)\n\n# Real FFT with real valued data\nx = dsk.layers.FFT2D(apply_real_fft = True)(real_data) #&lt;tf.Tensor: shape=(8, 64, 33, 3), dtype=complex64&gt;\nx = dsk.layers.iFFT2D(apply_real_fft = True)(x) #&lt;tf.Tensor: shape=(8, 64, 64, 3), dtype=float32&gt;\n\n# Standard FFT with complex valued data\nx = dsk.layers.FFT2D(apply_real_fft = False)(complex_data) #&lt;tf.Tensor: shape=(8, 64, 64, 3), dtype=complex64&gt;\nx = dsk.layers.iFFT2D(apply_real_fft = False)(x) #&lt;tf.Tensor: shape=(8, 64, 64, 3), dtype=complex64&gt;\n\n# Standard FFT with real valued data - FFT2D will create a pseude complex tensor tf.complex(real, tf.zeros_like(real))\nx = dsk.layers.FFT2D(apply_real_fft = False)(real_data) #&lt;tf.Tensor: shape=(8, 64, 64, 3), dtype=complex64&gt;\nx = dsk.layers.iFFT2D(apply_real_fft = False)(x) #&lt;tf.Tensor: shape=(8, 64, 64, 3), dtype=complex64&gt;\nx = tf.math.real(x) # can be casted to real without issues, since imag values are all zero\n</code></pre></p> <p>Initializes the <code>iFFT2D</code> layer.</p> <p>Parameters:</p> Name Type Description Default <code>is_channel_first</code> <code>bool</code> <p>Set true if input shape is (b,c,h,w) and false if input shape is (b,h,w,c). Defaults to <code>False</code>.</p> <code>False</code> <code>apply_real_fft</code> <code>bool</code> <p>If True, rfft2D is applied, which assumes real valued inputs and halves the width of the output. If False, fft2D is applied, which assumes complex input. Defaults to False.</p> <code>False</code> <code>shift_fft</code> <code>bool</code> <p>If true, low frequency components are centered. Defaults to True.</p> <code>True</code> <code>fft_length</code> <code>Optional[Tuple[int, int]]</code> <p>The FFT length for each dimension of the real FFT. Defaults to None.</p> <code>None</code> <code>kwargs</code> <code>Any</code> <p>keyword arguments passed to the parent class tf.keras.layers.Layer.</p> <code>{}</code> Source code in <code>DeepSaki/layers/fourier_layer.py</code> <pre><code>def __init__(\n    self,\n    is_channel_first: bool = False,\n    apply_real_fft: bool = False,\n    shift_fft: bool = True,\n    fft_length: Optional[Tuple[int, int]] = None,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Initializes the `iFFT2D` layer.\n\n    Args:\n        is_channel_first (bool, optional): Set true if input shape is (b,c,h,w) and false if input shape is\n            (b,h,w,c). Defaults to `False`.\n        apply_real_fft (bool, optional): If True, rfft2D is applied, which assumes real valued inputs and halves the\n            width of the output. If False, fft2D is applied, which assumes complex input. Defaults to False.\n        shift_fft (bool, optional): If true, low frequency components are centered. Defaults to True.\n        fft_length (Optional[Tuple[int,int]]): The FFT length for each dimension of the real FFT. Defaults to None.\n        kwargs (Any): keyword arguments passed to the parent class tf.keras.layers.Layer.\n    \"\"\"\n    super(iFFT2D, self).__init__(**kwargs)\n    self.is_channel_first = is_channel_first\n    self.apply_real_fft = apply_real_fft\n    self.shift_fft = shift_fft\n    self.fft_length = fft_length\n    self.input_spec = tf.keras.layers.InputSpec(ndim=4, dtype=tf.complex64)\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.fourier_layer.iFFT2D.call","title":"call","text":"<pre><code>call(inputs: tf.Tensor) -&gt; tf.Tensor\n</code></pre> <p>Calls the <code>iFFT2D</code> layer.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>tf.Tensor</code> <p>Complex valued input Tensor. Shape depends on attributes <code>is_channel_first</code> and <code>apply_real_fft</code>.  <code>is_channel_first=False</code>, <code>apply_real_fft=False</code>: Expected shape of input tensor: (b,h,w,c)  <code>is_channel_first=True</code>, <code>apply_real_fft=False</code>: Expected shape of input tensor: (b,c,h,w)  <code>is_channel_first=False</code>, <code>apply_real_fft=True</code>: Expected shape of input tensor: (b,h,w=h/2+1,c)  <code>is_channel_first=True</code>, <code>apply_real_fft=True</code>: Expected shape of input tensor: (b,c,h,w=h/2+1)</p> required <p>Returns:</p> Type Description <code>tf.Tensor</code> <p>Tensor of shape:  <code>is_channel_first=False</code>: Expected shape of input tensor: (b,h,w=h,c)  <code>is_channel_first=True</code>: Expected shape of input tensor: (b,c,h,w=h)</p> Source code in <code>DeepSaki/layers/fourier_layer.py</code> <pre><code>def call(self, inputs: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"Calls the `iFFT2D` layer.\n\n    Args:\n        inputs (tf.Tensor): Complex valued input Tensor. Shape depends on attributes `is_channel_first` and `apply_real_fft`. &lt;br&gt;\n            `is_channel_first=False`, `apply_real_fft=False`: Expected shape of input tensor: (b,h,w,c) &lt;br&gt;\n            `is_channel_first=True`, `apply_real_fft=False`: Expected shape of input tensor: (b,c,h,w) &lt;br&gt;\n            `is_channel_first=False`, `apply_real_fft=True`: Expected shape of input tensor: (b,h,w=h/2+1,c) &lt;br&gt;\n            `is_channel_first=True`, `apply_real_fft=True`: Expected shape of input tensor: (b,c,h,w=h/2+1)\n\n    Returns:\n        Tensor of shape: &lt;br&gt;\n            `is_channel_first=False`: Expected shape of input tensor: (b,h,w=h,c) &lt;br&gt;\n            `is_channel_first=True`: Expected shape of input tensor: (b,c,h,w=h)\n    \"\"\"\n    if not self.is_channel_first:\n        inputs = self._change_to_channel_first(inputs)\n    x = inputs\n\n    if self.apply_real_fft:\n        if self.shift_fft:\n            x = tf.signal.ifftshift(x, axes=[-2])\n        x = tf.signal.irfft2d(x, fft_length=self.fft_length)\n    else:\n        if self.shift_fft:\n            x = tf.signal.ifftshift(x)\n        x = tf.signal.ifft2d(x)\n\n    if not self.is_channel_first:  # reverse the channel configuration to its initial config\n        x = self._change_to_channel_last(x)\n\n    return x\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.fourier_layer.iFFT2D.get_config","title":"get_config","text":"<pre><code>get_config() -&gt; Dict[str, Any]\n</code></pre> <p>Serialization of the object.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with the class' variable names as keys.</p> Source code in <code>DeepSaki/layers/fourier_layer.py</code> <pre><code>def get_config(self) -&gt; Dict[str, Any]:\n    \"\"\"Serialization of the object.\n\n    Returns:\n        Dictionary with the class' variable names as keys.\n    \"\"\"\n    config = super(iFFT2D, self).get_config()\n    config.update(\n        {\n            \"is_channel_first\": self.is_channel_first,\n            \"apply_real_fft\": self.apply_real_fft,\n            \"shift_fft\": self.shift_fft,\n            \"fft_length\": self.fft_length,\n        }\n    )\n    return config\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.fourier_layer.iFFT3D","title":"iFFT3D","text":"<pre><code>iFFT3D(\n    is_channel_first: bool = False,\n    apply_real_fft: bool = False,\n    shift_fft: bool = True,\n    fft_length: Optional[Tuple[int, int, int]] = None,\n    **kwargs: Any\n)\n</code></pre> <p>             Bases: <code>FourierLayer</code></p> <p>Calculates the 3D inverse FFT.</p> <p>Initializes the <code>iFFT3D</code> layer.</p> <p>Parameters:</p> Name Type Description Default <code>is_channel_first</code> <code>bool</code> <p>Set true if input shape is (b,c,h,w) or (b,c,f,h,w) and false if input shape is (b,h,w,c) or (b,f,h,w,c). Defaults to <code>False</code>.</p> <code>False</code> <code>apply_real_fft</code> <code>bool</code> <p>If True, rfft3D is applied, which assumes real valued inputs and halves the width of the output. If False, fft3D is applied, which assumes complex input. Defaults to False.</p> <code>False</code> <code>shift_fft</code> <code>bool</code> <p>If true, low frequency components are centered. Defaults to True.</p> <code>True</code> <code>fft_length</code> <code>Optional[Tuple[int, int, int]]</code> <p>The FFT length for each dimension of the real FFT. Defaults to None.</p> <code>None</code> <code>kwargs</code> <code>Any</code> <p>keyword arguments passed to the parent class tf.keras.layers.Layer.</p> <code>{}</code> Source code in <code>DeepSaki/layers/fourier_layer.py</code> <pre><code>def __init__(\n    self,\n    is_channel_first: bool = False,\n    apply_real_fft: bool = False,\n    shift_fft: bool = True,\n    fft_length: Optional[Tuple[int, int, int]] = None,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Initializes the `iFFT3D` layer.\n\n    Args:\n        is_channel_first (bool, optional): Set true if input shape is (b,c,h,w) or (b,c,f,h,w) and false if input\n            shape is (b,h,w,c) or (b,f,h,w,c). Defaults to `False`.\n        apply_real_fft (bool, optional): If True, rfft3D is applied, which assumes real valued inputs and halves the\n            width of the output. If False, fft3D is applied, which assumes complex input. Defaults to False.\n        shift_fft (bool, optional): If true, low frequency components are centered. Defaults to True.\n        fft_length (Optional[Tuple[int,int,int]]): The FFT length for each dimension of the real FFT. Defaults to None.\n        kwargs (Any): keyword arguments passed to the parent class tf.keras.layers.Layer.\n    \"\"\"\n    super(iFFT3D, self).__init__(**kwargs)\n    self.is_channel_first = is_channel_first\n    self.apply_real_fft = apply_real_fft\n    self.shift_fft = shift_fft\n    self.fft_length = fft_length\n    self.input_spec = tf.keras.layers.InputSpec(min_ndim=4, max_ndim=5, dtype=tf.complex64)\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.fourier_layer.iFFT3D.call","title":"call","text":"<pre><code>call(inputs: tf.Tensor) -&gt; tf.Tensor\n</code></pre> <p>Calls the <code>iFFT3D</code> layer.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>tf.Tensor</code> <p>Complex valued input Tensor. Shape depends on attributes <code>is_channel_first</code> and <code>apply_real_fft</code>.  <code>is_channel_first=False</code>, <code>apply_real_fft=False</code>: Expected shape of input tensor: (b,h,w,c) or (b,f,h,w,c)  <code>is_channel_first=True</code>, <code>apply_real_fft=False</code>: Expected shape of input tensor: (b,c,h,w) or (b,c,f,h,w)  <code>is_channel_first=False</code>, <code>apply_real_fft=True</code>: Expected shape of input tensor: (b,h,w=h/2+1,c) or (b,f,h,w=h/2+1,c)  <code>is_channel_first=True</code>, <code>apply_real_fft=True</code>: Expected shape of input tensor: (b,c,h,w=h/2+1) or (b,c,f,h,w=h/2+1)</p> required <p>Returns:</p> Type Description <code>tf.Tensor</code> <p>Tensor of shape:  <code>is_channel_first=False</code>: Expected shape of input tensor: (b,h,w=h,c) or (b,f,h,w=h,c)  <code>is_channel_first=True</code>: Expected shape of input tensor: (b,c,h,w=h) or (b,c,f,h,w=h)</p> Source code in <code>DeepSaki/layers/fourier_layer.py</code> <pre><code>def call(self, inputs: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"Calls the `iFFT3D` layer.\n\n    Args:\n        inputs (tf.Tensor): Complex valued input Tensor. Shape depends on attributes `is_channel_first` and `apply_real_fft`. &lt;br&gt;\n            `is_channel_first=False`, `apply_real_fft=False`: Expected shape of input tensor: (b,h,w,c) or (b,f,h,w,c) &lt;br&gt;\n            `is_channel_first=True`, `apply_real_fft=False`: Expected shape of input tensor: (b,c,h,w) or (b,c,f,h,w) &lt;br&gt;\n            `is_channel_first=False`, `apply_real_fft=True`: Expected shape of input tensor: (b,h,w=h/2+1,c) or (b,f,h,w=h/2+1,c) &lt;br&gt;\n            `is_channel_first=True`, `apply_real_fft=True`: Expected shape of input tensor: (b,c,h,w=h/2+1) or (b,c,f,h,w=h/2+1)\n\n    Returns:\n        Tensor of shape: &lt;br&gt;\n            `is_channel_first=False`: Expected shape of input tensor: (b,h,w=h,c) or (b,f,h,w=h,c) &lt;br&gt;\n            `is_channel_first=True`: Expected shape of input tensor: (b,c,h,w=h) or (b,c,f,h,w=h)\n    \"\"\"\n    if not self.is_channel_first:\n        inputs = self._change_to_channel_first(inputs)\n    x = inputs\n\n    if self.apply_real_fft:\n        if self.shift_fft:\n            x = tf.signal.ifftshift(x, axes=[-2])\n        x = tf.signal.irfft3d(x, fft_length=self.fft_length)\n    else:\n        if self.shift_fft:\n            x = tf.signal.ifftshift(x)\n        x = tf.signal.ifft3d(x)\n\n    if not self.is_channel_first:\n        x = self._change_to_channel_last(x)\n\n    return x\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.fourier_layer.iFFT3D.get_config","title":"get_config","text":"<pre><code>get_config() -&gt; Dict[str, Any]\n</code></pre> <p>Serialization of the object.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with the class' variable names as keys.</p> Source code in <code>DeepSaki/layers/fourier_layer.py</code> <pre><code>def get_config(self) -&gt; Dict[str, Any]:\n    \"\"\"Serialization of the object.\n\n    Returns:\n        Dictionary with the class' variable names as keys.\n    \"\"\"\n    config = super(iFFT3D, self).get_config()\n    config.update(\n        {\n            \"is_channel_first\": self.is_channel_first,\n            \"apply_real_fft\": self.apply_real_fft,\n            \"shift_fft\": self.shift_fft,\n            \"fft_length\": self.fft_length,\n        }\n    )\n    return config\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.fourier_layer.rFFT2DFilter","title":"rFFT2DFilter","text":"<pre><code>rFFT2DFilter(\n    is_channel_first: bool = False,\n    filter_type: Literal[\n        FrequencyFilter.LOW_PASS, FrequencyFilter.HIGH_PASS\n    ] = FrequencyFilter.LOW_PASS,\n    **kwargs: Any\n)\n</code></pre> <p>             Bases: <code>FourierLayer</code></p> <p>Low or high pass filtering by truncating higher or lower frequencies in the frequency domain.</p> <p>Layer input is asumed to be in spatial domain. It is transformed into the frequency domain applying a 2D real FFT. Then the center-crop operation is performed and depending of the shift, either low or high frequencies are removed. Afterwards, the cropped region is zero padded and then the inverse real 2D FFT is calculated to transform back into the spatial domain.</p> <p>Initialize the <code>rFFT2DFilter</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>is_channel_first</code> <code>bool</code> <p>If True, input shape is assumed to be (<code>batch</code>,<code>channel</code>,<code>height</code>,<code>width</code>). If False, input shape is assumed to be (<code>batch</code>,<code>height</code>,<code>width</code>,<code>channel</code>). Defaults to False.</p> <code>False</code> <code>filter_type</code> <code>Literal[Frequency_Filter.LOW_PASS, Frequency_Filter.HIGH_PASS]</code> <p>If <code>Frequency_Filter.LOW_PASS</code>, high frequency values are truncated, if <code>Frequency_Filter.HIGH_PASS</code>, low frequencies are truncated. Defaults to <code>Frequency_Filter.LOW_PASS</code>.</p> <code>FrequencyFilter.LOW_PASS</code> <code>kwargs</code> <code>Any</code> <p>Additional key word arguments passed to the base class.</p> <code>{}</code> Source code in <code>DeepSaki/layers/fourier_layer.py</code> <pre><code>def __init__(\n    self,\n    is_channel_first: bool = False,\n    filter_type: Literal[FrequencyFilter.LOW_PASS, FrequencyFilter.HIGH_PASS] = FrequencyFilter.LOW_PASS,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Initialize the `rFFT2DFilter` object.\n\n    Args:\n        is_channel_first (bool, optional): If True, input shape is assumed to be (`batch`,`channel`,`height`,`width`).\n            If False, input shape is assumed to be (`batch`,`height`,`width`,`channel`). Defaults to False.\n        filter_type (Literal[Frequency_Filter.LOW_PASS,Frequency_Filter.HIGH_PASS], optional): If\n            `Frequency_Filter.LOW_PASS`, high frequency values are truncated, if `Frequency_Filter.HIGH_PASS`, low\n            frequencies are truncated. Defaults to `Frequency_Filter.LOW_PASS`.\n        kwargs (Any): Additional key word arguments passed to the base class.\n    \"\"\"\n    super(rFFT2DFilter, self).__init__(**kwargs)\n    self.is_channel_first = is_channel_first\n    self.filter_type = filter_type\n    self.input_spec = tf.keras.layers.InputSpec(ndim=4, dtype=tf.float32)\n\n    self.shift_fft = self.filter_type == FrequencyFilter.LOW_PASS\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.fourier_layer.rFFT2DFilter.build","title":"build","text":"<pre><code>build(input_shape: tf.TensorShape) -&gt; None\n</code></pre> <p>Build layer depending on the <code>input_shape</code> (output shape of the previous layer).</p> <p>Parameters:</p> Name Type Description Default <code>input_shape</code> <code>tf.TensorShape</code> <p>Shape of the input tensor to this layer.</p> required Source code in <code>DeepSaki/layers/fourier_layer.py</code> <pre><code>def build(self, input_shape: tf.TensorShape) -&gt; None:\n    \"\"\"Build layer depending on the `input_shape` (output shape of the previous layer).\n\n    Args:\n        input_shape (tf.TensorShape): Shape of the input tensor to this layer.\n    \"\"\"\n    super(rFFT2DFilter, self).build(input_shape)\n    if self.is_channel_first:\n        _, _, height, width = input_shape\n    else:\n        _, height, width, _ = input_shape\n\n    self.rfft2d = FFT2D(self.is_channel_first, apply_real_fft=True, shift_fft=self.shift_fft)\n    self.fourier_pooling_2d = FourierPooling2D(self.is_channel_first, input_from_rfft=True)\n    self.irfft2d = iFFT2D(\n        self.is_channel_first, apply_real_fft=True, shift_fft=self.shift_fft, fft_length=(height, width)\n    )\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.fourier_layer.rFFT2DFilter.call","title":"call","text":"<pre><code>call(inputs: tf.Tensor) -&gt; tf.Tensor\n</code></pre> <p>Calls the <code>rFFT2DFilter</code> layer.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>tf.Tensor</code> <p>Tensor of shape (<code>batch</code>,<code>height</code>,<code>width</code>,<code>channel</code>) or (<code>batch</code>,<code>channel</code>,<code>height</code>,<code>width</code>).</p> required <p>Returns:</p> Type Description <code>tf.Tensor</code> <p>Filtered tensor with shape (<code>batch</code>,<code>channel</code>,<code>height</code>,<code>width</code>).</p> Source code in <code>DeepSaki/layers/fourier_layer.py</code> <pre><code>def call(self, inputs: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"Calls the `rFFT2DFilter` layer.\n\n    Args:\n        inputs (tf.Tensor): Tensor of shape (`batch`,`height`,`width`,`channel`) or\n            (`batch`,`channel`,`height`,`width`).\n\n    Returns:\n        Filtered tensor with shape (`batch`,`channel`,`height`,`width`).\n    \"\"\"\n    x = self.rfft2d(inputs)\n    x = self.fourier_pooling_2d(x)\n    return self.irfft2d(x)\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.fourier_layer.rFFT2DFilter.get_config","title":"get_config","text":"<pre><code>get_config() -&gt; Dict[str, Any]\n</code></pre> <p>Serialization of the object.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with the class' variable names as keys.</p> Source code in <code>DeepSaki/layers/fourier_layer.py</code> <pre><code>def get_config(self) -&gt; Dict[str, Any]:\n    \"\"\"Serialization of the object.\n\n    Returns:\n        Dictionary with the class' variable names as keys.\n    \"\"\"\n    config = super(rFFT2DFilter, self).get_config()\n    config.update({\"is_channel_first\": self.is_channel_first, \"filter_type\": self.filter_type})\n    return config\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.sub_model_composites.Bottleneck","title":"Bottleneck","text":"<pre><code>Bottleneck(\n    n_bottleneck_blocks: int = 3,\n    kernels: int = 3,\n    split_kernels: bool = False,\n    number_of_blocks: int = 2,\n    use_ResidualBlock: bool = False,\n    activation: str = \"leaky_relu\",\n    dropout_rate: float = 0.2,\n    channel_list: Optional[List[int]] = None,\n    use_spec_norm: bool = False,\n    use_bias: bool = True,\n    residual_cardinality: int = 1,\n    padding: PaddingType = PaddingType.ZERO,\n    kernel_initializer: Optional[\n        tf.keras.initializers.Initializer\n    ] = None,\n    gamma_initializer: Optional[\n        tf.keras.initializers.Initializer\n    ] = None,\n)\n</code></pre> <p>             Bases: <code>tf.keras.layers.Layer</code></p> <p>Bottlenecks are sub-model blocks in auto-encoder-like models such as UNet or ResNet.</p> <p>It is composed of multiple convolution blocks which might have residuals.</p> <p>Can be combined with <code>dsk.layers.Encoder</code> and <code>dsk.layers.Decoder</code> to form an auto encoder model.</p> Tipp <p>Checkout the dsk.models api to find models using this layer.</p> <p>Initializes the <code>Bottleneck</code> layer.</p> <p>Parameters:</p> Name Type Description Default <code>n_bottleneck_blocks</code> <code>int</code> <p>Number of consecutive blocks. Defaults to 3.</p> <code>3</code> <code>kernels</code> <code>int</code> <p>Size of the convolutions kernels. Defaults to 3.</p> <code>3</code> <code>split_kernels</code> <code>bool</code> <p>To decrease the number of parameters, a convolution with the kernel_size <code>(kernel,kernel)</code> can be splitted into two consecutive convolutions with the kernel_size <code>(kernel,1)</code> and <code>(1,kernel)</code> respectivly. Defaults to False.</p> <code>False</code> <code>number_of_blocks</code> <code>int</code> <p>: Number of consecutive conv layers within a basic building block. Defaults to 2.</p> <code>2</code> <code>use_ResidualBlock</code> <code>bool</code> <p>Whether or not to use the <code>ResidualBlock</code> instead of the <code>Conv2DBlock</code>. Defaults to False.</p> <code>False</code> <code>activation</code> <code>str</code> <p>String literal or tensorflow activation function object to obtain activation function. Defaults to \"leaky_relu\".</p> <code>'leaky_relu'</code> <code>dropout_rate</code> <code>float</code> <p>Probability of the dropout layer. If the preceeding layer has more than one channel, spatial dropout is applied, otherwise standard dropout. Defaults to 0.2.</p> <code>0.2</code> <code>channel_list</code> <code>Optional[List[int]]</code> <p>Alternativly to number_of_layers and filters, a list with the disired filters for each level can be provided. e.g. channel_list = [64, 128, 256] results in a 3-level Decoder with 64, 128, 256 filters for level 1, 2 and 3 respectivly. Defaults to None.</p> <code>None</code> <code>use_spec_norm</code> <code>bool</code> <p>Applies spectral normalization to convolutional and dense layers. Defaults to False.</p> <code>False</code> <code>use_bias</code> <code>bool</code> <p>Whether convolutions and dense layers include a bias or not. Defaults to True.</p> <code>True</code> <code>residual_cardinality</code> <code>int</code> <p>Cardinality for the <code>ResidualBlock</code>. Defaults to 1.</p> <code>1</code> <code>padding</code> <code>PaddingType</code> <p>Padding type. Defaults to PaddingType.ZERO.</p> <code>PaddingType.ZERO</code> <code>kernel_initializer</code> <code>tf.keras.initializers.Initializer</code> <p>Initialization of the convolutions kernels. Defaults to None.</p> <code>None</code> <code>gamma_initializer</code> <code>tf.keras.initializers.Initializer</code> <p>Initialization of the normalization layers. Defaults to None.</p> <code>None</code> Source code in <code>DeepSaki/layers/sub_model_composites.py</code> <pre><code>def __init__(\n    self,\n    n_bottleneck_blocks: int = 3,\n    kernels: int = 3,\n    split_kernels: bool = False,\n    number_of_blocks: int = 2,\n    use_ResidualBlock: bool = False,\n    activation: str = \"leaky_relu\",\n    dropout_rate: float = 0.2,\n    channel_list: Optional[List[int]] = None,\n    use_spec_norm: bool = False,\n    use_bias: bool = True,\n    residual_cardinality: int = 1,\n    padding: PaddingType = PaddingType.ZERO,\n    kernel_initializer: Optional[tf.keras.initializers.Initializer] = None,\n    gamma_initializer: Optional[tf.keras.initializers.Initializer] = None,\n) -&gt; None:\n    \"\"\"Initializes the `Bottleneck` layer.\n\n    Args:\n        n_bottleneck_blocks (int, optional): Number of consecutive blocks. Defaults to 3.\n        kernels (int, optional): Size of the convolutions kernels. Defaults to 3.\n        split_kernels (bool, optional): To decrease the number of parameters, a convolution with the kernel_size\n            `(kernel,kernel)` can be splitted into two consecutive convolutions with the kernel_size `(kernel,1)`\n            and `(1,kernel)` respectivly. Defaults to False.\n        number_of_blocks (int, optional): : Number of consecutive conv layers within a basic building block.\n            Defaults to 2.\n        use_ResidualBlock (bool, optional): Whether or not to use the `ResidualBlock` instead of the\n            `Conv2DBlock`. Defaults to False.\n        activation (str, optional): String literal or tensorflow activation function object to obtain activation\n            function. Defaults to \"leaky_relu\".\n        dropout_rate (float, optional): Probability of the dropout layer. If the preceeding layer has more than one\n            channel, spatial dropout is applied, otherwise standard dropout. Defaults to 0.2.\n        channel_list (Optional[List[int]], optional): Alternativly to number_of_layers and filters, a list with the\n            disired filters for each level can be provided. e.g. channel_list = [64, 128, 256] results in a 3-level\n            Decoder with 64, 128, 256 filters for level 1, 2 and 3 respectivly. Defaults to None.\n        use_spec_norm (bool, optional): Applies spectral normalization to convolutional and dense layers. Defaults\n            to False.\n        use_bias (bool, optional): Whether convolutions and dense layers include a bias or not. Defaults to True.\n        residual_cardinality (int, optional): Cardinality for the `ResidualBlock`. Defaults to 1.\n        padding (PaddingType, optional): Padding type. Defaults to PaddingType.ZERO.\n        kernel_initializer (tf.keras.initializers.Initializer, optional): Initialization of the convolutions kernels.\n            Defaults to None.\n        gamma_initializer (tf.keras.initializers.Initializer, optional): Initialization of the normalization layers.\n            Defaults to None.\n    \"\"\"\n    super(Bottleneck, self).__init__()\n    self.use_ResidualBlock = use_ResidualBlock\n    self.n_bottleneck_blocks = n_bottleneck_blocks\n    self.kernels = kernels\n    self.split_kernels = split_kernels\n    self.number_of_blocks = number_of_blocks\n    self.activation = activation\n    self.dropout_rate = dropout_rate\n    self.channel_list = channel_list\n    self.use_spec_norm = use_spec_norm\n    self.use_bias = use_bias\n    self.residual_cardinality = residual_cardinality\n    self.padding = padding\n    self.kernel_initializer = kernel_initializer\n    self.gamma_initializer = gamma_initializer\n    self.input_spec = tf.keras.layers.InputSpec(ndim=4, dtype=tf.float32)\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.sub_model_composites.Bottleneck.build","title":"build","text":"<pre><code>build(input_shape: tf.TensorShape) -&gt; None\n</code></pre> <p>Build layer depending on the <code>input_shape</code> (output shape of the previous layer).</p> <p>Parameters:</p> Name Type Description Default <code>input_shape</code> <code>tf.TensorShape</code> <p>Shape of the input tensor to this layer.</p> required Source code in <code>DeepSaki/layers/sub_model_composites.py</code> <pre><code>def build(self, input_shape: tf.TensorShape) -&gt; None:\n    \"\"\"Build layer depending on the `input_shape` (output shape of the previous layer).\n\n    Args:\n        input_shape (tf.TensorShape): Shape of the input tensor to this layer.\n    \"\"\"\n    super(Bottleneck, self).build(input_shape)\n\n    if self.channel_list is None:\n        ch = input_shape[-1]\n        self.channel_list = [ch for _ in range(self.n_bottleneck_blocks)]\n\n    self.layers = []\n    for ch in self.channel_list:\n        if self.use_ResidualBlock:\n            self.layers.append(\n                ResidualBlock(\n                    activation=self.activation,\n                    filters=ch,\n                    kernels=self.kernels,\n                    number_of_blocks=self.number_of_blocks,\n                    use_spec_norm=self.use_spec_norm,\n                    use_bias=self.use_bias,\n                    residual_cardinality=self.residual_cardinality,\n                    padding=self.padding,\n                    kernel_initializer=self.kernel_initializer,\n                    gamma_initializer=self.gamma_initializer,\n                )\n            )\n        else:\n            self.layers.append(\n                Conv2DBlock(\n                    filters=ch,\n                    kernels=self.kernels,\n                    split_kernels=self.split_kernels,\n                    number_of_blocks=self.number_of_blocks,\n                    activation=self.activation,\n                    use_spec_norm=self.use_spec_norm,\n                    use_bias=self.use_bias,\n                    padding=self.padding,\n                    kernel_initializer=self.kernel_initializer,\n                    gamma_initializer=self.gamma_initializer,\n                )\n            )\n\n    self.dropout = dropout_func(self.channel_list[-1], self.dropout_rate)\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.sub_model_composites.Bottleneck.call","title":"call","text":"<pre><code>call(inputs: tf.Tensor) -&gt; tf.Tensor\n</code></pre> <p>Calls the <code>Bottleneck</code> layer.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>tf.Tensor</code> <p>Input tensor of shape (batch, height, width, channel)</p> required <p>Returns:</p> Type Description <code>tf.Tensor</code> <p>Tensor of shape (batch, height, width, channel)</p> Source code in <code>DeepSaki/layers/sub_model_composites.py</code> <pre><code>def call(self, inputs: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"Calls the `Bottleneck` layer.\n\n    Args:\n        inputs (tf.Tensor): Input tensor of shape (batch, height, width, channel)\n\n    Returns:\n        Tensor of shape (batch, height, width, channel)\n    \"\"\"\n    x = inputs\n\n    for layer in self.layers:\n        x = layer(x)\n\n    if self.dropout_rate &gt; 0:\n        x = self.dropout(x)\n\n    return x\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.sub_model_composites.Bottleneck.get_config","title":"get_config","text":"<pre><code>get_config() -&gt; Dict[str, Any]\n</code></pre> <p>Serialization of the object.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with the class' variable names as keys.</p> Source code in <code>DeepSaki/layers/sub_model_composites.py</code> <pre><code>def get_config(self) -&gt; Dict[str, Any]:\n    \"\"\"Serialization of the object.\n\n    Returns:\n        Dictionary with the class' variable names as keys.\n    \"\"\"\n    config = super(Bottleneck, self).get_config()\n    config.update(\n        {\n            \"use_ResidualBlock\": self.use_ResidualBlock,\n            \"n_bottleneck_blocks\": self.n_bottleneck_blocks,\n            \"kernels\": self.kernels,\n            \"split_kernels\": self.split_kernels,\n            \"number_of_blocks\": self.number_of_blocks,\n            \"activation\": self.activation,\n            \"dropout_rate\": self.dropout_rate,\n            \"use_spec_norm\": self.use_spec_norm,\n            \"use_bias\": self.use_bias,\n            \"channel_list\": self.channel_list,\n            \"residual_cardinality\": self.residual_cardinality,\n            \"padding\": self.padding,\n            \"kernel_initializer\": self.kernel_initializer,\n            \"gamma_initializer\": self.gamma_initializer,\n        }\n    )\n    return config\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.sub_model_composites.Decoder","title":"Decoder","text":"<pre><code>Decoder(\n    number_of_levels: int = 3,\n    upsampling: str = \"2D_upsample_and_conv\",\n    filters: int = 64,\n    limit_filters: int = 1024,\n    kernels: int = 3,\n    split_kernels: bool = False,\n    number_of_blocks: int = 2,\n    activation: str = \"leaky_relu\",\n    dropout_rate: float = 0.2,\n    use_ResidualBlock: bool = False,\n    residual_cardinality: int = 1,\n    channel_list: Optional[List[int]] = None,\n    use_spec_norm: bool = False,\n    use_bias: bool = True,\n    use_self_attention: bool = False,\n    enable_skip_connections_input: bool = False,\n    padding: PaddingType = PaddingType.ZERO,\n    kernel_initializer: Optional[\n        tf.keras.initializers.Initializer\n    ] = None,\n    gamma_initializer: Optional[\n        tf.keras.initializers.Initializer\n    ] = None,\n)\n</code></pre> <p>             Bases: <code>tf.keras.layers.Layer</code></p> <p>Combines conv blocks with up sample blocks.</p> <p>The spatial width is doubled with every level while the channel depth is halfed. Can be combined with <code>dsk.layers.Encoder</code> and <code>dsk.layers.Bottleneck</code> to form an auto encoder model.</p> Tipp <p>Checkout the dsk.models api to find models using this layer.</p> <p>Initializes the <code>Decoder</code> layer.</p> <p>Parameters:</p> Name Type Description Default <code>number_of_levels</code> <code>int</code> <p>Number levels in the decoder. Effectivly the number of convolution and upsample pairs. Defaults to 3.</p> <code>3</code> <code>upsampling</code> <code>str</code> <p>Describes the upsampling method used. Defaults to \"2D_upsample_and_conv\".</p> <code>'2D_upsample_and_conv'</code> <code>filters</code> <code>int</code> <p>Base size of filters the is doubled with every level of the decoder. Defaults to 64.</p> <code>64</code> <code>limit_filters</code> <code>int</code> <p>Limits the number of filters, which is doubled with every downsampling block. Defaults to 512.</p> <code>1024</code> <code>kernels</code> <code>int</code> <p>Size of the convolutions kernels. Defaults to 3.</p> <code>3</code> <code>split_kernels</code> <code>bool</code> <p>To decrease the number of parameters, a convolution with the kernel_size <code>(kernel,kernel)</code> can be splitted into two consecutive convolutions with the kernel_size <code>(kernel,1)</code> and <code>(1,kernel)</code> respectivly. Defaults to False.</p> <code>False</code> <code>number_of_blocks</code> <code>int</code> <p>Number of consecutive convolutional building blocks, i.e. <code>Conv2DBlock</code>. Defaults to 2.</p> <code>2</code> <code>activation</code> <code>str</code> <p>String literal or tensorflow activation function object to obtain activation function. Defaults to \"leaky_relu\".</p> <code>'leaky_relu'</code> <code>dropout_rate</code> <code>float</code> <p>Probability of the dropout layer. If the preceeding layer has more than one channel, spatial dropout is applied, otherwise standard dropout. Defaults to 0.2.</p> <code>0.2</code> <code>use_ResidualBlock</code> <code>bool</code> <p>Whether or not to use the <code>ResidualBlock</code> instead of the <code>Conv2DBlock</code>. Defaults to False.</p> <code>False</code> <code>residual_cardinality</code> <code>int</code> <p>Cardinality for the <code>ResidualBlock</code>. Defaults to 1.</p> <code>1</code> <code>channel_list</code> <code>Optional[List[int]]</code> <p>Alternativly to number_of_layers and filters, a list with the disired filters for each level can be provided. e.g. channel_list = [64, 128, 256] results in a 3-level Decoder with 64, 128, 256 filters for level 1, 2 and 3 respectivly. Defaults to None.</p> <code>None</code> <code>use_spec_norm</code> <code>bool</code> <p>Applies spectral normalization to convolutional and dense layers. Defaults to False.</p> <code>False</code> <code>use_bias</code> <code>bool</code> <p>Whether convolutions and dense layers include a bias or not. Defaults to True.</p> <code>True</code> <code>use_self_attention</code> <code>bool</code> <p>Determines whether to apply self-attention in the decoder. Defaults to False.</p> <code>False</code> <code>enable_skip_connections_input</code> <code>bool</code> <p>Whether or not to input skip connections at each level. Defaults to False.</p> <code>False</code> <code>padding</code> <code>PaddingType</code> <p>Padding type. Defaults to PaddingType.ZERO.</p> <code>PaddingType.ZERO</code> <code>kernel_initializer</code> <code>tf.keras.initializers.Initializer</code> <p>Initialization of the convolutions kernels. Defaults to None.</p> <code>None</code> <code>gamma_initializer</code> <code>tf.keras.initializers.Initializer</code> <p>Initialization of the normalization layers. Defaults to None.</p> <code>None</code> Source code in <code>DeepSaki/layers/sub_model_composites.py</code> <pre><code>def __init__(\n    self,\n    number_of_levels: int = 3,\n    upsampling: str = \"2D_upsample_and_conv\",\n    filters: int = 64,\n    limit_filters: int = 1024,\n    kernels: int = 3,\n    split_kernels: bool = False,\n    number_of_blocks: int = 2,\n    activation: str = \"leaky_relu\",\n    dropout_rate: float = 0.2,\n    use_ResidualBlock: bool = False,\n    residual_cardinality: int = 1,\n    channel_list: Optional[List[int]] = None,\n    use_spec_norm: bool = False,\n    use_bias: bool = True,\n    use_self_attention: bool = False,\n    enable_skip_connections_input: bool = False,\n    padding: PaddingType = PaddingType.ZERO,\n    kernel_initializer: Optional[tf.keras.initializers.Initializer] = None,\n    gamma_initializer: Optional[tf.keras.initializers.Initializer] = None,\n) -&gt; None:\n    \"\"\"Initializes the `Decoder` layer.\n\n    Args:\n        number_of_levels (int, optional): Number levels in the decoder. Effectivly the number of convolution and\n            upsample pairs. Defaults to 3.\n        upsampling (str, optional): Describes the upsampling method used. Defaults to \"2D_upsample_and_conv\".\n        filters (int, optional): Base size of filters the is doubled with every level of the decoder.\n            Defaults to 64.\n        limit_filters (int, optional): Limits the number of filters, which is doubled with every downsampling block.\n            Defaults to 512.\n        kernels (int, optional): Size of the convolutions kernels. Defaults to 3.\n        split_kernels (bool, optional): To decrease the number of parameters, a convolution with the kernel_size\n            `(kernel,kernel)` can be splitted into two consecutive convolutions with the kernel_size `(kernel,1)` and\n            `(1,kernel)` respectivly. Defaults to False.\n        number_of_blocks (int, optional): Number of consecutive convolutional building blocks, i.e. `Conv2DBlock`.\n            Defaults to 2.\n        activation (str, optional): String literal or tensorflow activation function object to obtain activation\n            function. Defaults to \"leaky_relu\".\n        dropout_rate (float, optional): Probability of the dropout layer. If the preceeding layer has more than one\n            channel, spatial dropout is applied, otherwise standard dropout. Defaults to 0.2.\n        use_ResidualBlock (bool, optional): Whether or not to use the `ResidualBlock` instead of the\n            `Conv2DBlock`. Defaults to False.\n        residual_cardinality (int, optional): Cardinality for the `ResidualBlock`. Defaults to 1.\n        channel_list (Optional[List[int]], optional): Alternativly to number_of_layers and filters, a list with the\n            disired filters for each level can be provided. e.g. channel_list = [64, 128, 256] results in a 3-level\n            Decoder with 64, 128, 256 filters for level 1, 2 and 3 respectivly. Defaults to None.\n        use_spec_norm (bool, optional): Applies spectral normalization to convolutional and dense layers. Defaults to False.\n        use_bias (bool, optional): Whether convolutions and dense layers include a bias or not. Defaults to True.\n        use_self_attention (bool, optional): Determines whether to apply self-attention in the decoder. Defaults to False.\n        enable_skip_connections_input (bool, optional): Whether or not to input skip connections at each level. Defaults to False.\n        padding (PaddingType, optional): Padding type. Defaults to PaddingType.ZERO.\n        kernel_initializer (tf.keras.initializers.Initializer, optional): Initialization of the convolutions kernels.\n            Defaults to None.\n        gamma_initializer (tf.keras.initializers.Initializer, optional): Initialization of the normalization layers.\n            Defaults to None.\n    \"\"\"\n    super(Decoder, self).__init__()\n    self.number_of_levels = number_of_levels\n    self.filters = filters\n    self.upsampling = upsampling\n    self.limit_filters = limit_filters\n    self.kernels = kernels\n    self.split_kernels = split_kernels\n    self.number_of_blocks = number_of_blocks\n    self.activation = activation\n    self.use_ResidualBlock = use_ResidualBlock\n    self.channel_list = channel_list\n    self.use_spec_norm = use_spec_norm\n    self.use_bias = use_bias\n    self.dropout_rate = dropout_rate\n    self.use_self_attention = use_self_attention\n    self.enable_skip_connections_input = enable_skip_connections_input\n    self.residual_cardinality = residual_cardinality\n    self.padding = padding\n\n    self.kernel_initializer = HeAlphaUniform() if kernel_initializer is None else kernel_initializer\n    self.gamma_initializer = HeAlphaUniform() if gamma_initializer is None else gamma_initializer\n\n    self.input_spec = tf.keras.layers.InputSpec(ndim=4, dtype=tf.float32)\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.sub_model_composites.Decoder.build","title":"build","text":"<pre><code>build(input_shape: tf.TensorShape) -&gt; None\n</code></pre> <p>Build layer depending on the <code>input_shape</code> (output shape of the previous layer).</p> <p>Parameters:</p> Name Type Description Default <code>input_shape</code> <code>tf.TensorShape</code> <p>Shape of the input tensor to this layer.</p> required Source code in <code>DeepSaki/layers/sub_model_composites.py</code> <pre><code>def build(self, input_shape: tf.TensorShape) -&gt; None:\n    \"\"\"Build layer depending on the `input_shape` (output shape of the previous layer).\n\n    Args:\n        input_shape (tf.TensorShape): Shape of the input tensor to this layer.\n    \"\"\"\n    super(Decoder, self).build(input_shape)\n\n    if self.channel_list is None:\n        self.channel_list = [\n            min(self.filters * 2**i, self.limit_filters) for i in reversed(range(self.number_of_levels))\n        ]\n    else:\n        self.number_of_levels = len(self.channel_list)\n\n    self.decoderBlocks = []\n    self.upSampleBlocks = []\n\n    if self.use_self_attention:\n        self.SA = ScalarGatedSelfAttention(\n            use_spec_norm=self.use_spec_norm,\n            intermediate_channel=None,\n            kernel_initializer=self.kernel_initializer,\n            gamma_initializer=self.gamma_initializer,\n        )\n    else:\n        self.SA = None\n\n    for i, ch in enumerate(self.channel_list):\n        dropout_rate = self.dropout_rate if i &lt; int(self.number_of_levels / 2) else 0\n\n        if self.use_ResidualBlock:\n            self.decoderBlocks.append(\n                ResidualBlock(\n                    filters=ch,\n                    activation=self.activation,\n                    kernels=self.kernels,\n                    number_of_blocks=self.number_of_blocks,\n                    use_spec_norm=self.use_spec_norm,\n                    dropout_rate=dropout_rate,\n                    use_bias=self.use_bias,\n                    residual_cardinality=self.residual_cardinality,\n                    padding=self.padding,\n                    kernel_initializer=self.kernel_initializer,\n                    gamma_initializer=self.gamma_initializer,\n                )\n            )\n            self.upSampleBlocks.append(\n                ResBlockUp(\n                    activation=self.activation,\n                    use_spec_norm=self.use_spec_norm,\n                    use_bias=self.use_bias,\n                    padding=self.padding,\n                    kernel_initializer=self.kernel_initializer,\n                    gamma_initializer=self.gamma_initializer,\n                )\n            )\n        else:\n            self.decoderBlocks.append(\n                Conv2DBlock(\n                    filters=ch,\n                    kernels=self.kernels,\n                    split_kernels=self.split_kernels,\n                    activation=self.activation,\n                    number_of_blocks=self.number_of_blocks,\n                    dropout_rate=dropout_rate,\n                    use_spec_norm=self.use_spec_norm,\n                    use_bias=self.use_bias,\n                    padding=self.padding,\n                    kernel_initializer=self.kernel_initializer,\n                    gamma_initializer=self.gamma_initializer,\n                )\n            )\n            self.upSampleBlocks.append(\n                UpSampleBlock(\n                    kernels=self.kernels,\n                    upsampling=self.upsampling,\n                    activation=self.activation,\n                    use_spec_norm=self.use_spec_norm,\n                    use_bias=self.use_bias,\n                    padding=self.padding,\n                    kernel_initializer=self.kernel_initializer,\n                    gamma_initializer=self.gamma_initializer,\n                )\n            )\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.sub_model_composites.Decoder.call","title":"call","text":"<pre><code>call(\n    inputs: Union[tf.Tensor, Tuple[tf.Tensor, tf.Tensor]]\n) -&gt; tf.Tensor\n</code></pre> <p>Calls the <code>Decoder</code> layer.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>Union[tf.Tensor, Tuple[tf.Tensor, tf.Tensor]]</code> <p>If <code>enable_skip_connections_input=False</code> only inputs a tensor of shape (batch, height, width, min(channel2*level, limit_filters)). If <code>enable_skip_connections_input=True</code>, additonally at every level of the decoder, skip connections from an encoder can be inserted.</p> required <p>Returns:</p> Type Description <code>tf.Tensor</code> <p>tf.Tensor: Tensor of shape (<code>batch</code>, <code>height*2**number_of_levels</code>, <code>width*2**number_of_levels</code>,<code>filters</code>).</p> Source code in <code>DeepSaki/layers/sub_model_composites.py</code> <pre><code>def call(self, inputs: Union[tf.Tensor, Tuple[tf.Tensor, tf.Tensor]]) -&gt; tf.Tensor:\n    \"\"\"Calls the `Decoder` layer.\n\n    Args:\n        inputs (Union[tf.Tensor , Tuple[tf.Tensor, tf.Tensor]]): If `enable_skip_connections_input=False` only\n            inputs a tensor of shape (batch, height, width, min(channel*2**level, limit_filters)). If\n            `enable_skip_connections_input=True`, additonally at every level of the decoder, skip connections from\n            an encoder can be inserted.\n\n    Returns:\n        tf.Tensor: Tensor of shape (`batch`, `height*2**number_of_levels`, `width*2**number_of_levels`,`filters`).\n    \"\"\"\n    skip_connections = None\n    if self.enable_skip_connections_input:\n        x, skip_connections = inputs\n    else:\n        x = inputs\n\n    for level in range(self.number_of_levels):\n        if level == 3 and self.SA is not None:\n            x = self.SA(x)\n        x = self.upSampleBlocks[level](x)\n        if skip_connections is not None:\n            x = tf.keras.layers.concatenate([x, skip_connections[self.number_of_levels - (level + 1)]])\n        x = self.decoderBlocks[level](x)\n\n    return x\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.sub_model_composites.Decoder.get_config","title":"get_config","text":"<pre><code>get_config() -&gt; Dict[str, Any]\n</code></pre> <p>Serialization of the object.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with the class' variable names as keys.</p> Source code in <code>DeepSaki/layers/sub_model_composites.py</code> <pre><code>def get_config(self) -&gt; Dict[str, Any]:\n    \"\"\"Serialization of the object.\n\n    Returns:\n        Dictionary with the class' variable names as keys.\n    \"\"\"\n    config = super(Decoder, self).get_config()\n    config.update(\n        {\n            \"number_of_levels\": self.number_of_levels,\n            \"filters\": self.filters,\n            \"limit_filters\": self.limit_filters,\n            \"upsampling\": self.upsampling,\n            \"kernels\": self.kernels,\n            \"split_kernels\": self.split_kernels,\n            \"number_of_blocks\": self.number_of_blocks,\n            \"activation\": self.activation,\n            \"use_ResidualBlock\": self.use_ResidualBlock,\n            \"residual_cardinality\": self.residual_cardinality,\n            \"channel_list\": self.channel_list,\n            \"use_spec_norm\": self.use_spec_norm,\n            \"dropout_rate\": self.dropout_rate,\n            \"use_bias\": self.use_bias,\n            \"use_self_attention\": self.use_self_attention,\n            \"enable_skip_connections_input\": self.enable_skip_connections_input,\n            \"padding\": self.padding,\n            \"kernel_initializer\": self.kernel_initializer,\n            \"gamma_initializer\": self.gamma_initializer,\n        }\n    )\n    return config\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.sub_model_composites.Encoder","title":"Encoder","text":"<pre><code>Encoder(\n    number_of_levels: int = 3,\n    filters: int = 64,\n    limit_filters: int = 1024,\n    downsampling: str = \"conv_stride_2\",\n    kernels: int = 3,\n    split_kernels: bool = False,\n    number_of_blocks: int = 2,\n    activation: str = \"leaky_relu\",\n    first_kernel: Optional[int] = None,\n    use_ResidualBlock: bool = False,\n    residual_cardinality: int = 1,\n    channel_list: Optional[List[int]] = None,\n    use_spec_norm: bool = False,\n    use_bias: bool = True,\n    dropout_rate: float = 0.0,\n    use_self_attention: bool = False,\n    omit_skips: int = 0,\n    padding: PaddingType = PaddingType.ZERO,\n    output_skips: bool = False,\n    kernel_initializer: Optional[\n        tf.keras.initializers.Initializer\n    ] = None,\n    gamma_initializer: Optional[\n        tf.keras.initializers.Initializer\n    ] = None,\n)\n</code></pre> <p>             Bases: <code>tf.keras.layers.Layer</code></p> <p>Combines conv blocks with down sample blocks.</p> <p>The spatial width is halved with every level while the channel depth is doubled. Can be combined with <code>dsk.layers.Decoder</code> and <code>dsk.layers.Bottleneck</code> to form an auto encoder model.</p> Tipp <p>Checkout the dsk.models api to find models using this layer.</p> <p>Initializes the <code>Encoder</code> layer.</p> <p>Parameters:</p> Name Type Description Default <code>number_of_levels</code> <code>int</code> <p>Number of downsampling levels of the model. Defaults to 3.</p> <code>3</code> <code>filters</code> <code>int</code> <p>Number of filters for the initial encoder block. Defaults to 64.</p> <code>64</code> <code>limit_filters</code> <code>int</code> <p>Limits the number of filters, which is doubled with every downsampling block. Defaults to 1024.</p> <code>1024</code> <code>downsampling</code> <code>str</code> <p>Describes the downsampling method. Defaults to \"conv_stride_2\".</p> <code>'conv_stride_2'</code> <code>kernels</code> <code>int</code> <p>Size of the convolutions kernels. Defaults to 3.</p> <code>3</code> <code>split_kernels</code> <code>bool</code> <p>To decrease the number of parameters, a convolution with the kernel_size <code>(kernel,kernel)</code> can be splitted into two consecutive convolutions with the kernel_size <code>(kernel,1)</code> and <code>(1,kernel)</code> respectivly. Defaults to False.</p> <code>False</code> <code>number_of_blocks</code> <code>int</code> <p>Number of consecutive convolutional building blocks, i.e. <code>Conv2DBlock</code>. Defaults to 2.</p> <code>2</code> <code>activation</code> <code>str</code> <p>String literal or tensorflow activation function object to obtain activation function. Defaults to \"leaky_relu\".</p> <code>'leaky_relu'</code> <code>first_kernel</code> <code>Optional[int]</code> <p>The first convolution can have a different kernel size, to e.g. increase the perceptive field, while the channel depth is still low. Defaults to None.</p> <code>None</code> <code>use_ResidualBlock</code> <code>bool</code> <p>Whether or not to use the <code>ResidualBlock</code> instead of the <code>Conv2DBlock</code>. Defaults to False.</p> <code>False</code> <code>residual_cardinality</code> <code>int</code> <p>Cardinality for the <code>ResidualBlock</code>. Defaults to 1.</p> <code>1</code> <code>channel_list</code> <code>Optional[List[int]]</code> <p>alternativly to number_of_layers and filters, a list with the disired filters for each level can be provided. e.g. channel_list = [64, 128, 256] results in a 3-level Encoder with 64, 128, 256 filters for level 1, 2 and 3 respectivly. Defaults to None.</p> <code>None</code> <code>use_spec_norm</code> <code>bool</code> <p>Applies spectral normalization to convolutional and dense layers. Defaults to False.</p> <code>False</code> <code>use_bias</code> <code>bool</code> <p>Whether convolutions and dense layers include a bias or not. Defaults to True.</p> <code>True</code> <code>dropout_rate</code> <code>float</code> <p>Probability of the dropout layer. If the preceeding layer has more than one channel, spatial dropout is applied, otherwise standard dropout. Defaults to 0.0.</p> <code>0.0</code> <code>use_self_attention</code> <code>bool</code> <p>Determines whether to apply self-attention in the encoder. Defaults to False.</p> <code>False</code> <code>omit_skips</code> <code>int</code> <p>Defines how many layers should not output a skip connection output. Requires <code>output_skips</code> to be True. E.g. if <code>omit_skips = 2</code>, the first two levels do not output a skip connection, it starts at level 3. Defaults to 0.</p> <code>0</code> <code>padding</code> <code>PaddingType</code> <p>Padding type. Defaults to PaddingType.ZERO.</p> <code>PaddingType.ZERO</code> <code>output_skips</code> <code>bool</code> <p>If true, ski connections are output. Could be used to attach an encoder to a decoder model. Defaults to False.</p> <code>False</code> <code>kernel_initializer</code> <code>tf.keras.initializers.Initializer</code> <p>Initialization of the convolutions kernels. Defaults to None.</p> <code>None</code> <code>gamma_initializer</code> <code>tf.keras.initializers.Initializer</code> <p>Initialization of the normalization layers. Defaults to None.</p> <code>None</code> Source code in <code>DeepSaki/layers/sub_model_composites.py</code> <pre><code>def __init__(\n    self,\n    number_of_levels: int = 3,\n    filters: int = 64,\n    limit_filters: int = 1024,\n    downsampling: str = \"conv_stride_2\",\n    kernels: int = 3,\n    split_kernels: bool = False,\n    number_of_blocks: int = 2,\n    activation: str = \"leaky_relu\",\n    first_kernel: Optional[int] = None,\n    use_ResidualBlock: bool = False,\n    residual_cardinality: int = 1,\n    channel_list: Optional[List[int]] = None,\n    use_spec_norm: bool = False,\n    use_bias: bool = True,\n    dropout_rate: float = 0.0,\n    use_self_attention: bool = False,\n    omit_skips: int = 0,\n    padding: PaddingType = PaddingType.ZERO,\n    output_skips: bool = False,\n    kernel_initializer: Optional[tf.keras.initializers.Initializer] = None,\n    gamma_initializer: Optional[tf.keras.initializers.Initializer] = None,\n) -&gt; None:\n    \"\"\"Initializes the `Encoder` layer.\n\n    Args:\n        number_of_levels (int, optional): Number of downsampling levels of the model. Defaults to 3.\n        filters (int, optional): Number of filters for the initial encoder block. Defaults to 64.\n        limit_filters (int, optional): Limits the number of filters, which is doubled with every downsampling block.\n            Defaults to 1024.\n        downsampling (str, optional): Describes the downsampling method. Defaults to \"conv_stride_2\".\n        kernels (int, optional): Size of the convolutions kernels. Defaults to 3.\n        split_kernels (bool, optional): To decrease the number of parameters, a convolution with the kernel_size\n            `(kernel,kernel)` can be splitted into two consecutive convolutions with the kernel_size `(kernel,1)` and\n            `(1,kernel)` respectivly. Defaults to False.\n        number_of_blocks (int, optional): Number of consecutive convolutional building blocks, i.e. `Conv2DBlock`.\n            Defaults to 2.\n        activation (str, optional): String literal or tensorflow activation function object to obtain activation\n            function. Defaults to \"leaky_relu\".\n        first_kernel (Optional[int], optional): The first convolution can have a different kernel size, to e.g.\n            increase the perceptive field, while the channel depth is still low. Defaults to None.\n        use_ResidualBlock (bool, optional): Whether or not to use the `ResidualBlock` instead of the\n            `Conv2DBlock`. Defaults to False.\n        residual_cardinality (int, optional): Cardinality for the `ResidualBlock`. Defaults to 1.\n        channel_list (Optional[List[int]], optional): alternativly to number_of_layers and filters, a list with the\n            disired filters for each level can be provided. e.g. channel_list = [64, 128, 256] results in a 3-level\n            Encoder with 64, 128, 256 filters for level 1, 2 and 3 respectivly. Defaults to None.\n        use_spec_norm (bool, optional): Applies spectral normalization to convolutional and dense layers.\n            Defaults to False.\n        use_bias (bool, optional): Whether convolutions and dense layers include a bias or not. Defaults to True.\n        dropout_rate (float, optional): Probability of the dropout layer. If the preceeding layer has more than one\n            channel, spatial dropout is applied, otherwise standard dropout. Defaults to 0.0.\n        use_self_attention (bool, optional): Determines whether to apply self-attention in the encoder. Defaults to False.\n        omit_skips (int, optional): Defines how many layers should not output a skip connection output. Requires\n            `output_skips` to be True. E.g. if `omit_skips = 2`, the first two levels do not output a skip connection,\n            it starts at level 3. Defaults to 0.\n        padding (PaddingType, optional): Padding type. Defaults to PaddingType.ZERO.\n        output_skips (bool, optional): If true, ski connections are output. Could be used to attach an encoder to a\n            decoder model. Defaults to False.\n        kernel_initializer (tf.keras.initializers.Initializer, optional): Initialization of the convolutions kernels.\n            Defaults to None.\n        gamma_initializer (tf.keras.initializers.Initializer, optional): Initialization of the normalization layers.\n            Defaults to None.\n    \"\"\"\n    super(Encoder, self).__init__()\n    self.number_of_levels = number_of_levels\n    self.filters = filters\n    self.limit_filters = limit_filters\n    self.downsampling = downsampling\n    self.kernels = kernels\n    self.split_kernels = split_kernels\n    self.number_of_blocks = number_of_blocks\n    self.activation = activation\n    self.first_kernel = first_kernel\n    self.use_ResidualBlock = use_ResidualBlock\n    self.residual_cardinality = residual_cardinality\n    self.channel_list = channel_list\n    self.use_spec_norm = use_spec_norm\n    self.dropout_rate = dropout_rate\n    self.use_self_attention = use_self_attention\n    self.omit_skips = omit_skips\n    self.padding = padding\n    self.output_skips = output_skips\n    self.use_bias = use_bias\n    self.kernel_initializer = HeAlphaUniform() if kernel_initializer is None else kernel_initializer\n    self.gamma_initializer = HeAlphaUniform() if gamma_initializer is None else gamma_initializer\n\n    self.input_spec = tf.keras.layers.InputSpec(ndim=4, dtype=tf.float32)\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.sub_model_composites.Encoder.build","title":"build","text":"<pre><code>build(input_shape: tf.TensorShape) -&gt; None\n</code></pre> <p>Build layer depending on the <code>input_shape</code> (output shape of the previous layer).</p> <p>Parameters:</p> Name Type Description Default <code>input_shape</code> <code>tf.TensorShape</code> <p>Shape of the input tensor to this layer.</p> required Source code in <code>DeepSaki/layers/sub_model_composites.py</code> <pre><code>def build(self, input_shape: tf.TensorShape) -&gt; None:\n    \"\"\"Build layer depending on the `input_shape` (output shape of the previous layer).\n\n    Args:\n        input_shape (tf.TensorShape): Shape of the input tensor to this layer.\n    \"\"\"\n    super(Encoder, self).build(input_shape)\n\n    if self.channel_list is None:\n        self.channel_list = [min(self.filters * 2**i, self.limit_filters) for i in range(self.number_of_levels)]\n    else:\n        self.number_of_levels = len(self.channel_list)\n\n    self.encoderBlocks = []\n    self.downSampleBlocks = []\n\n    if self.use_self_attention:\n        self.SA = ScalarGatedSelfAttention(\n            use_spec_norm=self.use_spec_norm,\n            intermediate_channel=None,\n            kernel_initializer=self.kernel_initializer,\n            gamma_initializer=self.gamma_initializer,\n        )\n    else:\n        self.SA = None\n\n    for i, ch in enumerate(self.channel_list):\n        encoder_kernels = self.first_kernel if i == 0 and self.first_kernel else self.kernels\n\n        if self.use_ResidualBlock:\n            self.encoderBlocks.append(\n                ResidualBlock(\n                    filters=ch,\n                    activation=self.activation,\n                    kernels=encoder_kernels,\n                    number_of_blocks=self.number_of_blocks,\n                    use_spec_norm=self.use_spec_norm,\n                    dropout_rate=self.dropout_rate,\n                    use_bias=self.use_bias,\n                    residual_cardinality=self.residual_cardinality,\n                    padding=self.padding,\n                    kernel_initializer=self.kernel_initializer,\n                    gamma_initializer=self.gamma_initializer,\n                )\n            )\n            self.downSampleBlocks.append(\n                ResBlockDown(\n                    activation=self.activation,\n                    use_spec_norm=self.use_spec_norm,\n                    use_bias=self.use_bias,\n                    padding=self.padding,\n                    kernel_initializer=self.kernel_initializer,\n                    gamma_initializer=self.gamma_initializer,\n                )\n            )\n        else:\n            self.encoderBlocks.append(\n                Conv2DBlock(\n                    filters=ch,\n                    kernels=encoder_kernels,\n                    split_kernels=self.split_kernels,\n                    activation=self.activation,\n                    number_of_blocks=self.number_of_blocks,\n                    use_spec_norm=self.use_spec_norm,\n                    dropout_rate=self.dropout_rate,\n                    padding=self.padding,\n                    use_bias=self.use_bias,\n                    kernel_initializer=self.kernel_initializer,\n                    gamma_initializer=self.gamma_initializer,\n                )\n            )\n            self.downSampleBlocks.append(\n                DownSampleBlock(\n                    downsampling=self.downsampling,\n                    activation=self.activation,\n                    kernels=encoder_kernels,\n                    use_spec_norm=self.use_spec_norm,\n                    padding=self.padding,\n                    use_bias=self.use_bias,\n                    kernel_initializer=self.kernel_initializer,\n                    gamma_initializer=self.gamma_initializer,\n                )\n            )\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.sub_model_composites.Encoder.call","title":"call","text":"<pre><code>call(\n    inputs: tf.Tensor,\n) -&gt; Union[tf.Tensor, Tuple[tf.Tensor, tf.Tensor]]\n</code></pre> <p>Calls the <code>Encoder</code> layer.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>tf.Tensor</code> <p>Input tensor of shape (batch, height, width, channel)</p> required <p>Returns:</p> Type Description <code>Union[tf.Tensor, Tuple[tf.Tensor, tf.Tensor]]</code> <p>If <code>output_skips=False</code> only the final output of the Encoder is returned as a tensor of shape (<code>batch</code>, <code>height/2**number_of_levels</code>, <code>width/2**number_of_levels</code>, <code>min(filters * 2 ** (number_of_levels - 1), limit_filters)</code>. If <code>output_skips=True</code> additionally returns a tensor of tensor (one for each level of the encoder) of shape (<code>batch</code>, <code>height/2**level</code>, <code>width/2**level</code>, <code>min(filters * 2 ** (number_of_levels - 1), limit_filters)</code>.</p> Source code in <code>DeepSaki/layers/sub_model_composites.py</code> <pre><code>def call(self, inputs: tf.Tensor) -&gt; Union[tf.Tensor, Tuple[tf.Tensor, tf.Tensor]]:\n    \"\"\"Calls the `Encoder` layer.\n\n    Args:\n        inputs (tf.Tensor): Input tensor of shape (batch, height, width, channel)\n\n    Returns:\n        If `output_skips=False` only the final output of the Encoder is returned as a tensor of shape\n            (`batch`, `height/2**number_of_levels`, `width/2**number_of_levels`,\n            `min(filters * 2 ** (number_of_levels - 1), limit_filters)`. If `output_skips=True` additionally returns\n            a tensor of tensor (one for each level of the encoder) of shape (`batch`, `height/2**level`,\n            `width/2**level`, `min(filters * 2 ** (number_of_levels - 1), limit_filters)`.\n    \"\"\"\n    x = inputs\n    skips = []\n\n    for level in range(self.number_of_levels):\n        if level == 3 and self.SA is not None:\n            x = self.SA(x)\n        skip = self.encoderBlocks[level](x)\n        x = self.downSampleBlocks[level](skip)\n        if self.output_skips:\n            if level &gt;= self.omit_skips:  # omit the first skip connection\n                skips.append(skip)\n            else:\n                skips.append(None)\n\n    if self.output_skips:\n        return x, skips\n    return x\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.sub_model_composites.Encoder.get_config","title":"get_config","text":"<pre><code>get_config() -&gt; Dict[str, Any]\n</code></pre> <p>Serialization of the object.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with the class' variable names as keys.</p> Source code in <code>DeepSaki/layers/sub_model_composites.py</code> <pre><code>def get_config(self) -&gt; Dict[str, Any]:\n    \"\"\"Serialization of the object.\n\n    Returns:\n        Dictionary with the class' variable names as keys.\n    \"\"\"\n    config = super(Encoder, self).get_config()\n    config.update(\n        {\n            \"number_of_levels\": self.number_of_levels,\n            \"filters\": self.filters,\n            \"limit_filters\": self.limit_filters,\n            \"downsampling\": self.downsampling,\n            \"kernels\": self.kernels,\n            \"split_kernels\": self.split_kernels,\n            \"number_of_blocks\": self.number_of_blocks,\n            \"activation\": self.activation,\n            \"first_kernel\": self.first_kernel,\n            \"use_ResidualBlock\": self.use_ResidualBlock,\n            \"residual_cardinality\": self.residual_cardinality,\n            \"channel_list\": self.channel_list,\n            \"use_spec_norm\": self.use_spec_norm,\n            \"use_bias\": self.use_bias,\n            \"dropout_rate\": self.dropout_rate,\n            \"use_self_attention\": self.use_self_attention,\n            \"omit_skips\": self.omit_skips,\n            \"padding\": self.padding,\n            \"output_skips\": self.output_skips,\n            \"kernel_initializer\": self.kernel_initializer,\n            \"gamma_initializer\": self.gamma_initializer,\n        }\n    )\n    return config\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_helper.InitializerFunc","title":"InitializerFunc","text":"<p>             Bases: <code>Enum</code></p> <p><code>Enum</code> used to define different types of initializer functions.</p> <p>Attributes:</p> Name Type Description <code>RANDOM_NORMAL</code> <code>int</code> <p>Corresponds to a random normal initializer function.</p> <code>RANDOM_UNIFORM</code> <code>int</code> <p>Corresponds to a random uniform initializer function.</p> <code>GLOROT_NORMAL</code> <code>int</code> <p>Corresponds to a Glorot normal initializer function.</p> <code>GLOROT_UNIFORM</code> <code>int</code> <p>Corresponds to a Glorot uniform initializer function.</p> <code>HE_NORMAL</code> <code>int</code> <p>Corresponds to a He normal initializer function.</p> <code>HE_UNIFORM</code> <code>int</code> <p>Corresponds to a He uniform initializer function.</p> <code>HE_ALPHA_NORMAL</code> <code>int</code> <p>Corresponds to a He Alpha normal initializer function.</p> <code>HE_ALPHA_UNIFORM</code> <code>int</code> <p>Corresponds to a He Alpha Uniform initializer function.</p>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_helper.PaddingType","title":"PaddingType","text":"<p>             Bases: <code>Enum</code></p> <p><code>Enum</code> used to define different types of padding opperations.</p> <p>Attributes:</p> Name Type Description <code>ZERO</code> <code>int</code> <p>Indicates to apply a zero padding operations.</p> <code>REFLECTION</code> <code>int</code> <p>Indicates to apply a reflection padding operation.</p>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_helper.dropout_func","title":"dropout_func","text":"<pre><code>dropout_func(\n    filters: int, dropout_rate: float\n) -&gt; tf.keras.layers.Layer\n</code></pre> <p>Wrapper to obtain a dropout layer depending on the number of filters of the preceeding feature map.</p> <p>Parameters:</p> Name Type Description Default <code>filters</code> <code>int</code> <p>Number of filters of the preceeding layer.</p> required <code>dropout_rate</code> <code>float</code> <p>Probability of the dropout layer to drop weights.</p> required <p>Returns:</p> Name Type Description <code>layer</code> <code>tf.keras.layers.Layer</code> <p>Returns <code>tf.keras.layers.SpatialDropout2D</code> if number of filters &gt; 1, otherwise 'tf.keras.layers.Dropout'.</p> Source code in <code>DeepSaki/layers/layer_helper.py</code> <pre><code>def dropout_func(filters: int, dropout_rate: float) -&gt; tf.keras.layers.Layer:\n    \"\"\"Wrapper to obtain a dropout layer depending on the number of filters of the preceeding feature map.\n\n    Args:\n        filters (int): Number of filters of the preceeding layer.\n        dropout_rate (float): Probability of the dropout layer to drop weights.\n\n    Returns:\n        layer: Returns `tf.keras.layers.SpatialDropout2D` if number of filters &gt; 1, otherwise 'tf.keras.layers.Dropout'.\n    \"\"\"\n    if not isinstance(filters, int):\n        raise TypeError(f\"Parameter 'filters' shall be of type int but is: '{type(filters)}'\")\n\n    if filters &gt; 1:\n        return tf.keras.layers.SpatialDropout2D(dropout_rate)\n    if filters == 1:\n        return tf.keras.layers.Dropout(dropout_rate)\n    raise ValueError(f\"provided value '{filters}'for param 'filters' is unvalid. Provide an int bigger than 0.\")\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_helper.get_initializer","title":"get_initializer","text":"<pre><code>get_initializer(\n    initializer: InitializerFunc, seed: Optional[int] = None\n) -&gt; tf.keras.initializers.Initializer\n</code></pre> <p>Wrapper to return a certain initializer given a descriptive string.</p> <p>Parameters:</p> Name Type Description Default <code>initializer</code> <code>InitializerFunc</code> <p>Enum description of the initializer.</p> required <code>seed</code> <code>Optional[int]</code> <p>Seed to make the behavior of the initializer deterministic. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>tf.keras.initializers.Initializer</code> <p>Instance of an initializer object.</p> Source code in <code>DeepSaki/layers/layer_helper.py</code> <pre><code>def get_initializer(\n    initializer: InitializerFunc,\n    seed: Optional[int] = None,\n) -&gt; tf.keras.initializers.Initializer:\n    \"\"\"Wrapper to return a certain initializer given a descriptive string.\n\n    Args:\n        initializer (InitializerFunc): Enum description of the initializer.\n        seed (Optional[int], optional): Seed to make the behavior of the initializer deterministic. Defaults to None.\n\n    Returns:\n        Instance of an initializer object.\n    \"\"\"\n    valid_options = {\n        InitializerFunc.RANDOM_NORMAL: tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02, seed=seed),\n        InitializerFunc.RANDOM_UNIFORM: tf.keras.initializers.RandomUniform(minval=-0.002, maxval=0.02, seed=seed),\n        InitializerFunc.GLOROT_NORMAL: tf.keras.initializers.GlorotNormal(seed=seed),\n        InitializerFunc.GLOROT_UNIFORM: tf.keras.initializers.GlorotUniform(seed=seed),\n        InitializerFunc.HE_NORMAL: tf.keras.initializers.HeNormal(seed=seed),\n        InitializerFunc.HE_UNIFORM: tf.keras.initializers.HeUniform(seed=seed),\n        InitializerFunc.HE_ALPHA_NORMAL: HeAlphaNormal(seed=seed),\n        InitializerFunc.HE_ALPHA_UNIFORM: HeAlphaUniform(seed=seed),\n    }\n\n    if initializer not in valid_options:\n        raise ValueError(f\"Undefined initializer provided: '{initializer}'. Valid options are: '{valid_options.keys()}\")\n\n    return valid_options.get(initializer)\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_helper.pad_func","title":"pad_func","text":"<pre><code>pad_func(\n    pad_values: Tuple[int, int] = (1, 1),\n    padding_type: PaddingType = PaddingType.ZERO,\n) -&gt; tf.keras.layers.Layer\n</code></pre> <p>Wrapper to obtain a padding layer instance.</p> <p>Parameters:</p> Name Type Description Default <code>pad_values</code> <code>Tuple[int, int]</code> <p>Size of the padding values. Defaults to (1, 1).</p> <code>(1, 1)</code> <code>padding_type</code> <code>PaddingType</code> <p>Padding Type. Defaults to PaddingType.ZERO.</p> <code>PaddingType.ZERO</code> <p>Returns:</p> Type Description <code>tf.keras.layers.Layer</code> <p>Instance of a padding layer object.</p> Source code in <code>DeepSaki/layers/layer_helper.py</code> <pre><code>def pad_func(\n    pad_values: Tuple[int, int] = (1, 1),\n    padding_type: PaddingType = PaddingType.ZERO,\n) -&gt; tf.keras.layers.Layer:\n    \"\"\"Wrapper to obtain a padding layer instance.\n\n    Args:\n        pad_values (Tuple[int,int], optional): Size of the padding values. Defaults to (1, 1).\n        padding_type (PaddingType, optional): Padding Type. Defaults to PaddingType.ZERO.\n\n    Returns:\n        Instance of a padding layer object.\n    \"\"\"\n    valid_options = {\n        PaddingType.REFLECTION: ReflectionPadding2D(pad_values),\n        PaddingType.ZERO: tf.keras.layers.ZeroPadding2D(pad_values),\n    }\n    if padding_type not in valid_options:\n        raise ValueError(\n            f\"Undefined padding type provided: '{padding_type}'. Valid options are: '{valid_options.keys()}'\"\n        )\n\n    return valid_options.get(padding_type)\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_helper.plot_layer","title":"plot_layer","text":"<pre><code>plot_layer(\n    layer: tf.keras.layers.Layer, input_shape: List[int]\n) -&gt; None\n</code></pre> <p>Creates a model from a given layer to be able to call model.summary() and to plot a graph image.</p> <p>Parameters:</p> Name Type Description Default <code>layer</code> <code>tf.keras.layers.Layer</code> <p>Layer to be plotted.</p> required <code>input_shape</code> <code>List[int]</code> <p>Shape of the desired input of the layer.</p> required Source code in <code>DeepSaki/layers/layer_helper.py</code> <pre><code>def plot_layer(\n    layer: tf.keras.layers.Layer,\n    input_shape: List[int],\n) -&gt; None:\n    \"\"\"Creates a model from a given layer to be able to call model.summary() and to plot a graph image.\n\n    Args:\n        layer (tf.keras.layers.Layer): Layer to be plotted.\n        input_shape (List[int]): Shape of the desired input of the layer.\n    \"\"\"\n    layer.build([None, *input_shape])\n    inputs = tf.keras.layers.Input(shape=input_shape)\n    model = tf.keras.Model(inputs=inputs, outputs=layer.call(inputs))\n    model.summary()\n    tf.keras.utils.plot_model(model, show_shapes=True, expand_nested=True, to_file=layer.name + \".png\")\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.padding.ReflectionPadding2D","title":"ReflectionPadding2D","text":"<pre><code>ReflectionPadding2D(\n    padding: Tuple[int, int] = (1, 1), **kwargs: Any\n)\n</code></pre> <p>             Bases: <code>tf.keras.layers.Layer</code></p> <p>Reflection Padding layer with support for TPU.</p> <p>Initialize the <code>ReflectionPadding2D</code> layer.</p> <p>Parameters:</p> Name Type Description Default <code>padding</code> <code>Tuple[int, int]</code> <p>One-sided padding added to the <code>hight</code> and <code>width</code> to an input tensor of shape (batch, height, width, channel)respectively. Defaults to (1, 1).</p> <code>(1, 1)</code> Source code in <code>DeepSaki/layers/padding.py</code> <pre><code>def __init__(self, padding: Tuple[int, int] = (1, 1), **kwargs: Any) -&gt; None:\n    \"\"\"Initialize the `ReflectionPadding2D` layer.\n\n    Args:\n        padding (Tuple[int, int], optional): One-sided padding added to the `hight` and `width` to an input tensor\n            of shape (batch, height, width, channel)respectively. Defaults to (1, 1).\n    \"\"\"\n    super(ReflectionPadding2D, self).__init__(**kwargs)\n    self.padding = tuple(padding)\n    self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.padding.ReflectionPadding2D.call","title":"call","text":"<pre><code>call(input_tensor: tf.Tensor) -&gt; tf.Tensor\n</code></pre> <p>Calls the <code>ReflectionPadding2D</code> layer.</p> <p>Parameters:</p> Name Type Description Default <code>input_tensor</code> <code>tf.Tensor</code> <p>Tensor of shape <code>(batch, height, width, channel)</code>.</p> required <p>Returns:</p> Type Description <code>tf.Tensor</code> <p>padded tensor of shape <code>(batch, height+2*padding, width+2*padding, channel)</code>.</p> Source code in <code>DeepSaki/layers/padding.py</code> <pre><code>def call(self, input_tensor: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"Calls the `ReflectionPadding2D` layer.\n\n    Args:\n        input_tensor (tf.Tensor): Tensor of shape `(batch, height, width, channel)`.\n\n    Returns:\n        padded tensor of shape `(batch, height+2*padding, width+2*padding, channel)`.\n    \"\"\"\n    return self._padding_func(input_tensor)\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.padding.ReflectionPadding2D.compute_output_shape","title":"compute_output_shape","text":"<pre><code>compute_output_shape(\n    input_shape: tf.TensorShape,\n) -&gt; tf.TensorShape\n</code></pre> <p>Calculates the expected output shape after calling the layer.</p> <p>Assumes \"channels_last\" configuration.</p> <p>Parameters:</p> Name Type Description Default <code>input_shape</code> <code>tf.TensorShape</code> <p>Shape of the input data to the layer.</p> required <p>Returns:</p> Name Type Description <code>output_shape</code> <code>tf.TensorShape</code> <p>expected output shape of the layer.</p> Source code in <code>DeepSaki/layers/padding.py</code> <pre><code>def compute_output_shape(self, input_shape: tf.TensorShape) -&gt; tf.TensorShape:\n    \"\"\"Calculates the expected output shape after calling the layer.\n\n    Assumes \"channels_last\" configuration.\n\n    Args:\n        input_shape (tf.TensorShape): Shape of the input data to the layer.\n\n    Returns:\n        output_shape: expected output shape of the layer.\n    \"\"\"\n    return tf.TensorShape(\n        (\n            input_shape[0],\n            input_shape[1] + 2 * self.padding[0],\n            input_shape[2] + 2 * self.padding[1],\n            input_shape[3],\n        )\n    )\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.padding.ReflectionPadding2D.get_config","title":"get_config","text":"<pre><code>get_config() -&gt; Dict[str, Any]\n</code></pre> <p>Serialization of the object.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with the class' variable names as keys.</p> Source code in <code>DeepSaki/layers/padding.py</code> <pre><code>def get_config(self) -&gt; Dict[str, Any]:\n    \"\"\"Serialization of the object.\n\n    Returns:\n        Dictionary with the class' variable names as keys.\n    \"\"\"\n    config = super(ReflectionPadding2D, self).get_config()\n    config.update({\"padding\": self.padding})\n    return config\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.pooling.GlobalSumPooling2D","title":"GlobalSumPooling2D","text":"<pre><code>GlobalSumPooling2D(\n    data_format: str = \"channels_last\", **kwargs: Any\n)\n</code></pre> <p>             Bases: <code>tf.keras.layers.Layer</code></p> <p>Global sum pooling operation for spatial data.</p> Tips <p>Similar to tensorflow's GlobalMaxPooling2D and GlobalAveragePooling2D</p> <p>Initialize the <code>GlobalSumPooling2D</code> object.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>data_format</code> is not supported.</p> <p>Parameters:</p> Name Type Description Default <code>data_format</code> <code>str</code> <p>[\"channels_last\"|\"data_format\"]</p> <code>'channels_last'</code> <code>kwargs</code> <code>Any</code> <p>Additional key word arguments passed to the base class.</p> <code>{}</code> Source code in <code>DeepSaki/layers/pooling.py</code> <pre><code>def __init__(self, data_format: str = \"channels_last\", **kwargs: Any) -&gt; None:\n    \"\"\"Initialize the `GlobalSumPooling2D` object.\n\n    Raises:\n        ValueError: If `data_format` is not supported.\n\n    Args:\n        data_format (str, optional): [\"channels_last\"|\"data_format\"]\n        kwargs (Any): Additional key word arguments passed to the base class.\n    \"\"\"\n    super(GlobalSumPooling2D, self).__init__(**kwargs)\n    match data_format:\n        case \"channels_last\" | \"channels_first\":\n            self.data_format = data_format\n        case _:\n            raise ValueError(\"Unsupported channel configuration provided\")\n    self.channel_axis = 3 if self.data_format == \"channels_last\" else 1\n    self.axis_to_sum = (1, 2) if self.data_format == \"channels_last\" else (2, 3)\n    self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.pooling.GlobalSumPooling2D.call","title":"call","text":"<pre><code>call(inputs: tf.Tensor) -&gt; tf.Tensor\n</code></pre> <p>Calls the <code>GlobalSumPooling2D</code> layer.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>tf.Tensor</code> <p>Tensor of shape (<code>batch</code>,<code>height</code>,<code>width</code>,<code>channel</code>) or (<code>batch</code>,<code>channel</code>,<code>height</code>,<code>width</code>).</p> required <p>Returns:</p> Type Description <code>tf.Tensor</code> <p>Tensor of shape (<code>batch</code>,<code>channel</code>) where the elements are summed to reduce the axis.</p> Source code in <code>DeepSaki/layers/pooling.py</code> <pre><code>def call(self, inputs: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"Calls the `GlobalSumPooling2D` layer.\n\n    Args:\n        inputs (tf.Tensor): Tensor of shape (`batch`,`height`,`width`,`channel`) or\n            (`batch`,`channel`,`height`,`width`).\n\n    Returns:\n        Tensor of shape (`batch`,`channel`) where the elements are summed to reduce the axis.\n    \"\"\"\n    return tf.reduce_sum(input_tensor=inputs, axis=self.axis_to_sum, keepdims=False)\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.pooling.GlobalSumPooling2D.compute_output_shape","title":"compute_output_shape","text":"<pre><code>compute_output_shape(\n    input_shape: tf.TensorShape,\n) -&gt; tf.TensorShape\n</code></pre> <p>Computes the output shape of the layer.</p> <p>This method will cause the layer's state to be built, if that has not happened before. This requires that the layer will later be used with inputs that match the input shape provided here.</p> <p>Parameters:</p> Name Type Description Default <code>input_shape</code> <code>tf.TensorShape</code> <p>Shape of the input tensor to this layer.</p> required <p>Returns:</p> Type Description <code>tf.TensorShape</code> <p>A TensorShape instance representing the shape of the layer's output Tensor.</p> Source code in <code>DeepSaki/layers/pooling.py</code> <pre><code>def compute_output_shape(self, input_shape: tf.TensorShape) -&gt; tf.TensorShape:\n    \"\"\"Computes the output shape of the layer.\n\n    This method will cause the layer's state to be built, if that has not happened before. This requires that the\n    layer will later be used with inputs that match the input shape provided here.\n\n    Args:\n        input_shape (tf.TensorShape): Shape of the input tensor to this layer.\n\n    Returns:\n        A TensorShape instance representing the shape of the layer's output Tensor.\n    \"\"\"\n    input_shape = tf.TensorShape(input_shape).as_list()\n    return tf.TensorShape([input_shape[0], input_shape[self.channel_axis]])\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.pooling.GlobalSumPooling2D.get_config","title":"get_config","text":"<pre><code>get_config() -&gt; Dict[str, Any]\n</code></pre> <p>Serialization of the object.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with the class' variable names as keys.</p> Source code in <code>DeepSaki/layers/pooling.py</code> <pre><code>def get_config(self) -&gt; Dict[str, Any]:\n    \"\"\"Serialization of the object.\n\n    Returns:\n        Dictionary with the class' variable names as keys.\n    \"\"\"\n    config = super(GlobalSumPooling2D, self).get_config()\n    config.update({\"data_format\": self.data_format})\n    return config\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.pooling.LearnedPooling","title":"LearnedPooling","text":"<pre><code>LearnedPooling(pool_size: int = 2, **kwargs: Any)\n</code></pre> <p>             Bases: <code>tf.keras.layers.Layer</code></p> <p>Layer that learns a pooling operation.</p> <p>Instead of using MaxPooling2D or AveragePooling2D the layer learns a pooling operation.</p> Info <p>Under the hood this layer simply performs a non-overlapping convolution operation.</p> <p>Initializes an instance of <code>LearnedPooling</code>.</p> <p>Parameters:</p> Name Type Description Default <code>pool_size</code> <code>int</code> <p>Size of the pooling window and the stride of the convolution operation. If the input is of shape (b, h, w, c), the output is (b,h/pool_size,w/pool_size,c). Defaults to 2.</p> <code>2</code> <code>kwargs</code> <code>Any</code> <p>Additional key word arguments passed to the base class.</p> <code>{}</code> Source code in <code>DeepSaki/layers/pooling.py</code> <pre><code>def __init__(self, pool_size: int = 2, **kwargs: Any) -&gt; None:\n    \"\"\"Initializes an instance of `LearnedPooling`.\n\n    Args:\n        pool_size (int, optional): Size of the pooling window and the stride of the convolution operation. If the\n            input is of shape (b, h, w, c), the output is (b,h/pool_size,w/pool_size,c). Defaults to 2.\n        kwargs (Any): Additional key word arguments passed to the base class.\n    \"\"\"\n    super(LearnedPooling, self).__init__(**kwargs)\n    self.pool_size = pool_size\n    self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.pooling.LearnedPooling.build","title":"build","text":"<pre><code>build(input_shape: tf.TensorShape) -&gt; None\n</code></pre> <p>Build layer depending on the <code>input_shape</code> (output shape of the previous layer).</p> <p>Parameters:</p> Name Type Description Default <code>input_shape</code> <code>tf.TensorShape</code> <p>Shape of the input tensor to this layer.</p> required Source code in <code>DeepSaki/layers/pooling.py</code> <pre><code>def build(self, input_shape: tf.TensorShape) -&gt; None:\n    \"\"\"Build layer depending on the `input_shape` (output shape of the previous layer).\n\n    Args:\n        input_shape (tf.TensorShape): Shape of the input tensor to this layer.\n    \"\"\"\n    self.pooling = tf.keras.layers.Conv2D(\n        kernel_size=self.pool_size,\n        strides=self.pool_size,\n        filters=input_shape[-1],\n        use_bias=False,\n        padding=\"same\",\n    )\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.pooling.LearnedPooling.call","title":"call","text":"<pre><code>call(x: tf.Tensor) -&gt; tf.Tensor\n</code></pre> <p>Calls the <code>LearnedPooling</code> layer.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>tf.Tensor</code> <p>Tensor of shape (<code>batch</code>,<code>height</code>,<code>width</code>,<code>channel</code>).</p> required <p>Returns:</p> Type Description <code>tf.Tensor</code> <p>Pooled tensor of shape (<code>batch</code>,<code>height/pool_size</code>,<code>width/pool_size</code>,<code>channel</code>)</p> Source code in <code>DeepSaki/layers/pooling.py</code> <pre><code>def call(self, x: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"Calls the `LearnedPooling` layer.\n\n    Args:\n        x (tf.Tensor): Tensor of shape (`batch`,`height`,`width`,`channel`).\n\n    Returns:\n        Pooled tensor of shape (`batch`,`height/pool_size`,`width/pool_size`,`channel`)\n    \"\"\"\n    return self.pooling(x)\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.pooling.LearnedPooling.get_config","title":"get_config","text":"<pre><code>get_config() -&gt; Dict[str, Any]\n</code></pre> <p>Serialization of the object.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with the class' variable names as keys.</p> Source code in <code>DeepSaki/layers/pooling.py</code> <pre><code>def get_config(self) -&gt; Dict[str, Any]:\n    \"\"\"Serialization of the object.\n\n    Returns:\n        Dictionary with the class' variable names as keys.\n    \"\"\"\n    config = super(LearnedPooling, self).get_config()\n    config.update({\"pool_size\": self.pool_size})\n    return config\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_composites.Conv2DBlock","title":"Conv2DBlock","text":"<pre><code>Conv2DBlock(\n    filters: int = 3,\n    kernels: int = 3,\n    split_kernels: bool = False,\n    number_of_blocks: int = 1,\n    activation: str = \"leaky_relu\",\n    dropout_rate: float = 0.0,\n    final_activation: bool = True,\n    use_spec_norm: bool = False,\n    strides: Tuple[int, int] = (1, 1),\n    padding: PaddingType = PaddingType.ZERO,\n    apply_final_normalization: bool = True,\n    use_bias: bool = True,\n    kernel_initializer: Optional[\n        tf.keras.initializers.Initializer\n    ] = None,\n    gamma_initializer: Optional[\n        tf.keras.initializers.Initializer\n    ] = None,\n)\n</code></pre> <p>             Bases: <code>tf.keras.layers.Layer</code></p> <p>Wraps a two-dimensional convolution into a more complex building block.</p> <p>Initializes the <code>Conv2DBlock</code> layer.</p> <p>Parameters:</p> Name Type Description Default <code>filters</code> <code>int</code> <p>Number of individual filters. Defaults to 3.</p> <code>3</code> <code>kernels</code> <code>int</code> <p>Size of the convolutions kernels. Defaults to 3.</p> <code>3</code> <code>split_kernels</code> <code>bool</code> <p>To decrease the number of parameters, a convolution with the kernel_size <code>(kernel,kernel)</code> can be splitted into two consecutive convolutions with the kernel_size <code>(kernel,1)</code> and <code>(1,kernel)</code> respectivly. Defaults to False.</p> <code>False</code> <code>number_of_blocks</code> <code>int</code> <p>Number of consecutive convolutional building blocks, i.e. <code>Conv2DBlock</code>. Defaults to 1.</p> <code>1</code> <code>activation</code> <code>str</code> <p>String literal or tensorflow activation function object to obtain activation function. Defaults to \"leaky_relu\".</p> <code>'leaky_relu'</code> <code>dropout_rate</code> <code>float</code> <p>Probability of the dropout layer. If the preceeding layer has more than one channel, spatial dropout is applied, otherwise standard dropout. Defaults to 0.0.</p> <code>0.0</code> <code>final_activation</code> <code>bool</code> <p>Whether or not to activate the output of this layer. Defaults to True.</p> <code>True</code> <code>use_spec_norm</code> <code>bool</code> <p>Applies spectral normalization to convolutional and dense layers. Defaults to False.</p> <code>False</code> <code>strides</code> <code>Tuple[int, int]</code> <p>Stride of the filter. Defaults to (1, 1).</p> <code>(1, 1)</code> <code>padding</code> <code>PaddingType</code> <p>Padding type. Defaults to PaddingType.ZERO.</p> <code>PaddingType.ZERO</code> <code>apply_final_normalization</code> <code>bool</code> <p>Whether or not to place a normalization on the layer's output. Defaults to True.</p> <code>True</code> <code>use_bias</code> <code>bool</code> <p>Whether convolutions and dense layers include a bias or not. Defaults to True.</p> <code>True</code> <code>kernel_initializer</code> <code>tf.keras.initializers.Initializer</code> <p>Initialization of the convolutions kernels. Defaults to None.</p> <code>None</code> <code>gamma_initializer</code> <code>tf.keras.initializers.Initializer</code> <p>Initialization of the normalization layers. Defaults to None.</p> <code>None</code> Source code in <code>DeepSaki/layers/layer_composites.py</code> <pre><code>def __init__(\n    self,\n    filters: int = 3,\n    kernels: int = 3,\n    split_kernels: bool = False,\n    number_of_blocks: int = 1,\n    activation: str = \"leaky_relu\",\n    dropout_rate: float = 0.0,\n    final_activation: bool = True,\n    use_spec_norm: bool = False,\n    strides: Tuple[int, int] = (1, 1),\n    padding: PaddingType = PaddingType.ZERO,\n    apply_final_normalization: bool = True,\n    use_bias: bool = True,\n    kernel_initializer: Optional[tf.keras.initializers.Initializer] = None,\n    gamma_initializer: Optional[tf.keras.initializers.Initializer] = None,\n) -&gt; None:\n    \"\"\"Initializes the `Conv2DBlock` layer.\n\n    Args:\n        filters (int, optional): Number of individual filters. Defaults to 3.\n        kernels (int, optional): Size of the convolutions kernels. Defaults to 3.\n        split_kernels (bool, optional): To decrease the number of parameters, a convolution with the kernel_size\n            `(kernel,kernel)` can be splitted into two consecutive convolutions with the kernel_size `(kernel,1)`\n            and `(1,kernel)` respectivly. Defaults to False.\n        number_of_blocks (int, optional): Number of consecutive convolutional building blocks, i.e. `Conv2DBlock`.\n            Defaults to 1.\n        activation (str, optional): String literal or tensorflow activation function object to obtain activation\n            function. Defaults to \"leaky_relu\".\n        dropout_rate (float, optional): Probability of the dropout layer. If the preceeding layer has more than one\n            channel, spatial dropout is applied, otherwise standard dropout. Defaults to 0.0.\n        final_activation (bool, optional): Whether or not to activate the output of this layer. Defaults to True.\n        use_spec_norm (bool, optional): Applies spectral normalization to convolutional and dense layers.\n            Defaults to False.\n        strides (Tuple[int, int], optional): Stride of the filter. Defaults to (1, 1).\n        padding (PaddingType, optional): Padding type. Defaults to PaddingType.ZERO.\n        apply_final_normalization (bool, optional): Whether or not to place a normalization on the layer's output.\n            Defaults to True.\n        use_bias (bool, optional): Whether convolutions and dense layers include a bias or not. Defaults to True.\n        kernel_initializer (tf.keras.initializers.Initializer, optional): Initialization of the convolutions kernels.\n            Defaults to None.\n        gamma_initializer (tf.keras.initializers.Initializer, optional): Initialization of the normalization layers.\n            Defaults to None.\n    \"\"\"\n    super(Conv2DBlock, self).__init__()\n    self.filters = filters\n    self.kernels = kernels\n    self.split_kernels = split_kernels\n    self.number_of_blocks = number_of_blocks\n    self.activation = activation\n    self.dropout_rate = dropout_rate\n    self.final_activation = final_activation\n    self.use_spec_norm = use_spec_norm\n    self.strides = strides\n    self.padding = padding\n    self.apply_final_normalization = apply_final_normalization\n    self.use_bias = use_bias\n    self.kernel_initializer = HeAlphaUniform() if kernel_initializer is None else kernel_initializer\n    self.gamma_initializer = HeAlphaUniform() if gamma_initializer is None else gamma_initializer\n    self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n\n    pad = (kernels - 1) // 2  # assumes odd kernel size, which is typical!\n\n    self.blocks = []\n    for block in range(number_of_blocks):\n        layers = []\n        if pad != 0 and self.padding != PaddingType.NONE:\n            layers.append(pad_func(pad_values=(pad, pad), padding_type=self.padding))\n        layers.append(self._get_conv_layer())\n\n        if block != (self.number_of_blocks - 1) or self.apply_final_normalization:\n            layers.append(tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer))  #\n\n        if block != (self.number_of_blocks - 1) or self.final_activation:\n            layers.append(tf.keras.layers.Activation(self.activation))\n\n        self.blocks.append(layers)\n\n    self.dropout = dropout_func(filters, dropout_rate)\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_composites.Conv2DBlock.call","title":"call","text":"<pre><code>call(inputs: tf.Tensor) -&gt; tf.Tensor\n</code></pre> <p>Calls the <code>Conv2DBlock</code> layer.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>tf.Tensor</code> <p>Tensor of shape (b, h, w, c)</p> required <p>Returns:</p> Type Description <code>tf.Tensor</code> <p>Tensor of shape (b, h/(<code>strides[0]</code><code>number_of_blocks</code>), w/(<code>strides[1]</code><code>number_of_blocks</code>), <code>filters</code>).</p> Source code in <code>DeepSaki/layers/layer_composites.py</code> <pre><code>def call(self, inputs: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"Calls the `Conv2DBlock` layer.\n\n    Args:\n        inputs (tf.Tensor): Tensor of shape (b, h, w, c)\n\n    Returns:\n        Tensor of shape (b, h/(`strides[0]`**`number_of_blocks`), w/(`strides[1]`**`number_of_blocks`), `filters`).\n    \"\"\"\n    x = inputs\n\n    for block in self.blocks:\n        for layer in block:\n            x = layer(x)\n\n    if self.dropout_rate &gt; 0:\n        x = self.dropout(x)\n\n    return x\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_composites.Conv2DBlock.get_config","title":"get_config","text":"<pre><code>get_config() -&gt; Dict[str, Any]\n</code></pre> <p>Serialization of the object.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with the class' variable names as keys.</p> Source code in <code>DeepSaki/layers/layer_composites.py</code> <pre><code>def get_config(self) -&gt; Dict[str, Any]:\n    \"\"\"Serialization of the object.\n\n    Returns:\n        Dictionary with the class' variable names as keys.\n    \"\"\"\n    config = super(Conv2DBlock, self).get_config()\n    config.update(\n        {\n            \"filters\": self.filters,\n            \"kernels\": self.kernels,\n            \"split_kernels\": self.split_kernels,\n            \"number_of_blocks\": self.number_of_blocks,\n            \"activation\": self.activation,\n            \"dropout_rate\": self.dropout_rate,\n            \"final_activation\": self.final_activation,\n            \"use_spec_norm\": self.use_spec_norm,\n            \"strides\": self.strides,\n            \"padding\": self.padding,\n            \"apply_final_normalization\": self.apply_final_normalization,\n            \"use_bias\": self.use_bias,\n            \"kernel_initializer\": self.kernel_initializer,\n            \"gamma_initializer\": self.gamma_initializer,\n        }\n    )\n    return config\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_composites.Conv2DSplitted","title":"Conv2DSplitted","text":"<pre><code>Conv2DSplitted(\n    filters: int = 3,\n    kernels: int = 3,\n    use_spec_norm: bool = False,\n    strides: Tuple[int, int] = (1, 1),\n    use_bias: bool = True,\n    padding: str = \"valid\",\n    kernel_initializer: Optional[\n        tf.keras.initializers.Initializer\n    ] = None,\n)\n</code></pre> <p>             Bases: <code>tf.keras.layers.Layer</code></p> <p>Convolution layer where a single convolution is splitted into two consecutive convolutions.</p> <p>To decrease the number of parameters, a convolution with the kernel_size (kernel,kernel) can be splitted into two consecutive convolutions with the kernel_size (kernel,1) and (1,kernel) respectivly.</p> <p>Initialize the <code>Conv2DSplitted</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>filters</code> <code>int</code> <p>Number of filters in the output feature map. Defaults to 3.</p> <code>3</code> <code>kernels</code> <code>int</code> <p>Size of the convolutions' kernels, which will be translated to (kernels, 1) and (1,kernels) for the first and seccond convolution respectivly. Defaults to 3.</p> <code>3</code> <code>use_spec_norm</code> <code>bool</code> <p>Applies spectral normalization to convolutional and dense layers. Defaults to False.</p> <code>False</code> <code>strides</code> <code>Tuple[int, int]</code> <p>Strides of the convolution layers. Defaults to (1, 1).</p> <code>(1, 1)</code> <code>use_bias</code> <code>bool</code> <p>Whether or not to use bias weights. Defaults to True.</p> <code>True</code> <code>padding</code> <code>str</code> <p>[\"valid\"|\"same\"]</p> <code>'valid'</code> <code>kernel_initializer</code> <code>tf.keras.initializers.Initializer</code> <p>Initialization of the convolutions kernels. Defaults to None.</p> <code>None</code> Source code in <code>DeepSaki/layers/layer_composites.py</code> <pre><code>def __init__(\n    self,\n    filters: int = 3,\n    kernels: int = 3,\n    use_spec_norm: bool = False,\n    strides: Tuple[int, int] = (1, 1),\n    use_bias: bool = True,\n    padding: str = \"valid\",\n    kernel_initializer: Optional[tf.keras.initializers.Initializer] = None,\n) -&gt; None:\n    \"\"\"Initialize the `Conv2DSplitted` object.\n\n    Args:\n        filters (int, optional): Number of filters in the output feature map. Defaults to 3.\n        kernels (int, optional): Size of the convolutions' kernels, which will be translated to (kernels, 1) and\n            (1,kernels) for the first and seccond convolution respectivly. Defaults to 3.\n        use_spec_norm (bool, optional): Applies spectral normalization to convolutional and dense layers. Defaults\n            to False.\n        strides (Tuple[int, int], optional): Strides of the convolution layers. Defaults to (1, 1).\n        use_bias (bool, optional): Whether or not to use bias weights. Defaults to True.\n        padding (str, optional): [\"valid\"|\"same\"]\n        kernel_initializer (tf.keras.initializers.Initializer, optional): Initialization of the convolutions\n            kernels. Defaults to None.\n    \"\"\"\n    super(Conv2DSplitted, self).__init__()\n    self.filters = filters\n    self.kernels = kernels\n    self.use_spec_norm = use_spec_norm\n    self.strides = strides\n    self.use_bias = use_bias\n    self.padding = padding\n    self.kernel_initializer = HeAlphaUniform() if kernel_initializer is None else kernel_initializer\n    self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n\n    self.conv1 = tf.keras.layers.Conv2D(\n        filters=filters,\n        kernel_size=(kernels, 1),\n        kernel_initializer=kernel_initializer,\n        use_bias=use_bias,\n        padding=padding,\n        strides=(strides[0], 1),\n    )\n    self.conv2 = tf.keras.layers.Conv2D(\n        filters=filters,\n        kernel_size=(1, kernels),\n        kernel_initializer=kernel_initializer,\n        use_bias=use_bias,\n        padding=padding,\n        strides=(1, strides[1]),\n    )\n\n    if use_spec_norm:\n        self.conv1 = tfa.layers.SpectralNormalization(self.conv1)\n        self.conv2 = tfa.layers.SpectralNormalization(self.conv2)\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_composites.Conv2DSplitted.call","title":"call","text":"<pre><code>call(inputs: tf.Tensor) -&gt; tf.Tensor\n</code></pre> <p>Calls the <code>Conv2DSplitted</code> layer.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>tf.Tensor</code> <p>Tensor of shape <code>(batch, height, width, channel)</code>.</p> required <p>Returns:</p> Type Description <code>tf.Tensor</code> <p>Convoluted tensor of shape <code>(batch, H, W, filters)</code>, where <code>H</code> and <code>W</code> depend on the padding type used in the convolution layers.</p> Source code in <code>DeepSaki/layers/layer_composites.py</code> <pre><code>def call(self, inputs: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"Calls the `Conv2DSplitted` layer.\n\n    Args:\n        inputs (tf.Tensor): Tensor of shape `(batch, height, width, channel)`.\n\n    Returns:\n        Convoluted tensor of shape `(batch, H, W, filters)`, where `H` and `W` depend on the padding type used in\n            the convolution layers.\n    \"\"\"\n    x = self.conv1(inputs)\n    return self.conv2(x)\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_composites.Conv2DSplitted.get_config","title":"get_config","text":"<pre><code>get_config() -&gt; Dict[str, Any]\n</code></pre> <p>Serialization of the object.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with the class' variable names as keys.</p> Source code in <code>DeepSaki/layers/layer_composites.py</code> <pre><code>def get_config(self) -&gt; Dict[str, Any]:\n    \"\"\"Serialization of the object.\n\n    Returns:\n        Dictionary with the class' variable names as keys.\n    \"\"\"\n    config = super(Conv2DSplitted, self).get_config()\n    config.update(\n        {\n            \"filters\": self.filters,\n            \"kernels\": self.kernels,\n            \"use_spec_norm\": self.use_spec_norm,\n            \"strides\": self.strides,\n            \"use_bias\": self.use_bias,\n            \"padding\": self.padding,\n            \"kernel_initializer\": self.kernel_initializer,\n        }\n    )\n    return config\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_composites.DenseBlock","title":"DenseBlock","text":"<pre><code>DenseBlock(\n    units: int,\n    number_of_blocks: int = 1,\n    activation: str = \"leaky_relu\",\n    dropout_rate: float = 0.0,\n    final_activation: bool = True,\n    use_spec_norm: bool = False,\n    apply_final_normalization: bool = True,\n    use_bias: bool = True,\n    kernel_initializer: Optional[\n        tf.keras.initializers.Initializer\n    ] = None,\n    gamma_initializer: Optional[\n        tf.keras.initializers.Initializer\n    ] = None,\n)\n</code></pre> <p>             Bases: <code>tf.keras.layers.Layer</code></p> <p>Wraps a dense layer into a more complex building block.</p> <p>Initializes the <code>DenseBlock</code> layer.</p> <p>Parameters:</p> Name Type Description Default <code>units</code> <code>int</code> <p>Number of units of each dense block</p> required <code>number_of_blocks</code> <code>int</code> <p>Number of consecutive subblocks. Defaults to 1.</p> <code>1</code> <code>activation</code> <code>str</code> <p>String literal to obtain activation function. Defaults to \"leaky_relu\".</p> <code>'leaky_relu'</code> <code>dropout_rate</code> <code>float</code> <p>Probability of the dropout layer dropping weights. If the preceeding layer has more than one channel, spatial dropout is applied, otherwise standard dropout. Defaults to 0.0.</p> <code>0.0</code> <code>final_activation</code> <code>bool</code> <p>Whether or not to activate the output of this layer. Defaults to True.</p> <code>True</code> <code>use_spec_norm</code> <code>bool</code> <p>Applies spectral normalization to dense layers. Defaults to False.</p> <code>False</code> <code>apply_final_normalization</code> <code>bool</code> <p>Whether or not to apply normalization at the layer's output. Defaults to True.</p> <code>True</code> <code>use_bias</code> <code>bool</code> <p>Whether dense layers include bias weights. Defaults to True.</p> <code>True</code> <code>kernel_initializer</code> <code>tf.keras.initializers.Initializer</code> <p>Initialization of the convolutions kernels. Defaults to None.</p> <code>None</code> <code>gamma_initializer</code> <code>tf.keras.initializers.Initializer</code> <p>Initialization of the normalization layers. Defaults to None.</p> <code>None</code> Source code in <code>DeepSaki/layers/layer_composites.py</code> <pre><code>def __init__(\n    self,\n    units: int,\n    number_of_blocks: int = 1,\n    activation: str = \"leaky_relu\",\n    dropout_rate: float = 0.0,\n    final_activation: bool = True,\n    use_spec_norm: bool = False,\n    apply_final_normalization: bool = True,\n    use_bias: bool = True,\n    kernel_initializer: Optional[tf.keras.initializers.Initializer] = None,\n    gamma_initializer: Optional[tf.keras.initializers.Initializer] = None,\n) -&gt; None:\n    \"\"\"Initializes the `DenseBlock` layer.\n\n    Args:\n        units (int): Number of units of each dense block\n        number_of_blocks (int, optional): Number of consecutive subblocks. Defaults to 1.\n        activation (str, optional): String literal to obtain activation function. Defaults to \"leaky_relu\".\n        dropout_rate (float, optional): Probability of the dropout layer dropping weights. If the preceeding layer\n            has more than one channel, spatial dropout is applied, otherwise standard dropout. Defaults to 0.0.\n        final_activation (bool, optional): Whether or not to activate the output of this layer. Defaults to True.\n        use_spec_norm (bool, optional): Applies spectral normalization to dense layers. Defaults to False.\n        apply_final_normalization (bool, optional): Whether or not to apply normalization at the layer's output.\n            Defaults to True.\n        use_bias (bool, optional): Whether dense layers include bias weights. Defaults to True.\n        kernel_initializer (tf.keras.initializers.Initializer, optional): Initialization of the convolutions kernels.\n            Defaults to None.\n        gamma_initializer (tf.keras.initializers.Initializer, optional): Initialization of the normalization layers.\n            Defaults to None.\n    \"\"\"\n    super(DenseBlock, self).__init__()\n    self.units = units\n    self.number_of_blocks = number_of_blocks\n    self.dropout_rate = dropout_rate\n    self.activation = activation\n    self.final_activation = final_activation\n    self.use_spec_norm = use_spec_norm\n    self.apply_final_normalization = apply_final_normalization\n    self.use_bias = use_bias\n    self.kernel_initializer = HeAlphaUniform() if kernel_initializer is None else kernel_initializer\n    self.gamma_initializer = HeAlphaUniform() if gamma_initializer is None else gamma_initializer\n    self.input_spec = tf.keras.layers.InputSpec(min_ndim=2)\n\n    self.blocks = []\n    for block in range(number_of_blocks):\n        layers = []\n        layers.append(self._get_dense_layer())\n\n        if block != (number_of_blocks - 1) or self.apply_final_normalization:\n            layers.append(tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer))\n\n        if block != (number_of_blocks - 1) or self.final_activation:\n            layers.append(tf.keras.layers.Activation(self.activation))\n\n        self.blocks.append(layers)\n\n    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_composites.DenseBlock.call","title":"call","text":"<pre><code>call(inputs: tf.Tensor) -&gt; tf.Tensor\n</code></pre> <p>Calls the <code>DenseBlock</code> layer.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>tf.Tensor</code> <p>Tensor of shape (b, h, w, c)</p> required <p>Returns:</p> Type Description <code>tf.Tensor</code> <p>Tensor of shape (b, h, w, <code>units</code>).</p> Source code in <code>DeepSaki/layers/layer_composites.py</code> <pre><code>def call(self, inputs: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"Calls the `DenseBlock` layer.\n\n    Args:\n        inputs (tf.Tensor): Tensor of shape (b, h, w, c)\n\n    Returns:\n        Tensor of shape (b, h, w, `units`).\n    \"\"\"\n    x = inputs\n\n    for block in self.blocks:\n        for layer in block:\n            x = layer(x)\n\n    if self.dropout_rate &gt; 0:\n        x = self.dropout(x)\n    return x\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_composites.DenseBlock.get_config","title":"get_config","text":"<pre><code>get_config() -&gt; Dict[str, Any]\n</code></pre> <p>Serialization of the object.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with the class' variable names as keys.</p> Source code in <code>DeepSaki/layers/layer_composites.py</code> <pre><code>def get_config(self) -&gt; Dict[str, Any]:\n    \"\"\"Serialization of the object.\n\n    Returns:\n        Dictionary with the class' variable names as keys.\n    \"\"\"\n    config = super(DenseBlock, self).get_config()\n    config.update(\n        {\n            \"units\": self.units,\n            \"number_of_blocks\": self.number_of_blocks,\n            \"dropout_rate\": self.dropout_rate,\n            \"activation\": self.activation,\n            \"final_activation\": self.final_activation,\n            \"use_spec_norm\": self.use_spec_norm,\n            \"apply_final_normalization\": self.apply_final_normalization,\n            \"use_bias\": self.use_bias,\n            \"kernel_initializer\": self.kernel_initializer,\n            \"gamma_initializer\": self.gamma_initializer,\n        }\n    )\n    return config\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_composites.DownSampleBlock","title":"DownSampleBlock","text":"<pre><code>DownSampleBlock(\n    downsampling: str = \"average_pooling\",\n    activation: str = \"leaky_relu\",\n    kernels: int = 3,\n    use_spec_norm: bool = False,\n    padding: PaddingType = PaddingType.ZERO,\n    use_bias: bool = True,\n    kernel_initializer: Optional[\n        tf.keras.initializers.Initializer\n    ] = None,\n    gamma_initializer: Optional[\n        tf.keras.initializers.Initializer\n    ] = None,\n)\n</code></pre> <p>             Bases: <code>tf.keras.layers.Layer</code></p> <p>Spatial down-sampling for grid-like data using <code>DeepSaki.layers.ConvBlock2D()</code>.</p> <p>Initializes the <code>DownSampleBlock</code> layer.</p> <p>Parameters:</p> Name Type Description Default <code>downsampling</code> <code>str</code> <p>Downsampling method used. Defaults to \"average_pooling\".</p> <code>'average_pooling'</code> <code>activation</code> <code>str</code> <p>String literal or tensorflow activation function object to obtain activation function. Defaults to \"leaky_relu\".</p> <code>'leaky_relu'</code> <code>kernels</code> <code>int</code> <p>Size of the convolutions kernels. Defaults to 3.</p> <code>3</code> <code>use_spec_norm</code> <code>bool</code> <p>Applies spectral normalization to convolutional and dense layers. Defaults to False.</p> <code>False</code> <code>padding</code> <code>PaddingType</code> <p>Padding type. Defaults to PaddingType.ZERO.</p> <code>PaddingType.ZERO</code> <code>use_bias</code> <code>bool</code> <p>Whether convolutions and dense layers include a bias or not. Defaults to True.</p> <code>True</code> <code>kernel_initializer</code> <code>tf.keras.initializers.Initializer</code> <p>Initialization of the convolutions kernels. Defaults to None.</p> <code>None</code> <code>gamma_initializer</code> <code>tf.keras.initializers.Initializer</code> <p>Initialization of the normalization layers. Defaults to None.</p> <code>None</code> Source code in <code>DeepSaki/layers/layer_composites.py</code> <pre><code>def __init__(\n    self,\n    downsampling: str = \"average_pooling\",\n    activation: str = \"leaky_relu\",\n    kernels: int = 3,\n    use_spec_norm: bool = False,\n    padding: PaddingType = PaddingType.ZERO,\n    use_bias: bool = True,\n    kernel_initializer: Optional[tf.keras.initializers.Initializer] = None,\n    gamma_initializer: Optional[tf.keras.initializers.Initializer] = None,\n) -&gt; None:\n    \"\"\"Initializes the `DownSampleBlock` layer.\n\n    Args:\n        downsampling (str, optional): Downsampling method used. Defaults to \"average_pooling\".\n        activation (str, optional): String literal or tensorflow activation function object to obtain activation\n            function. Defaults to \"leaky_relu\".\n        kernels (int, optional): Size of the convolutions kernels. Defaults to 3.\n        use_spec_norm (bool, optional): Applies spectral normalization to convolutional and dense layers. Defaults\n            to False.\n        padding (PaddingType, optional): Padding type. Defaults to PaddingType.ZERO.\n        use_bias (bool, optional): Whether convolutions and dense layers include a bias or not. Defaults to True.\n        kernel_initializer (tf.keras.initializers.Initializer, optional): Initialization of the convolutions kernels.\n            Defaults to None.\n        gamma_initializer (tf.keras.initializers.Initializer, optional): Initialization of the normalization layers.\n            Defaults to None.\n    \"\"\"\n    super(DownSampleBlock, self).__init__()\n    self.kernels = kernels\n    self.downsampling = downsampling\n    self.activation = activation\n    self.use_spec_norm = use_spec_norm\n    self.padding = padding\n    self.use_bias = use_bias\n    self.kernel_initializer = HeAlphaUniform() if kernel_initializer is None else kernel_initializer\n    self.gamma_initializer = HeAlphaUniform() if gamma_initializer is None else gamma_initializer\n    self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_composites.DownSampleBlock.build","title":"build","text":"<pre><code>build(input_shape: tf.TensorShape) -&gt; None\n</code></pre> <p>Build layer depending on the <code>input_shape</code> (output shape of the previous layer).</p> <p>Parameters:</p> Name Type Description Default <code>input_shape</code> <code>tf.TensorShape</code> <p>Shape of the input tensor to this layer.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>if unsupported downsampling is provided.</p> Source code in <code>DeepSaki/layers/layer_composites.py</code> <pre><code>def build(self, input_shape: tf.TensorShape) -&gt; None:\n    \"\"\"Build layer depending on the `input_shape` (output shape of the previous layer).\n\n    Args:\n        input_shape (tf.TensorShape): Shape of the input tensor to this layer.\n\n    Raises:\n        ValueError: if unsupported downsampling is provided.\n    \"\"\"\n    super(DownSampleBlock, self).build(input_shape)\n\n    self.layers = []\n    if self.downsampling == \"conv_stride_2\":\n        self.layers.append(\n            Conv2DBlock(\n                input_shape[-1],\n                self.kernels,\n                activation=self.activation,\n                strides=(2, 2),\n                use_spec_norm=self.use_spec_norm,\n                padding=self.padding,\n                use_bias=self.use_bias,\n                kernel_initializer=self.kernel_initializer,\n                gamma_initializer=self.gamma_initializer,\n            )\n        )\n    elif self.downsampling == \"max_pooling\":\n        # Only spatial downsampling, increase in features is done by the conv2D_block specified later!\n        self.layers.append(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n    elif self.downsampling == \"average_pooling\":\n        self.layers.append(tf.keras.layers.AveragePooling2D(pool_size=(2, 2)))\n    elif self.downsampling == \"space_to_depth\":\n        self.layers.append(self._space_to_depth_block_size_2)\n        self.layers.append(\n            tf.keras.layers.Conv2D(\n                filters=input_shape[-1],\n                kernel_size=1,\n                activation=self.activation,\n                use_bias=False,\n                padding=\"same\",\n                kernel_initializer=self.kernel_initializer,\n            )\n        )\n    else:\n        raise ValueError(\"Undefined downsampling provided\")\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_composites.DownSampleBlock.call","title":"call","text":"<pre><code>call(inputs: tf.Tensor) -&gt; tf.Tensor\n</code></pre> <p>Calls the <code>DownSampleBlock</code> layer.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>tf.Tensor</code> <p>Tensor of shape (b,h,w,c)</p> required <p>Returns:</p> Type Description <code>tf.Tensor</code> <p>Spatially downsampled tensor of shape (b,h/2,w/2,c)</p> Source code in <code>DeepSaki/layers/layer_composites.py</code> <pre><code>def call(self, inputs: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"Calls the `DownSampleBlock` layer.\n\n    Args:\n        inputs (tf.Tensor): Tensor of shape (b,h,w,c)\n\n    Returns:\n        Spatially downsampled tensor of shape (b,h/2,w/2,c)\n    \"\"\"\n    x = inputs\n    for layer in self.layers:\n        x = layer(x)\n\n    return x\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_composites.DownSampleBlock.get_config","title":"get_config","text":"<pre><code>get_config() -&gt; Dict[str, Any]\n</code></pre> <p>Serialization of the object.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with the class' variable names as keys.</p> Source code in <code>DeepSaki/layers/layer_composites.py</code> <pre><code>def get_config(self) -&gt; Dict[str, Any]:\n    \"\"\"Serialization of the object.\n\n    Returns:\n        Dictionary with the class' variable names as keys.\n    \"\"\"\n    config = super(DownSampleBlock, self).get_config()\n    config.update(\n        {\n            \"kernels\": self.kernels,\n            \"downsampling\": self.downsampling,\n            \"activation\": self.activation,\n            \"use_spec_norm\": self.use_spec_norm,\n            \"padding\": self.padding,\n            \"use_bias\": self.use_bias,\n            \"kernel_initializer\": self.kernel_initializer,\n            \"gamma_initializer\": self.gamma_initializer,\n        }\n    )\n    return config\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_composites.ResBlockDown","title":"ResBlockDown","text":"<pre><code>ResBlockDown(\n    activation: str = \"leaky_relu\",\n    use_spec_norm: bool = False,\n    use_bias: bool = True,\n    padding: PaddingType = PaddingType.ZERO,\n    kernel_initializer: Optional[\n        tf.keras.initializers.Initializer\n    ] = None,\n    gamma_initializer: Optional[\n        tf.keras.initializers.Initializer\n    ] = None,\n)\n</code></pre> <p>             Bases: <code>tf.keras.layers.Layer</code></p> <p>Spatial down-sampling with residual connection for grid-like data using <code>DeepSaki.layers.ConvBlock2D()</code>.</p> Architecture <pre><code>flowchart LR\n    i([input_tensor])--&gt; c1 &amp; c2\n    subgraph ResBlockDown\n        subgraph Block[2x]\n        c1[dsk.layers.Conv2DBlock]\n        end\n        c1--&gt;ap1[AveragePooling2D]\n        c2[dsk.layers.Conv2DBlock]--&gt;ap2[AveragePooling2D]\n        ap1 &amp; ap2--&gt;add((+))\n    end\n    add--&gt;o([output_tensor])</code></pre> <p>Initializes the <code>ResBlockDown</code> layer.</p> <p>Parameters:</p> Name Type Description Default <code>activation</code> <code>str</code> <p>String literal or tensorflow activation function object to obtain activation function. Defaults to \"leaky_relu\".</p> <code>'leaky_relu'</code> <code>use_spec_norm</code> <code>bool</code> <p>Applies spectral normalization to convolutional and dense layers. Defaults to False.</p> <code>False</code> <code>use_bias</code> <code>bool</code> <p>Whether convolutions and dense layers include a bias or not. Defaults to True.</p> <code>True</code> <code>padding</code> <code>PaddingType</code> <p>Padding type. Defaults to PaddingType.ZERO.</p> <code>PaddingType.ZERO</code> <code>kernel_initializer</code> <code>tf.keras.initializers.Initializer</code> <p>Initialization of the convolutions kernels. Defaults to None.</p> <code>None</code> <code>gamma_initializer</code> <code>tf.keras.initializers.Initializer</code> <p>Initialization of the normalization layers. Defaults to None.</p> <code>None</code> Source code in <code>DeepSaki/layers/layer_composites.py</code> <pre><code>def __init__(\n    self,\n    activation: str = \"leaky_relu\",\n    use_spec_norm: bool = False,\n    use_bias: bool = True,\n    padding: PaddingType = PaddingType.ZERO,\n    kernel_initializer: Optional[tf.keras.initializers.Initializer] = None,\n    gamma_initializer: Optional[tf.keras.initializers.Initializer] = None,\n) -&gt; None:\n    \"\"\"Initializes the `ResBlockDown` layer.\n\n    Args:\n        activation (str, optional): String literal or tensorflow activation function object to obtain activation\n            function. Defaults to \"leaky_relu\".\n        use_spec_norm (bool, optional): Applies spectral normalization to convolutional and dense layers. Defaults\n            to False.\n        use_bias (bool, optional): Whether convolutions and dense layers include a bias or not. Defaults to True.\n        padding (PaddingType, optional): Padding type. Defaults to PaddingType.ZERO.\n        kernel_initializer (tf.keras.initializers.Initializer, optional): Initialization of the convolutions kernels.\n            Defaults to None.\n        gamma_initializer (tf.keras.initializers.Initializer, optional): Initialization of the normalization layers.\n            Defaults to None.\n    \"\"\"\n    super(ResBlockDown, self).__init__()\n    self.activation = activation\n    self.use_spec_norm = use_spec_norm\n    self.use_bias = use_bias\n    self.padding = padding\n    self.kernel_initializer = HeAlphaUniform() if kernel_initializer is None else kernel_initializer\n    self.gamma_initializer = HeAlphaUniform() if gamma_initializer is None else gamma_initializer\n    self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_composites.ResBlockDown.build","title":"build","text":"<pre><code>build(input_shape: tf.TensorShape) -&gt; None\n</code></pre> <p>Build layer depending on the <code>input_shape</code> (output shape of the previous layer).</p> <p>Parameters:</p> Name Type Description Default <code>input_shape</code> <code>tf.TensorShape</code> <p>Shape of the input tensor to this layer.</p> required Source code in <code>DeepSaki/layers/layer_composites.py</code> <pre><code>def build(self, input_shape: tf.TensorShape) -&gt; None:\n    \"\"\"Build layer depending on the `input_shape` (output shape of the previous layer).\n\n    Args:\n        input_shape (tf.TensorShape): Shape of the input tensor to this layer.\n    \"\"\"\n    super(ResBlockDown, self).build(input_shape)\n\n    self.convRes = Conv2DBlock(\n        filters=input_shape[-1],\n        kernels=1,\n        split_kernels=False,\n        number_of_blocks=1,\n        activation=self.activation,\n        use_spec_norm=self.use_spec_norm,\n        use_bias=self.use_bias,\n        padding=self.padding,\n        kernel_initializer=self.kernel_initializer,\n        gamma_initializer=self.gamma_initializer,\n    )\n    self.conv1 = Conv2DBlock(\n        filters=input_shape[-1],\n        kernels=3,\n        split_kernels=False,\n        number_of_blocks=1,\n        activation=self.activation,\n        use_spec_norm=self.use_spec_norm,\n        use_bias=self.use_bias,\n        padding=self.padding,\n        kernel_initializer=self.kernel_initializer,\n        gamma_initializer=self.gamma_initializer,\n    )\n    self.conv2 = Conv2DBlock(\n        filters=input_shape[-1],\n        kernels=3,\n        split_kernels=False,\n        number_of_blocks=1,\n        activation=self.activation,\n        use_spec_norm=self.use_spec_norm,\n        use_bias=self.use_bias,\n        padding=self.padding,\n        kernel_initializer=self.kernel_initializer,\n        gamma_initializer=self.gamma_initializer,\n    )\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_composites.ResBlockDown.call","title":"call","text":"<pre><code>call(inputs: tf.Tensor) -&gt; tf.Tensor\n</code></pre> <p>Calls the <code>ResBlockDown</code> layer.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>tf.Tensor</code> <p>Tensor of shape (b,h,w,c)</p> required <p>Returns:</p> Type Description <code>tf.Tensor</code> <p>Spatially downsampled tensor of shape (b,h/2,w/2,c)</p> Source code in <code>DeepSaki/layers/layer_composites.py</code> <pre><code>def call(self, inputs: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"Calls the `ResBlockDown` layer.\n\n    Args:\n        inputs (tf.Tensor): Tensor of shape (b,h,w,c)\n\n    Returns:\n        Spatially downsampled tensor of shape (b,h/2,w/2,c)\n    \"\"\"\n    path1 = inputs\n    path2 = inputs\n\n    path1 = self.convRes(path1)\n    path1 = tf.keras.layers.AveragePooling2D()(path1)\n\n    path2 = self.conv1(path2)\n    path2 = self.conv2(path2)\n    path2 = tf.keras.layers.AveragePooling2D()(path2)\n\n    return tf.keras.layers.Add()([path1, path2])\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_composites.ResBlockDown.get_config","title":"get_config","text":"<pre><code>get_config() -&gt; Dict[str, Any]\n</code></pre> <p>Serialization of the object.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with the class' variable names as keys.</p> Source code in <code>DeepSaki/layers/layer_composites.py</code> <pre><code>def get_config(self) -&gt; Dict[str, Any]:\n    \"\"\"Serialization of the object.\n\n    Returns:\n        Dictionary with the class' variable names as keys.\n    \"\"\"\n    config = super(ResBlockDown, self).get_config()\n    config.update(\n        {\n            \"activation\": self.activation,\n            \"use_spec_norm\": self.use_spec_norm,\n            \"use_bias\": self.use_bias,\n            \"padding\": self.padding,\n            \"kernel_initializer\": self.kernel_initializer,\n            \"gamma_initializer\": self.gamma_initializer,\n        }\n    )\n    return config\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_composites.ResBlockUp","title":"ResBlockUp","text":"<pre><code>ResBlockUp(\n    activation: str = \"leaky_relu\",\n    use_spec_norm: bool = False,\n    use_bias: bool = True,\n    padding: PaddingType = PaddingType.ZERO,\n    kernel_initializer: Optional[\n        tf.keras.initializers.Initializer\n    ] = None,\n    gamma_initializer: Optional[\n        tf.keras.initializers.Initializer\n    ] = None,\n)\n</code></pre> <p>             Bases: <code>tf.keras.layers.Layer</code></p> <p>Spatial up-sampling with residual connection for grid-like data using <code>DeepSaki.layers.ConvBlock2D()</code>.</p> Architecture <pre><code>flowchart LR\n    i([input_tensor])--&gt;up1 &amp; up2\n    subgraph ResBlockUp\n        up1[UpSample2D]--&gt;c1\n        subgraph Block[2x]\n        c1[dsk.layers.Conv2DBlock]\n        end\n        up2[UpSample2D]--&gt;c2[dsk.layers.Conv2DBlock]\n        c1 &amp; c2--&gt;add((+))\n    end\n    add--&gt;o([output_tensor])</code></pre> <p>Initializes the <code>ResBlockUp</code> layer.</p> <p>Parameters:</p> Name Type Description Default <code>activation</code> <code>str</code> <p>String literal or tensorflow activation function object to obtain activation function. Defaults to \"leaky_relu\".</p> <code>'leaky_relu'</code> <code>use_spec_norm</code> <code>bool</code> <p>Applies spectral normalization to convolutional and dense layers. Defaults to False.</p> <code>False</code> <code>use_bias</code> <code>bool</code> <p>Whether convolutions and dense layers include a bias or not. Defaults to True.</p> <code>True</code> <code>padding</code> <code>PaddingType</code> <p>Padding type. Defaults to PaddingType.ZERO.</p> <code>PaddingType.ZERO</code> <code>kernel_initializer</code> <code>tf.keras.initializers.Initializer</code> <p>Initialization of the convolutions kernels. Defaults to None.</p> <code>None</code> <code>gamma_initializer</code> <code>tf.keras.initializers.Initializer</code> <p>Initialization of the normalization layers. Defaults to None.</p> <code>None</code> Source code in <code>DeepSaki/layers/layer_composites.py</code> <pre><code>def __init__(\n    self,\n    activation: str = \"leaky_relu\",\n    use_spec_norm: bool = False,\n    use_bias: bool = True,\n    padding: PaddingType = PaddingType.ZERO,\n    kernel_initializer: Optional[tf.keras.initializers.Initializer] = None,\n    gamma_initializer: Optional[tf.keras.initializers.Initializer] = None,\n) -&gt; None:\n    \"\"\"Initializes the `ResBlockUp` layer.\n\n    Args:\n        activation (str, optional): String literal or tensorflow activation function object to obtain activation\n            function. Defaults to \"leaky_relu\".\n        use_spec_norm (bool, optional): Applies spectral normalization to convolutional and dense layers. Defaults\n            to False.\n        use_bias (bool, optional): Whether convolutions and dense layers include a bias or not. Defaults to True.\n        padding (PaddingType, optional): Padding type. Defaults to PaddingType.ZERO.\n        kernel_initializer (tf.keras.initializers.Initializer, optional): Initialization of the convolutions kernels.\n            Defaults to None.\n        gamma_initializer (tf.keras.initializers.Initializer, optional): Initialization of the normalization layers.\n            Defaults to None.\n    \"\"\"\n    super(ResBlockUp, self).__init__()\n    self.activation = activation\n    self.use_spec_norm = use_spec_norm\n    self.use_bias = use_bias\n    self.padding = padding\n    self.kernel_initializer = HeAlphaUniform() if kernel_initializer is None else kernel_initializer\n    self.gamma_initializer = HeAlphaUniform() if gamma_initializer is None else gamma_initializer\n    self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_composites.ResBlockUp.build","title":"build","text":"<pre><code>build(input_shape: tf.TensorShape) -&gt; None\n</code></pre> <p>Build layer depending on the <code>input_shape</code> (output shape of the previous layer).</p> <p>Parameters:</p> Name Type Description Default <code>input_shape</code> <code>tf.TensorShape</code> <p>Shape of the input tensor to this layer.</p> required Source code in <code>DeepSaki/layers/layer_composites.py</code> <pre><code>def build(self, input_shape: tf.TensorShape) -&gt; None:\n    \"\"\"Build layer depending on the `input_shape` (output shape of the previous layer).\n\n    Args:\n        input_shape (tf.TensorShape): Shape of the input tensor to this layer.\n    \"\"\"\n    super(ResBlockUp, self).build(input_shape)\n    self.convRes = Conv2DBlock(\n        filters=input_shape[-1],\n        kernels=1,\n        split_kernels=False,\n        number_of_blocks=1,\n        activation=self.activation,\n        use_spec_norm=self.use_spec_norm,\n        use_bias=self.use_bias,\n        padding=self.padding,\n        kernel_initializer=self.kernel_initializer,\n        gamma_initializer=self.gamma_initializer,\n    )\n    self.conv1 = Conv2DBlock(\n        filters=input_shape[-1],\n        kernels=3,\n        split_kernels=False,\n        number_of_blocks=1,\n        activation=self.activation,\n        use_spec_norm=self.use_spec_norm,\n        use_bias=self.use_bias,\n        padding=self.padding,\n        kernel_initializer=self.kernel_initializer,\n        gamma_initializer=self.gamma_initializer,\n    )\n    self.conv2 = Conv2DBlock(\n        filters=input_shape[-1],\n        kernels=3,\n        split_kernels=False,\n        number_of_blocks=1,\n        activation=self.activation,\n        use_spec_norm=self.use_spec_norm,\n        use_bias=self.use_bias,\n        padding=self.padding,\n        kernel_initializer=self.kernel_initializer,\n        gamma_initializer=self.gamma_initializer,\n    )\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_composites.ResBlockUp.call","title":"call","text":"<pre><code>call(inputs: tf.Tensor) -&gt; tf.Tensor\n</code></pre> <p>Calls the <code>ResBlockUp</code> layer.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>tf.Tensor</code> <p>Tensor of shape (b,h,w,c)</p> required <p>Returns:</p> Type Description <code>tf.Tensor</code> <p>Tensor of shape (b,h2,w2,c)</p> Source code in <code>DeepSaki/layers/layer_composites.py</code> <pre><code>def call(self, inputs: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"Calls the `ResBlockUp` layer.\n\n    Args:\n        inputs (tf.Tensor): Tensor of shape (b,h,w,c)\n\n    Returns:\n        Tensor of shape (b,h*2,w*2,c)\n    \"\"\"\n    path1 = inputs\n    path2 = inputs\n\n    path1 = tf.keras.layers.UpSampling2D()(path1)\n    path1 = self.convRes(path1)\n\n    path2 = tf.keras.layers.UpSampling2D()(path2)\n    path2 = self.conv1(path2)\n    path2 = self.conv2(path2)\n\n    return tf.keras.layers.Add()([path1, path2])\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_composites.ResBlockUp.get_config","title":"get_config","text":"<pre><code>get_config() -&gt; Dict[str, Any]\n</code></pre> <p>Serialization of the object.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with the class' variable names as keys.</p> Source code in <code>DeepSaki/layers/layer_composites.py</code> <pre><code>def get_config(self) -&gt; Dict[str, Any]:\n    \"\"\"Serialization of the object.\n\n    Returns:\n        Dictionary with the class' variable names as keys.\n    \"\"\"\n    config = super(ResBlockUp, self).get_config()\n    config.update(\n        {\n            \"activation\": self.activation,\n            \"use_spec_norm\": self.use_spec_norm,\n            \"use_bias\": self.use_bias,\n            \"padding\": self.padding,\n            \"kernel_initializer\": self.kernel_initializer,\n            \"gamma_initializer\": self.gamma_initializer,\n        }\n    )\n    return config\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_composites.ResidualBlock","title":"ResidualBlock","text":"<pre><code>ResidualBlock(\n    filters: int = 3,\n    kernels: int = 3,\n    activation: str = \"leaky_relu\",\n    number_of_blocks: int = 1,\n    use_spec_norm: bool = False,\n    residual_cardinality: int = 1,\n    dropout_rate: float = 0.0,\n    use_bias: bool = True,\n    padding: PaddingType = PaddingType.ZERO,\n    kernel_initializer: Optional[\n        tf.keras.initializers.Initializer\n    ] = None,\n    gamma_initializer: Optional[\n        tf.keras.initializers.Initializer\n    ] = None,\n)\n</code></pre> <p>             Bases: <code>tf.keras.layers.Layer</code></p> <p>Residual block with configurable cardinality.</p> <p>Initializes the <code>ResidualBlock</code> layer.</p> <p>Parameters:</p> Name Type Description Default <code>filters</code> <code>int</code> <p>Number of individual filters. Defaults to 3.</p> <code>3</code> <code>kernels</code> <code>int</code> <p>Size of the convolutions kernels. Defaults to 3.</p> <code>3</code> <code>activation</code> <code>str</code> <p>String literal or tensorflow activation function object to obtain activation function. Defaults to \"leaky_relu\".</p> <code>'leaky_relu'</code> <code>number_of_blocks</code> <code>int</code> <p>Number of residual subblocks. Defaults to 1.</p> <code>1</code> <code>use_spec_norm</code> <code>bool</code> <p>Applies spectral normalization to convolutional and dense layers. Defaults to False.</p> <code>False</code> <code>residual_cardinality</code> <code>int</code> <p>Number of parallel paths. Defaults to 1.</p> <code>1</code> <code>dropout_rate</code> <code>float</code> <p>Probability of the dropout layer. If the preceeding layer has more than one channel, spatial dropout is applied, otherwise standard dropout. Defaults to 0.0.</p> <code>0.0</code> <code>use_bias</code> <code>bool</code> <p>Whether convolutions and dense layers include a bias or not. Defaults to True.</p> <code>True</code> <code>padding</code> <code>PaddingType</code> <p>Padding type. Defaults to PaddingType.ZERO.</p> <code>PaddingType.ZERO</code> <code>kernel_initializer</code> <code>tf.keras.initializers.Initializer</code> <p>Initialization of the convolutions kernels. Defaults to None.</p> <code>None</code> <code>gamma_initializer</code> <code>tf.keras.initializers.Initializer</code> <p>Initialization of the normalization layers. Defaults to None.</p> <code>None</code> Source code in <code>DeepSaki/layers/layer_composites.py</code> <pre><code>def __init__(\n    self,\n    filters: int = 3,\n    kernels: int = 3,\n    activation: str = \"leaky_relu\",\n    number_of_blocks: int = 1,\n    use_spec_norm: bool = False,\n    residual_cardinality: int = 1,\n    dropout_rate: float = 0.0,\n    use_bias: bool = True,\n    padding: PaddingType = PaddingType.ZERO,\n    kernel_initializer: Optional[tf.keras.initializers.Initializer] = None,\n    gamma_initializer: Optional[tf.keras.initializers.Initializer] = None,\n) -&gt; None:\n    \"\"\"Initializes the `ResidualBlock` layer.\n\n    Args:\n        filters (int, optional): Number of individual filters. Defaults to 3.\n        kernels (int, optional): Size of the convolutions kernels. Defaults to 3.\n        activation (str, optional): String literal or tensorflow activation function object to obtain activation\n            function. Defaults to \"leaky_relu\".\n        number_of_blocks (int, optional): Number of residual subblocks. Defaults to 1.\n        use_spec_norm (bool, optional): Applies spectral normalization to convolutional and dense layers. Defaults\n            to False.\n        residual_cardinality (int, optional): Number of parallel paths. Defaults to 1.\n        dropout_rate (float, optional): Probability of the dropout layer. If the preceeding layer has more than one\n            channel, spatial dropout is applied, otherwise standard dropout. Defaults to 0.0.\n        use_bias (bool, optional): Whether convolutions and dense layers include a bias or not. Defaults to True.\n        padding (PaddingType, optional): Padding type. Defaults to PaddingType.ZERO.\n        kernel_initializer (tf.keras.initializers.Initializer, optional): Initialization of the convolutions kernels.\n            Defaults to None.\n        gamma_initializer (tf.keras.initializers.Initializer, optional): Initialization of the normalization layers.\n            Defaults to None.\n    \"\"\"\n    super(ResidualBlock, self).__init__()\n    self.activation = activation\n    self.filters = filters\n    self.kernels = kernels\n    self.number_of_blocks = number_of_blocks\n    self.use_spec_norm = use_spec_norm\n    self.residual_cardinality = residual_cardinality\n    self.dropout_rate = dropout_rate\n    self.use_bias = use_bias\n    self.padding = padding\n    self.kernel_initializer = HeAlphaUniform() if kernel_initializer is None else kernel_initializer\n    self.gamma_initializer = HeAlphaUniform() if gamma_initializer is None else gamma_initializer\n    self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n\n    self.pad = int((kernels - 1) / 2)  # assumes odd kernel size, which is typical!\n\n    if residual_cardinality &gt; 1:\n        self.intermediateFilters = int(max(filters / 32, filters / 16, filters / 8, filters / 4, filters / 2, 1))\n    else:\n        self.intermediateFilters = int(max(filters / 4, filters / 2, 1))\n\n    # for each block, add several con\n    self.blocks = []\n    for _ in range(number_of_blocks):\n        cardinals = [\n            [\n                Conv2DBlock(\n                    filters=self.intermediateFilters,\n                    kernels=1,\n                    split_kernels=False,\n                    number_of_blocks=1,\n                    activation=activation,\n                    use_spec_norm=use_spec_norm,\n                    use_bias=use_bias,\n                    padding=padding,\n                    kernel_initializer=self.kernel_initializer,\n                    gamma_initializer=self.gamma_initializer,\n                ),\n                Conv2DBlock(\n                    filters=self.intermediateFilters,\n                    kernels=kernels,\n                    split_kernels=False,\n                    number_of_blocks=1,\n                    activation=activation,\n                    padding=PaddingType.NONE,\n                    use_spec_norm=use_spec_norm,\n                    use_bias=use_bias,\n                    kernel_initializer=self.kernel_initializer,\n                    gamma_initializer=self.gamma_initializer,\n                ),\n                Conv2DBlock(\n                    filters=filters,\n                    kernels=1,\n                    split_kernels=False,\n                    number_of_blocks=1,\n                    activation=activation,\n                    use_spec_norm=use_spec_norm,\n                    use_bias=use_bias,\n                    padding=padding,\n                    kernel_initializer=self.kernel_initializer,\n                    gamma_initializer=self.gamma_initializer,\n                ),\n            ]\n            for _ in range(residual_cardinality)\n        ]\n        self.blocks.append(cardinals)\n    self.dropout = dropout_func(filters, dropout_rate)\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_composites.ResidualBlock.build","title":"build","text":"<pre><code>build(input_shape: tf.TensorShape) -&gt; None\n</code></pre> <p>Build layer depending on the <code>input_shape</code> (output shape of the previous layer).</p> <p>Parameters:</p> Name Type Description Default <code>input_shape</code> <code>tf.TensorShape</code> <p>Shape of the input tensor to this layer.</p> required Source code in <code>DeepSaki/layers/layer_composites.py</code> <pre><code>def build(self, input_shape: tf.TensorShape) -&gt; None:\n    \"\"\"Build layer depending on the `input_shape` (output shape of the previous layer).\n\n    Args:\n        input_shape (tf.TensorShape): Shape of the input tensor to this layer.\n    \"\"\"\n    super(ResidualBlock, self).build(input_shape)\n    self.conv0 = None\n    if input_shape[-1] != self.filters:\n        self.conv0 = Conv2DBlock(\n            filters=self.filters,\n            kernels=1,\n            split_kernels=False,\n            number_of_blocks=1,\n            activation=self.activation,\n            use_spec_norm=self.use_spec_norm,\n            use_bias=self.use_bias,\n            padding=self.padding,\n            kernel_initializer=self.kernel_initializer,\n            gamma_initializer=self.gamma_initializer,\n        )\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_composites.ResidualBlock.call","title":"call","text":"<pre><code>call(inputs: tf.Tensor) -&gt; tf.Tensor\n</code></pre> <p>Calls the <code>ResidualBlock</code> layer.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>tf.Tensor</code> <p>Tensor of shape (batch, height, width, channel)</p> required <p>Returns:</p> Type Description <code>tf.Tensor</code> <p>Tensor of shape (batch, height, width, <code>filters</code>)</p> Source code in <code>DeepSaki/layers/layer_composites.py</code> <pre><code>def call(self, inputs: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"Calls the `ResidualBlock` layer.\n\n    Args:\n        inputs (tf.Tensor): Tensor of shape (batch, height, width, channel)\n\n    Returns:\n        Tensor of shape (batch, height, width, `filters`)\n    \"\"\"\n    x = inputs\n\n    if self.conv0 is not None:\n        x = self.conv0(x)\n\n    for block in range(self.number_of_blocks):\n        residual = x\n\n        if self.pad != 0 and self.padding != PaddingType.NONE:\n            x = pad_func(pad_values=(self.pad, self.pad), padding_type=self.padding)(x)\n\n        # y is allways the footpoint of the cardinality blocks\n        y = x\n        for cardinal in range(self.residual_cardinality):\n            # after the first iteration c is the previous cardinality block output\n            # its used to iterativly add the result, rather than summing all at once.\n            # performance reasons, since otherwise multiple arrays must be stored at once!\n            c = x\n            x = self.blocks[block][cardinal][0](y)\n            x = self.blocks[block][cardinal][1](x)\n            x = self.blocks[block][cardinal][2](x)\n            if cardinal &gt; 0:\n                x = tf.keras.layers.Add()([x, c])\n\n        x = tf.keras.layers.Add()([x, residual])\n\n    if self.dropout_rate &gt; 0:\n        x = self.dropout(x)\n\n    return x\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_composites.ResidualBlock.get_config","title":"get_config","text":"<pre><code>get_config() -&gt; Dict[str, Any]\n</code></pre> <p>Serialization of the object.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with the class' variable names as keys.</p> Source code in <code>DeepSaki/layers/layer_composites.py</code> <pre><code>def get_config(self) -&gt; Dict[str, Any]:\n    \"\"\"Serialization of the object.\n\n    Returns:\n        Dictionary with the class' variable names as keys.\n    \"\"\"\n    config = super(ResidualBlock, self).get_config()\n    config.update(\n        {\n            \"activation\": self.activation,\n            \"filters\": self.filters,\n            \"kernels\": self.kernels,\n            \"number_of_blocks\": self.number_of_blocks,\n            \"use_spec_norm\": self.use_spec_norm,\n            \"residual_cardinality\": self.residual_cardinality,\n            \"dropout_rate\": self.dropout_rate,\n            \"use_bias\": self.use_bias,\n            \"padding\": self.padding,\n            \"kernel_initializer\": self.kernel_initializer,\n            \"gamma_initializer\": self.gamma_initializer,\n        }\n    )\n    return config\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_composites.ScalarGatedSelfAttention","title":"ScalarGatedSelfAttention","text":"<pre><code>ScalarGatedSelfAttention(\n    use_spec_norm: bool = False,\n    intermediate_channel: Optional[bool] = None,\n    kernel_initializer: Optional[\n        tf.keras.initializers.Initializer\n    ] = None,\n    gamma_initializer: Optional[\n        tf.keras.initializers.Initializer\n    ] = None,\n)\n</code></pre> <p>             Bases: <code>tf.keras.layers.Layer</code></p> <p>Scaled dot-product self attention that is gated by a learnable scalar.</p> Info <p>Implementation as used in the VoloGAN paper.</p> Architecture <pre><code>flowchart LR\n    i([input_tensor])--&gt;f &amp; g &amp; h\n    subgraph ScalarGatedSelfAttention\n        f[dsk.layers.DenseBlock] --&gt; t[Transpose]\n        g[dsk.layers.DenseBlock] &amp; t --&gt; m1[Multiply] --&gt; s[SoftMax]\n        h[dsk.layers.DenseBlock] &amp; s --&gt; m2[Multiply] --&gt; v[DenseBlock] --&gt; sc[dsk.layers.ScaleLayer]\n    end\n    sc --&gt;o([output_tensor])</code></pre> <p>Initializes the <code>ScalarGatedSelfAttention</code> layer.</p> <p>Parameters:</p> Name Type Description Default <code>use_spec_norm</code> <code>bool</code> <p>If true, applies spectral normalization to convolutional and dense layers. Defaults to False.</p> <code>False</code> <code>intermediate_channel</code> <code>Optional[bool]</code> <p>Intermediate channels for the self attention mechanism. Defaults to None.</p> <code>None</code> <code>kernel_initializer</code> <code>tf.keras.initializers.Initializer</code> <p>Initialization of the kernel weights. Defaults to None.</p> <code>None</code> <code>gamma_initializer</code> <code>tf.keras.initializers.Initializer</code> <p>Initialization of the normalization layers. Defaults to None.</p> <code>None</code> Source code in <code>DeepSaki/layers/layer_composites.py</code> <pre><code>def __init__(\n    self,\n    use_spec_norm: bool = False,\n    intermediate_channel: Optional[bool] = None,\n    kernel_initializer: Optional[tf.keras.initializers.Initializer] = None,\n    gamma_initializer: Optional[tf.keras.initializers.Initializer] = None,\n) -&gt; None:\n    \"\"\"Initializes the `ScalarGatedSelfAttention` layer.\n\n    Args:\n        use_spec_norm (bool, optional): If true, applies spectral normalization to convolutional and dense layers.\n            Defaults to False.\n        intermediate_channel (Optional[bool], optional): Intermediate channels for the self attention mechanism.\n            Defaults to None.\n        kernel_initializer (tf.keras.initializers.Initializer, optional): Initialization of the kernel weights.\n            Defaults to None.\n        gamma_initializer (tf.keras.initializers.Initializer, optional): Initialization of the normalization layers.\n            Defaults to None.\n    \"\"\"\n    super(ScalarGatedSelfAttention, self).__init__()\n    self.use_spec_norm = use_spec_norm\n    self.intermediate_channel = intermediate_channel\n    self.kernel_initializer = HeAlphaUniform() if kernel_initializer is None else kernel_initializer\n    self.gamma_initializer = HeAlphaUniform() if gamma_initializer is None else gamma_initializer\n    self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_composites.ScalarGatedSelfAttention.build","title":"build","text":"<pre><code>build(input_shape: tf.TensorShape) -&gt; None\n</code></pre> <p>Build layer depending on the <code>input_shape</code> (output shape of the previous layer).</p> <p>Parameters:</p> Name Type Description Default <code>input_shape</code> <code>tf.TensorShape</code> <p>Shape of the input tensor to this layer.</p> required Source code in <code>DeepSaki/layers/layer_composites.py</code> <pre><code>def build(self, input_shape: tf.TensorShape) -&gt; None:\n    \"\"\"Build layer depending on the `input_shape` (output shape of the previous layer).\n\n    Args:\n        input_shape (tf.TensorShape): Shape of the input tensor to this layer.\n    \"\"\"\n    super(ScalarGatedSelfAttention, self).build(input_shape)\n    batch_size, height, width, num_channel = input_shape\n    if self.intermediate_channel is None:\n        self.intermediate_channel = num_channel\n\n    self.w_f = DenseBlock(\n        units=self.intermediate_channel,\n        use_spec_norm=self.use_spec_norm,\n        number_of_blocks=1,\n        activation=None,\n        apply_final_normalization=False,\n        use_bias=False,\n        kernel_initializer=self.kernel_initializer,\n        gamma_initializer=self.gamma_initializer,\n    )\n    self.w_g = DenseBlock(\n        units=self.intermediate_channel,\n        use_spec_norm=self.use_spec_norm,\n        number_of_blocks=1,\n        activation=None,\n        apply_final_normalization=False,\n        use_bias=False,\n        kernel_initializer=self.kernel_initializer,\n        gamma_initializer=self.gamma_initializer,\n    )\n    self.w_h = DenseBlock(\n        units=self.intermediate_channel,\n        use_spec_norm=self.use_spec_norm,\n        number_of_blocks=1,\n        activation=None,\n        apply_final_normalization=False,\n        use_bias=False,\n        kernel_initializer=self.kernel_initializer,\n        gamma_initializer=self.gamma_initializer,\n    )\n    self.w_fgh = DenseBlock(\n        units=num_channel,\n        use_spec_norm=self.use_spec_norm,\n        number_of_blocks=1,\n        activation=None,\n        apply_final_normalization=False,\n        use_bias=False,\n        kernel_initializer=self.kernel_initializer,\n        gamma_initializer=self.gamma_initializer,\n    )\n\n    self.LN_f = tf.keras.layers.LayerNormalization(gamma_initializer=self.gamma_initializer)\n    self.LN_g = tf.keras.layers.LayerNormalization(gamma_initializer=self.gamma_initializer)\n    self.LN_h = tf.keras.layers.LayerNormalization(gamma_initializer=self.gamma_initializer)\n    self.LN_fgh = tf.keras.layers.LayerNormalization(gamma_initializer=self.gamma_initializer)\n    self.scale = ScaleLayer()\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_composites.ScalarGatedSelfAttention.call","title":"call","text":"<pre><code>call(inputs: tf.Tensor) -&gt; tf.Tensor\n</code></pre> <p>Calls the <code>ScalarGatedSelfAttention</code> layer.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>tf.Tensor</code> <p>Tensor of shape (batch, height, width, channel)</p> required <p>Returns:</p> Type Description <code>tf.Tensor</code> <p>Tensor with same shape as input.</p> Source code in <code>DeepSaki/layers/layer_composites.py</code> <pre><code>def call(self, inputs: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"Calls the `ScalarGatedSelfAttention` layer.\n\n    Args:\n        inputs (tf.Tensor): Tensor of shape (batch, height, width, channel)\n\n    Returns:\n        Tensor with same shape as input.\n    \"\"\"\n    f = self.w_f(inputs)\n    f = self.LN_f(f)\n    f = tf.keras.layers.Permute(dims=(2, 1, 3))(f)\n\n    g = self.w_g(inputs)\n    g = self.LN_g(g)\n\n    h = self.w_h(inputs)\n    h = self.LN_h(h)\n\n    f_g = tf.keras.layers.Multiply()([f, g])\n    f_g = tf.keras.layers.Softmax(axis=1)(f_g)\n\n    f_g_h = tf.keras.layers.Multiply()([f_g, h])\n    f_g_h = self.w_fgh(f_g_h)\n    f_g_h = self.LN_fgh(f_g_h)\n    f_g_h = self.scale(f_g_h)\n\n    return tf.keras.layers.Add()([f_g_h, inputs])\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_composites.ScalarGatedSelfAttention.get_config","title":"get_config","text":"<pre><code>get_config() -&gt; Dict[str, Any]\n</code></pre> <p>Serialization of the object.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with the class' variable names as keys.</p> Source code in <code>DeepSaki/layers/layer_composites.py</code> <pre><code>def get_config(self) -&gt; Dict[str, Any]:\n    \"\"\"Serialization of the object.\n\n    Returns:\n        Dictionary with the class' variable names as keys.\n    \"\"\"\n    config = super(ScalarGatedSelfAttention, self).get_config()\n    config.update(\n        {\n            \"use_spec_norm\": self.use_spec_norm,\n            \"intermediate_channel\": self.intermediate_channel,\n            \"gamma_initializer\": self.gamma_initializer,\n            \"kernel_initializer\": self.kernel_initializer,\n        }\n    )\n    return config\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_composites.ScaleLayer","title":"ScaleLayer","text":"<pre><code>ScaleLayer(\n    initializer: Optional[\n        tf.keras.initializers.Initializer\n    ] = None,\n)\n</code></pre> <p>             Bases: <code>tf.keras.layers.Layer</code></p> <p>Trainable non-negative scalar that might be used as a trainable gate.</p> <p>It is a single learnable weight that is multiplied by all weights of the input tensor through broadcasting.</p> <p>Initializes the <code>ScaleLayer</code> layer.</p> <p>Parameters:</p> Name Type Description Default <code>initializer</code> <code>tf.keras.initializers.Initializer</code> <p>Initializer used to initialize the scalar weight. Defaults to None..</p> <code>None</code> Source code in <code>DeepSaki/layers/layer_composites.py</code> <pre><code>def __init__(self, initializer: Optional[tf.keras.initializers.Initializer] = None) -&gt; None:\n    \"\"\"Initializes the `ScaleLayer` layer.\n\n    Args:\n        initializer (tf.keras.initializers.Initializer, optional): Initializer used to initialize the scalar weight.\n            Defaults to None..\n    \"\"\"\n    super(ScaleLayer, self).__init__()\n    self.initializer = tf.keras.initializers.Ones() if initializer is None else initializer\n    self.scale = self.add_weight(shape=[1], initializer=initializer, constraint=NonNegative(), trainable=True)\n    self.input_spec = tf.keras.layers.InputSpec(min_ndim=1)\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_composites.ScaleLayer.call","title":"call","text":"<pre><code>call(inputs: tf.Tensor) -&gt; tf.Tensor\n</code></pre> <p>Calls the <code>ScaleLayer</code> layer.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>tf.Tensor</code> <p>Tensor of shape (batch, ...).</p> required <p>Returns:</p> Type Description <code>tf.Tensor</code> <p>Non-negative scaled version of the input. Tensor of shape (batch, ...).</p> Source code in <code>DeepSaki/layers/layer_composites.py</code> <pre><code>def call(self, inputs: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"Calls the `ScaleLayer` layer.\n\n    Args:\n        inputs (tf.Tensor): Tensor of shape (batch, ...).\n\n    Returns:\n        Non-negative scaled version of the input. Tensor of shape (batch, ...).\n    \"\"\"\n    return inputs * self.scale\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_composites.ScaleLayer.get_config","title":"get_config","text":"<pre><code>get_config() -&gt; Dict[str, Any]\n</code></pre> <p>Serialization of the object.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with the class' variable names as keys.</p> Source code in <code>DeepSaki/layers/layer_composites.py</code> <pre><code>def get_config(self) -&gt; Dict[str, Any]:\n    \"\"\"Serialization of the object.\n\n    Returns:\n        Dictionary with the class' variable names as keys.\n    \"\"\"\n    config = super(ScaleLayer, self).get_config()\n    config.update({\"scale\": self.scale, \"initializer\": self.initializer})\n    return config\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_composites.UpSampleBlock","title":"UpSampleBlock","text":"<pre><code>UpSampleBlock(\n    upsampling: str = \"2D_upsample_and_conv\",\n    activation: str = \"leaky_relu\",\n    kernels: int = 3,\n    use_spec_norm: bool = False,\n    use_bias: bool = True,\n    padding: PaddingType = PaddingType.ZERO,\n    kernel_initializer: Optional[\n        tf.keras.initializers.Initializer\n    ] = None,\n    gamma_initializer: Optional[\n        tf.keras.initializers.Initializer\n    ] = None,\n)\n</code></pre> <p>             Bases: <code>tf.keras.layers.Layer</code></p> <p>Spatial up-sampling for grid-like data using <code>DeepSaki.layers.ConvBlock2D()</code>.</p> <p>Initializes the <code>UpSampleBlock</code> layer.</p> <p>Parameters:</p> Name Type Description Default <code>upsampling</code> <code>str</code> <p>description. Defaults to \"2D_upsample_and_conv\".</p> <code>'2D_upsample_and_conv'</code> <code>activation</code> <code>str</code> <p>String literal or tensorflow activation function object to obtain activation function. Defaults to \"leaky_relu\".</p> <code>'leaky_relu'</code> <code>kernels</code> <code>int</code> <p>Size of the convolutions kernels. Defaults to 3.</p> <code>3</code> <code>use_spec_norm</code> <code>bool</code> <p>Applies spectral normalization to convolutional and dense layers. Defaults to False.</p> <code>False</code> <code>use_bias</code> <code>bool</code> <p>Whether convolutions and dense layers include a bias or not. Defaults to True.</p> <code>True</code> <code>padding</code> <code>PaddingType</code> <p>Padding type. Defaults to PaddingType.ZERO.</p> <code>PaddingType.ZERO</code> <code>kernel_initializer</code> <code>tf.keras.initializers.Initializer</code> <p>Initialization of the convolutions kernels. Defaults to None.</p> <code>None</code> <code>gamma_initializer</code> <code>tf.keras.initializers.Initializer</code> <p>Initialization of the normalization layers. Defaults to None.</p> <code>None</code> Source code in <code>DeepSaki/layers/layer_composites.py</code> <pre><code>def __init__(\n    self,\n    upsampling: str = \"2D_upsample_and_conv\",\n    activation: str = \"leaky_relu\",\n    kernels: int = 3,\n    use_spec_norm: bool = False,\n    use_bias: bool = True,\n    padding: PaddingType = PaddingType.ZERO,\n    kernel_initializer: Optional[tf.keras.initializers.Initializer] = None,\n    gamma_initializer: Optional[tf.keras.initializers.Initializer] = None,\n) -&gt; None:\n    \"\"\"Initializes the `UpSampleBlock` layer.\n\n    Args:\n        upsampling (str, optional): _description_. Defaults to \"2D_upsample_and_conv\".\n        activation (str, optional): String literal or tensorflow activation function object to obtain activation\n            function. Defaults to \"leaky_relu\".\n        kernels (int, optional): Size of the convolutions kernels. Defaults to 3.\n        use_spec_norm (bool, optional): Applies spectral normalization to convolutional and dense layers. Defaults\n            to False.\n        use_bias (bool, optional): Whether convolutions and dense layers include a bias or not. Defaults to True.\n        padding (PaddingType, optional): Padding type. Defaults to PaddingType.ZERO.\n        kernel_initializer (tf.keras.initializers.Initializer, optional): Initialization of the convolutions kernels.\n            Defaults to None.\n        gamma_initializer (tf.keras.initializers.Initializer, optional): Initialization of the normalization layers.\n            Defaults to None.\n    \"\"\"\n    super(UpSampleBlock, self).__init__()\n    self.kernels = kernels\n    self.activation = activation\n    self.use_spec_norm = use_spec_norm\n    self.upsampling = upsampling\n    self.use_bias = use_bias\n    self.kernel_initializer = HeAlphaUniform() if kernel_initializer is None else kernel_initializer\n    self.gamma_initializer = HeAlphaUniform() if gamma_initializer is None else gamma_initializer\n    self.padding = padding\n    self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_composites.UpSampleBlock.build","title":"build","text":"<pre><code>build(input_shape: tf.TensorShape) -&gt; None\n</code></pre> <p>Build layer depending on the <code>input_shape</code> (output shape of the previous layer).</p> <p>Parameters:</p> Name Type Description Default <code>input_shape</code> <code>tf.TensorShape</code> <p>Shape of the input tensor to this layer.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>upsampling</code> is not supported.</p> Source code in <code>DeepSaki/layers/layer_composites.py</code> <pre><code>def build(self, input_shape: tf.TensorShape) -&gt; None:\n    \"\"\"Build layer depending on the `input_shape` (output shape of the previous layer).\n\n    Args:\n        input_shape (tf.TensorShape): Shape of the input tensor to this layer.\n\n    Raises:\n        ValueError: if `upsampling` is not supported.\n    \"\"\"\n    super(UpSampleBlock, self).build(input_shape)\n    self.layers = []\n\n    if self.upsampling == \"2D_upsample_and_conv\":\n        self.layers.append(tf.keras.layers.UpSampling2D(interpolation=\"bilinear\"))\n        self.layers.append(\n            Conv2DBlock(\n                filters=input_shape[-1],\n                kernels=1,\n                number_of_blocks=1,\n                activation=self.activation,\n                use_spec_norm=self.use_spec_norm,\n                use_bias=self.use_bias,\n                padding=self.padding,\n                kernel_initializer=self.kernel_initializer,\n                gamma_initializer=self.gamma_initializer,\n            )\n        )\n    elif self.upsampling == \"transpose_conv\":\n        self.layers.append(\n            tf.keras.layers.Conv2DTranspose(\n                input_shape[-1],\n                kernel_size=(self.kernels, self.kernels),\n                strides=(2, 2),\n                kernel_initializer=self.kernel_initializer,\n                padding=\"same\",\n                use_bias=self.use_bias,\n            )\n        )\n        self.layers.append(tfa.layers.InstanceNormalization(gamma_initializer=self.gamma_initializer))\n        self.layers.append(tf.keras.layers.Activation(self.activation))\n    elif self.upsampling == \"depth_to_space\":\n        self.layers.append(\n            tf.keras.layers.Conv2D(\n                filters=4 * input_shape[-1],\n                kernel_size=1,\n                activation=self.activation,\n                use_bias=False,\n                padding=\"same\",\n                kernel_initializer=self.kernel_initializer,\n            )\n        )\n        self.layers.append(self._depth_to_space_block_size_2)\n    else:\n        raise ValueError(\"Undefined upsampling provided\")\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_composites.UpSampleBlock.call","title":"call","text":"<pre><code>call(inputs: tf.Tensor) -&gt; tf.Tensor\n</code></pre> <p>Calls the <code>UpSampleBlock</code> layer.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>tf.Tensor</code> <p>Tensor of shape (b,h,w,c)</p> required <p>Returns:</p> Type Description <code>tf.Tensor</code> <p>Tensor of shape (b,h2,w2,c)</p> Source code in <code>DeepSaki/layers/layer_composites.py</code> <pre><code>def call(self, inputs: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"Calls the `UpSampleBlock` layer.\n\n    Args:\n        inputs (tf.Tensor): Tensor of shape (b,h,w,c)\n\n    Returns:\n        Tensor of shape (b,h*2,w*2,c)\n    \"\"\"\n    x = inputs\n    for layer in self.layers:\n        x = layer(x)\n    return x\n</code></pre>"},{"location":"reference/DeepSaki/layers/#DeepSaki.layers.layer_composites.UpSampleBlock.get_config","title":"get_config","text":"<pre><code>get_config() -&gt; Dict[str, Any]\n</code></pre> <p>Serialization of the object.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with the class' variable names as keys.</p> Source code in <code>DeepSaki/layers/layer_composites.py</code> <pre><code>def get_config(self) -&gt; Dict[str, Any]:\n    \"\"\"Serialization of the object.\n\n    Returns:\n        Dictionary with the class' variable names as keys.\n    \"\"\"\n    config = super(UpSampleBlock, self).get_config()\n    config.update(\n        {\n            \"kernels\": self.kernels,\n            \"activation\": self.activation,\n            \"use_spec_norm\": self.use_spec_norm,\n            \"upsampling\": self.upsampling,\n            \"use_bias\": self.use_bias,\n            \"padding\": self.padding,\n            \"kernel_initializer\": self.kernel_initializer,\n            \"gamma_initializer\": self.gamma_initializer,\n        }\n    )\n    return config\n</code></pre>"},{"location":"reference/DeepSaki/losses/","title":"losses","text":"<p>Loss functions designed for image like data of the shape (<code>batch</code>, <code>height</code>, <code>width</code>, <code>channels</code>).</p>"},{"location":"reference/DeepSaki/losses/#DeepSaki.losses.image_based_losses.ImageBasedLoss","title":"ImageBasedLoss","text":"<pre><code>ImageBasedLoss(\n    global_batch_size: int,\n    calculation_type: str = \"per_image\",\n    normalize_depth_channel: bool = False,\n    loss_reduction: tf.keras.losses.Reduction = tf.keras.losses.Reduction.AUTO,\n)\n</code></pre> <p>             Bases: <code>tf.keras.losses.Loss</code>, <code>ABC</code></p> <p>Abstract base class for image based losses.</p> <p>Sub-classes must override <code>_error_func(self, tensor1: tf.Tensor, tensor2: tf.Tensor) -&gt; tf.Tensor</code>, the actuall loss function that callculates the loss between two tensors.</p> <p>Initializes the abstract base class <code>ImageBasedLoss</code>.</p> <p>Parameters:</p> Name Type Description Default <code>global_batch_size</code> <code>int</code> <p>Batch size considering all workers running in parallel in a data parallel setup</p> required <code>calculation_type</code> <code>str</code> <p>Determines how the loss is calculated: [\"per_image\" | \"per_channel\"]. Defaults to \"per_image\".</p> <code>'per_image'</code> <code>normalize_depth_channel</code> <code>bool</code> <p>For RGBD images, the weight of depth is increased by multiplying the depth by the number of color channels. Defaults to False.</p> <code>False</code> <code>loss_reduction</code> <code>tf.keras.losses.Reduction</code> <p>Determines how the loss is reduced. Defaults to tf.keras.losses.Reduction.AUTO.</p> <code>tf.keras.losses.Reduction.AUTO</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>calculation_type</code> is not a valid option.</p> Source code in <code>DeepSaki/losses/image_based_losses.py</code> <pre><code>def __init__(\n    self,\n    global_batch_size: int,\n    calculation_type: str = \"per_image\",\n    normalize_depth_channel: bool = False,\n    loss_reduction: tf.keras.losses.Reduction = tf.keras.losses.Reduction.AUTO,\n) -&gt; None:\n    \"\"\"Initializes the abstract base class `ImageBasedLoss`.\n\n    Args:\n        global_batch_size (int): Batch size considering all workers running in parallel in a data parallel setup\n        calculation_type (str, optional): Determines how the loss is calculated: [\"per_image\" | \"per_channel\"].\n            Defaults to \"per_image\".\n        normalize_depth_channel (bool, optional): For RGBD images, the weight of depth is increased by multiplying\n            the depth by the number of color channels. Defaults to False.\n        loss_reduction (tf.keras.losses.Reduction, optional): Determines how the loss is reduced. Defaults to\n            tf.keras.losses.Reduction.AUTO.\n\n    Raises:\n        ValueError: if `calculation_type` is not a valid option.\n    \"\"\"\n    super(ImageBasedLoss, self).__init__(reduction=loss_reduction)\n\n    match calculation_type:\n        case \"per_channel\":\n            self.loss_calc_func = self._calc_loss_per_channel\n        case \"per_image\":\n            self.loss_calc_func = self._calc_loss_per_image\n        case _:\n            raise ValueError(f\"Pixel distance type '{calculation_type}' is not defined.\")\n\n    self.global_batch_size = global_batch_size\n    self.normalize_depth_channel = normalize_depth_channel\n</code></pre>"},{"location":"reference/DeepSaki/losses/#DeepSaki.losses.image_based_losses.ImageBasedLoss.call","title":"call","text":"<pre><code>call(img1: tf.Tensor, img2: tf.Tensor) -&gt; tf.Tensor\n</code></pre> <p>Calculates the image loss between <code>img1</code> and <code>img2</code> using the overriden <code>error_func</code> from the sub-class.</p> <p>Parameters:</p> Name Type Description Default <code>img1</code> <code>tf.Tensor</code> <p>Image of shape (<code>batch_size</code>, <code>height</code>, <code>width</code>,<code>channel</code>).</p> required <code>img2</code> <code>tf.Tensor</code> <p>Image of shape (<code>batch_size</code>, <code>height</code>, <code>width</code>,<code>channel</code>).</p> required <p>Returns:</p> Type Description <code>tf.Tensor</code> <p>Tensor containing the loss.</p> Source code in <code>DeepSaki/losses/image_based_losses.py</code> <pre><code>def call(self, img1: tf.Tensor, img2: tf.Tensor) -&gt; tf.Tensor:\n    \"\"\"Calculates the image loss between `img1` and `img2` using the overriden `error_func` from the sub-class.\n\n    Args:\n        img1 (tf.Tensor): Image of shape (`batch_size`, `height`, `width`,`channel`).\n        img2 (tf.Tensor): Image of shape (`batch_size`, `height`, `width`,`channel`).\n\n    Returns:\n        Tensor containing the loss.\n    \"\"\"\n    img1 = tf.cast(img1, tf.dtypes.float32)\n    img2 = tf.cast(img2, tf.dtypes.float32)\n\n    return self.loss_calc_func(img1, img2, self._error_func)\n</code></pre>"},{"location":"reference/DeepSaki/losses/#DeepSaki.losses.image_based_losses.PixelDistanceLoss","title":"PixelDistanceLoss","text":"<pre><code>PixelDistanceLoss(\n    global_batch_size: int,\n    calculation_type: str = \"per_image\",\n    normalize_depth_channel: bool = False,\n    loss_type: str = \"mae\",\n    loss_reduction: tf.keras.losses.Reduction = tf.keras.losses.Reduction.AUTO,\n)\n</code></pre> <p>             Bases: <code>ImageBasedLoss</code></p> <p>Calculates a pixel distance loss (per pixel loss) of two images of the shape (batch, height, width, channels).</p> <p>The distance is either a mean squared error (MSE) or a mean absolute error (MAE).</p> <p>Initializes the <code>PixelDistanceLoss</code>.</p> <p>Parameters:</p> Name Type Description Default <code>global_batch_size</code> <code>int</code> <p>Batch size considering all workers running in parallel in a data parallel setup</p> required <code>calculation_type</code> <code>str</code> <p>Determines how the loss is calculated: [\"per_image\" | \"per_channel\"]. Defaults to \"per_image\".</p> <code>'per_image'</code> <code>normalize_depth_channel</code> <code>bool</code> <p>For RGBD images, the weight of depth is increased by multiplying the depth by the number of color channels. Defaults to False.</p> <code>False</code> <code>loss_type</code> <code>str</code> <p>Loss to apply: [\"mae\" | \"mse\"]. Defaults to \"mae\".</p> <code>'mae'</code> <code>loss_reduction</code> <code>tf.keras.losses.Reduction</code> <p>Determines how the loss is reduced. Defaults to tf.keras.losses.Reduction.AUTO.</p> <code>tf.keras.losses.Reduction.AUTO</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>loss_type</code> is not a valid option.</p> Source code in <code>DeepSaki/losses/image_based_losses.py</code> <pre><code>def __init__(\n    self,\n    global_batch_size: int,\n    calculation_type: str = \"per_image\",\n    normalize_depth_channel: bool = False,\n    loss_type: str = \"mae\",\n    loss_reduction: tf.keras.losses.Reduction = tf.keras.losses.Reduction.AUTO,\n) -&gt; None:\n    \"\"\"Initializes the `PixelDistanceLoss`.\n\n    Args:\n        global_batch_size (int): Batch size considering all workers running in parallel in a data parallel setup\n        calculation_type (str, optional): Determines how the loss is calculated: [\"per_image\" | \"per_channel\"].\n            Defaults to \"per_image\".\n        normalize_depth_channel (bool, optional): For RGBD images, the weight of depth is increased by multiplying\n            the depth by the number of color channels. Defaults to False.\n        loss_type (str, optional): Loss to apply: [\"mae\" | \"mse\"]. Defaults to \"mae\".\n        loss_reduction (tf.keras.losses.Reduction, optional): Determines how the loss is reduced. Defaults to\n            tf.keras.losses.Reduction.AUTO.\n\n    Raises:\n        ValueError: if `loss_type` is not a valid option.\n    \"\"\"\n    match loss_type:\n        case \"mae\":\n            self.error_func_type = tf.abs\n        case \"mse\":\n            self.error_func_type = tf.square\n        case _:\n            raise ValueError(f\"Parameter loss_type={loss_type} is not defined. Use 'mae' or 'mse' instead.\")\n\n    super(PixelDistanceLoss, self).__init__(\n        global_batch_size=global_batch_size,\n        calculation_type=calculation_type,\n        normalize_depth_channel=normalize_depth_channel,\n        loss_reduction=loss_reduction,\n    )\n</code></pre>"},{"location":"reference/DeepSaki/losses/#DeepSaki.losses.image_based_losses.StructuralSimilarityLoss","title":"StructuralSimilarityLoss","text":"<pre><code>StructuralSimilarityLoss(\n    global_batch_size: int,\n    calculation_type: str = \"per_image\",\n    normalize_depth_channel: bool = False,\n    alpha: float = 1.0,\n    beta: float = 1.0,\n    gamma: float = 1.0,\n    c1: float = 0.0001,\n    c2: float = 0.0009,\n    loss_reduction: tf.keras.losses.Reduction = tf.keras.losses.Reduction.AUTO,\n)\n</code></pre> <p>             Bases: <code>ImageBasedLoss</code></p> <p>Calculates the structural similarity (SSIM) loss of two images of the shape (batch, height, width, channels).</p> <p>The structural similarity loss between two images \\(x\\) and \\(y\\) is defined as: \\(\\mathcal{L}_{SSIM}=1-SSIM(x,y)\\).</p> <p>SSIM compares contrast, luminance, and structure of two images using statistical parameters i.e., the mean \\(\\mu\\), the variance \\(\\sigma\\), and the covariance \\(\\sigma_{x,y}\\) of both images. The SSIM of two images \\(x\\) and \\(y\\) is defined as:</p> \\[ SSIM(x,y)= \\underbrace{\\left[ \\frac{2\\mu_x\\mu_y+C_1}{\\mu_x^2+\\mu_y^2 +C_1}\\right]^{\\alpha}}_\\text{contrast} \\cdot \\underbrace{\\left[ \\frac{2\\sigma_x\\sigma_y+C_2}{\\sigma_x^2+\\sigma_y^2 +C_2}\\right]^{\\beta}}_\\text{luminance} \\cdot \\underbrace{\\left[ \\frac{\\sigma_{x,y}+C_3}{\\sigma_x\\sigma_y+C_3}\\right]^{\\gamma}}_\\text{structure}, \\] <p>where \\(\\alpha\\), \\(\\beta\\) and \\(\\gamma\\) are hyperparameters to give relative importance to individual terms and \\(C_1\\), \\(C_2\\) and \\(C_3\\) are constants that must be chosen.</p> <p>Dunder method to initialize <code>StructuralSimilarityLoss</code>.</p> <p>Parameters:</p> Name Type Description Default <code>global_batch_size</code> <code>int</code> <p>Batch size considering all workers running in parallel in a data parallel setup.</p> required <code>calculation_type</code> <code>str</code> <p>Determines how the loss is calculated: [\"per_image\" | \"per_channel\"]. Defaults to \"per_image\".</p> <code>'per_image'</code> <code>normalize_depth_channel</code> <code>bool</code> <p>For RGBD images, the weight of depth is increased by multiplying the depth by the number of color channels. Defaults to False.</p> <code>False</code> <code>alpha</code> <code>float</code> <p>Weighting factor for contrast. Defaults to 1.0.</p> <code>1.0</code> <code>beta</code> <code>float</code> <p>Weighting factor for luminance. Defaults to 1.0.</p> <code>1.0</code> <code>gamma</code> <code>float</code> <p>Weighting factor for structure. Defaults to 1.0.</p> <code>1.0</code> <code>c1</code> <code>float</code> <p>Constant considered in contrast calculation. Defaults to 0.0001.</p> <code>0.0001</code> <code>c2</code> <code>float</code> <p>Constant considered in luminance calculation. Defaults to 0.0009.</p> <code>0.0009</code> <code>loss_reduction</code> <code>tf.keras.losses.Reduction</code> <p>Determines how the loss is reduced. Defaults to tf.keras.losses.Reduction.AUTO.</p> <code>tf.keras.losses.Reduction.AUTO</code> Source code in <code>DeepSaki/losses/image_based_losses.py</code> <pre><code>def __init__(\n    self,\n    global_batch_size: int,\n    calculation_type: str = \"per_image\",\n    normalize_depth_channel: bool = False,\n    alpha: float = 1.0,\n    beta: float = 1.0,\n    gamma: float = 1.0,\n    c1: float = 0.0001,\n    c2: float = 0.0009,\n    loss_reduction: tf.keras.losses.Reduction = tf.keras.losses.Reduction.AUTO,\n) -&gt; None:\n    \"\"\"Dunder method to initialize `StructuralSimilarityLoss`.\n\n    Args:\n        global_batch_size (int): Batch size considering all workers running in parallel in a data parallel setup.\n        calculation_type (str, optional): Determines how the loss is calculated: [\"per_image\" | \"per_channel\"].\n            Defaults to \"per_image\".\n        normalize_depth_channel (bool, optional): For RGBD images, the weight of depth is increased by multiplying\n            the depth by the number of color channels. Defaults to False.\n        alpha (float, optional): Weighting factor for contrast. Defaults to 1.0.\n        beta (float, optional): Weighting factor for luminance. Defaults to 1.0.\n        gamma (float, optional): Weighting factor for structure. Defaults to 1.0.\n        c1 (float, optional): Constant considered in contrast calculation. Defaults to 0.0001.\n        c2 (float, optional): Constant considered in luminance calculation. Defaults to 0.0009.\n        loss_reduction (tf.keras.losses.Reduction, optional): Determines how the loss is reduced. Defaults to\n            tf.keras.losses.Reduction.AUTO.\n    \"\"\"\n    super(StructuralSimilarityLoss, self).__init__(\n        global_batch_size=global_batch_size,\n        calculation_type=calculation_type,\n        normalize_depth_channel=normalize_depth_channel,\n        loss_reduction=loss_reduction,\n    )\n\n    self.alpha = alpha\n    self.beta = beta\n    self.gamma = gamma\n    self.c1 = c1\n    self.c2 = c2\n    self.c3 = c2 / 2\n</code></pre>"},{"location":"reference/DeepSaki/models/","title":"models","text":""},{"location":"reference/DeepSaki/models/#DeepSaki.models.autoencoders.ResNet","title":"ResNet","text":"<pre><code>ResNet(\n    number_of_levels: int = 3,\n    filters: int = 64,\n    split_kernels: bool = False,\n    kernels: int = 3,\n    first_kernel: int = 5,\n    number_of_blocks: int = 2,\n    activation: str = \"leaky_relu\",\n    final_activation: str = \"hard_sigmoid\",\n    use_ResidualBlock: bool = True,\n    residual_cardinality: int = 32,\n    limit_filters: int = 512,\n    n_bottleneck_blocks: int = 5,\n    upsampling: str = \"transpose_conv\",\n    downsampling: str = \"average_pooling\",\n    dropout_rate: float = 0.2,\n    use_spec_norm: bool = False,\n    use_bias: bool = True,\n    use_self_attention: bool = False,\n    fully_connected: str = \"MLP\",\n    padding: PaddingType = PaddingType.ZERO,\n    kernel_initializer: Optional[\n        tf.keras.initializers.Initializer\n    ] = None,\n    gamma_initializer: tf.keras.initializers.Initializer = HeAlphaUniform(),\n)\n</code></pre> <p>             Bases: <code>tf.keras.Model</code></p> <p>ResNet model in autoencoder architecture (encoder, bottleneck, decoder). Input_shape = Output_shape.</p> Architecture <pre><code>flowchart LR\ni([Input])--&gt;e1\nsubgraph Encoder\ne1--&gt;e2--&gt;e3--&gt;ex\nend\nsubgraph Bottleneck\nex--&gt;b1--&gt;bx\nend\nsubgraph Decoder\nbx--&gt;dx--&gt;d3--&gt;d2--&gt;d1\nend\nd1--&gt;o([Output])</code></pre> <p>Example: <pre><code>import DeepSaki as dsk\nimport tensorflow as tf\ninputs = tf.keras.layers.Input(shape = (256,256,4))\nmodel = tf.keras.Model(inputs=inputs, outputs=dsk.model.ResNet((256,256,4), 5,residual_cardinality=1).call(inputs))\nmodel.summary()\ntf.keras.utils.plot_model(model, show_shapes=True, expand_nested=True, show_dtype=True, to_file='ResNet_model.png')\n</code></pre></p> <p>Initialize the <code>ResNet</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>number_of_levels</code> <code>int</code> <p>Number of down and apsampling levels of the model. Defaults to 3.</p> <code>3</code> <code>filters</code> <code>int</code> <p>Number of filters for the initial encoder block. Defaults to 64.</p> <code>64</code> <code>split_kernels</code> <code>bool</code> <p>To decrease the number of parameters, a convolution with the kernel_size <code>(kernel,kernel)</code> can be splitted into two consecutive convolutions with the kernel_size <code>(kernel,1)</code> and <code>(1,kernel)</code> respectivly. Defaults to False.</p> <code>False</code> <code>kernels</code> <code>int</code> <p>Size of the convolutions kernels. Defaults to 3.</p> <code>3</code> <code>first_kernel</code> <code>int</code> <p>The first convolution can have a different kernel size, to e.g. increase the perceptive field, while the channel depth is still low. Defaults to 5.</p> <code>5</code> <code>number_of_blocks</code> <code>int</code> <p>Number of consecutive convolutional building blocks, i.e. <code>Conv2DBlock</code>. Defaults to 2.</p> <code>2</code> <code>activation</code> <code>str</code> <p>String literal or tensorflow activation function object to obtain activation function. Defaults to \"leaky_relu\".</p> <code>'leaky_relu'</code> <code>final_activation</code> <code>str</code> <p>String literal or tensorflow activation function object to obtain activation function for the model's output activation. Defaults to \"hard_sigmoid\".</p> <code>'hard_sigmoid'</code> <code>use_ResidualBlock</code> <code>bool</code> <p>Whether or not to use the ResidualBlock instead of the <code>Conv2DBlock</code>. Defaults to False.</p> <code>True</code> <code>residual_cardinality</code> <code>int</code> <p>Cardinality for the ResidualBlock. Defaults to 1.</p> <code>32</code> <code>limit_filters</code> <code>int</code> <p>Limits the number of filters, which is doubled with every downsampling block. Defaults to 512.</p> <code>512</code> <code>n_bottleneck_blocks</code> <code>int</code> <p>Number of consecutive convolution blocks in the bottleneck. Defaults to 1.</p> <code>5</code> <code>upsampling</code> <code>str</code> <p>Describes the upsampling method used. Defaults to \"transpose_conv\".</p> <code>'transpose_conv'</code> <code>downsampling</code> <code>str</code> <p>Describes the downsampling method. Defaults to \"conv_stride_2\".</p> <code>'average_pooling'</code> <code>dropout_rate</code> <code>float</code> <p>Probability of the dropout layer. If the preceeding layer has more than one channel, spatial dropout is applied, otherwise standard dropout. Defaults to 0.2.</p> <code>0.2</code> <code>use_spec_norm</code> <code>bool</code> <p>Applies spectral normalization to convolutional and dense layers. Defaults to False.</p> <code>False</code> <code>use_bias</code> <code>bool</code> <p>Whether convolutions and dense layers include a bias or not. Defaults to True.</p> <code>True</code> <code>use_self_attention</code> <code>bool</code> <p>Determines whether to apply self-attention in the decoder. Defaults to False.</p> <code>False</code> <code>fully_connected</code> <code>str</code> <p>Determines whether 1x1 convolutions are replaced by linear layers, which gives the same result, but linear layers are faster. Option: \"MLP\" or \"1x1_conv\". Defaults to \"MLP\".</p> <code>'MLP'</code> <code>padding</code> <code>PaddingType</code> <p>Padding type. Defaults to PaddingType.ZERO.</p> <code>PaddingType.ZERO</code> <code>kernel_initializer</code> <code>tf.keras.initializers.Initializer</code> <p>Initialization of the convolutions kernels. Defaults to None.</p> <code>None</code> <code>gamma_initializer</code> <code>tf.keras.initializers.Initializer</code> <p>Initialization of the normalization layers. Defaults to None.</p> <code>HeAlphaUniform()</code> Source code in <code>DeepSaki/models/autoencoders.py</code> <pre><code>def __init__(self,\n            number_of_levels:int = 3,\n            filters:int=64,\n            split_kernels:bool = False,\n            kernels:int = 3,\n            first_kernel:int = 5,\n            number_of_blocks:int = 2,\n            activation:str = \"leaky_relu\",\n            final_activation:str = \"hard_sigmoid\",\n            use_ResidualBlock:bool = True,\n            residual_cardinality:int = 32,\n            limit_filters:int = 512,\n            n_bottleneck_blocks:int = 5,\n            upsampling:str = \"transpose_conv\",\n            downsampling:str = \"average_pooling\",\n            dropout_rate:float = 0.2,\n            use_spec_norm:bool=False,\n            use_bias:bool = True,\n            use_self_attention:bool= False,\n            fully_connected:str = \"MLP\",\n            padding:PaddingType=PaddingType.ZERO,\n            kernel_initializer:Optional[tf.keras.initializers.Initializer] = None,\n            gamma_initializer:tf.keras.initializers.Initializer =  HeAlphaUniform()\n            ):\n    \"\"\"Initialize the `ResNet` object.\n\n    Args:\n        number_of_levels (int, optional): Number of down and apsampling levels of the model. Defaults to 3.\n        filters (int, optional): Number of filters for the initial encoder block. Defaults to 64.\n        split_kernels (bool, optional): To decrease the number of parameters, a convolution with the kernel_size\n            `(kernel,kernel)` can be splitted into two consecutive convolutions with the kernel_size `(kernel,1)` and\n            `(1,kernel)` respectivly. Defaults to False.\n        kernels (int, optional): Size of the convolutions kernels. Defaults to 3.\n        first_kernel (int, optional): The first convolution can have a different kernel size, to e.g. increase the\n            perceptive field, while the channel depth is still low. Defaults to 5.\n        number_of_blocks (int, optional): Number of consecutive convolutional building blocks, i.e. `Conv2DBlock`.\n            Defaults to 2.\n        activation (str, optional): String literal or tensorflow activation function object to obtain activation\n            function. Defaults to \"leaky_relu\".\n        final_activation (str, optional): String literal or tensorflow activation function object to obtain activation\n            function for the model's output activation. Defaults to \"hard_sigmoid\".\n        use_ResidualBlock (bool, optional): Whether or not to use the ResidualBlock instead of the\n            `Conv2DBlock`. Defaults to False.\n        residual_cardinality (int, optional): Cardinality for the ResidualBlock. Defaults to 1.\n        limit_filters (int, optional): Limits the number of filters, which is doubled with every downsampling block.\n            Defaults to 512.\n        n_bottleneck_blocks (int, optional): Number of consecutive convolution blocks in the bottleneck. Defaults to 1.\n        upsampling (str, optional): Describes the upsampling method used. Defaults to \"transpose_conv\".\n        downsampling (str, optional): Describes the downsampling method. Defaults to \"conv_stride_2\".\n        dropout_rate (float, optional): Probability of the dropout layer. If the preceeding layer has more than one\n            channel, spatial dropout is applied, otherwise standard dropout. Defaults to 0.2.\n        use_spec_norm (bool, optional): Applies spectral normalization to convolutional and dense layers. Defaults to\n            False.\n        use_bias (bool, optional): Whether convolutions and dense layers include a bias or not. Defaults to True.\n        use_self_attention (bool, optional): Determines whether to apply self-attention in the decoder. Defaults to\n            False.\n        fully_connected (str, optional): Determines whether 1x1 convolutions are replaced by linear layers, which gives\n            the same result, but linear layers are faster. Option: \"MLP\" or \"1x1_conv\". Defaults to \"MLP\".\n        padding (PaddingType, optional): Padding type. Defaults to PaddingType.ZERO.\n        kernel_initializer (tf.keras.initializers.Initializer, optional): Initialization of the convolutions kernels.\n            Defaults to None.\n        gamma_initializer (tf.keras.initializers.Initializer, optional): Initialization of the normalization layers.\n            Defaults to None.\n    \"\"\"\n    super(ResNet, self).__init__()\n    if fully_connected not in (\"MLP\", \"1x1_conv\"):\n        raise ValueError(f\"{fully_connected= } is not a supported option.\")\n\n    self.number_of_levels=number_of_levels\n    self.filters=filters\n    self.split_kernels=split_kernels\n    self.kernels=kernels\n    self.first_kernel=first_kernel\n    self.number_of_blocks=number_of_blocks\n    self.activation=activation\n    self.final_activation=final_activation\n    self.use_ResidualBlock=use_ResidualBlock\n    self.residual_cardinality=residual_cardinality\n    self.limit_filters=limit_filters\n    self.n_bottleneck_blocks=n_bottleneck_blocks\n    self.upsampling=upsampling\n    self.downsampling=downsampling\n    self.dropout_rate=dropout_rate\n    self.use_spec_norm=use_spec_norm\n    self.use_bias=use_bias\n    self.use_self_attention=use_self_attention\n    self.fully_connected=fully_connected\n    self.padding=padding\n    self.kernel_initializer=kernel_initializer\n    self.gamma_initializer=gamma_initializer\n\n    self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n\n    self.encoder = Encoder(number_of_levels=number_of_levels, filters=filters, limit_filters=limit_filters, downsampling=downsampling, kernels=kernels, split_kernels=split_kernels, number_of_blocks=number_of_blocks,activation=activation, first_kernel=first_kernel,use_ResidualBlock=use_ResidualBlock,use_spec_norm=use_spec_norm, use_bias = use_bias, residual_cardinality=residual_cardinality,padding = padding, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n    self.bottleNeck = Bottleneck(use_ResidualBlock=use_ResidualBlock, n_bottleneck_blocks=n_bottleneck_blocks, kernels=kernels, split_kernels=split_kernels,number_of_blocks=number_of_blocks , activation = activation,dropout_rate=dropout_rate,use_spec_norm=use_spec_norm, use_bias = use_bias, residual_cardinality=residual_cardinality,padding = padding, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n    self.decoder = Decoder(number_of_levels=number_of_levels, upsampling=upsampling, filters=filters, limit_filters=limit_filters, kernels=kernels, split_kernels=split_kernels,number_of_blocks=number_of_blocks,activation=activation,dropout_rate=dropout_rate, use_ResidualBlock=use_ResidualBlock,use_spec_norm=use_spec_norm,use_self_attention=use_self_attention, use_bias = use_bias, residual_cardinality=residual_cardinality,padding = padding, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n    #To enable mixed precission support for matplotlib and distributed training and to increase training stability\n    self.linear_dtype = tf.keras.layers.Activation(\"linear\", dtype = tf.float32)\n</code></pre>"},{"location":"reference/DeepSaki/models/#DeepSaki.models.autoencoders.ResNet.call","title":"call","text":"<pre><code>call(inputs: tf.Tensor) -&gt; tf.Tensor\n</code></pre> <p>Calls the <code>ResNet</code> model.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>tf.Tensor</code> <p>Tensor of shape (<code>batch</code>,<code>height</code>,<code>width</code>,<code>channel</code>).</p> required <p>Returns:</p> Type Description <code>tf.Tensor</code> <p>tf.Tensor: Tensor of shape (<code>batch</code>,<code>height</code>,<code>width</code>,<code>channel</code>)</p> Source code in <code>DeepSaki/models/autoencoders.py</code> <pre><code>def call(self, inputs:tf.Tensor)-&gt;tf.Tensor:\n    \"\"\"Calls the `ResNet` model.\n\n    Args:\n        inputs (tf.Tensor): Tensor of shape (`batch`,`height`,`width`,`channel`).\n\n    Returns:\n        tf.Tensor: Tensor of shape (`batch`,`height`,`width`,`channel`)\n    \"\"\"\n    x = inputs\n    x = self.encoder(x)\n    x = self.bottleNeck(x)\n    x = self.decoder(x)\n    x = self.img_reconstruction(x)\n    return self.linear_dtype(x)\n</code></pre>"},{"location":"reference/DeepSaki/models/#DeepSaki.models.autoencoders.UNet","title":"UNet","text":"<pre><code>UNet(\n    number_of_levels: int = 3,\n    upsampling: str = \"transpose_conv\",\n    downsampling: str = \"conv_stride_2\",\n    final_activation: str = \"hard_sigmoid\",\n    filters: int = 64,\n    kernels: int = 3,\n    first_kernel: int = 5,\n    split_kernels: bool = False,\n    number_of_blocks: int = 2,\n    activation: str = \"leaky_relu\",\n    limit_filters: int = 512,\n    use_ResidualBlock: bool = False,\n    residual_cardinality: int = 1,\n    n_bottleneck_blocks: int = 1,\n    dropout_rate: float = 0.2,\n    use_spec_norm: bool = False,\n    use_bias: bool = True,\n    use_self_attention: bool = False,\n    omit_skips: int = 0,\n    fully_connected: str = \"MLP\",\n    padding: PaddingType = PaddingType.ZERO,\n    kernel_initializer: Optional[\n        tf.keras.initializers.Initializer\n    ] = None,\n    gamma_initializer: Optional[\n        tf.keras.initializers.Initializer\n    ] = None,\n)\n</code></pre> <p>             Bases: <code>tf.keras.Model</code></p> <p>U-Net based autoencoder model with skip conections between encoder and decoder. Input_shape = Output_shape.</p> Architecture <pre><code>flowchart LR\ni([Input])--&gt;e1\nsubgraph Encoder\ne1--&gt;e2--&gt;e3--&gt;ex\nend\nsubgraph Bottleneck\nex--&gt;b1--&gt;bx\nend\nsubgraph Decoder\nbx--&gt;dx--&gt;d3--&gt;d2--&gt;d1\nend\nd1--&gt;o([Output])\ne1--&gt;d1\ne2--&gt;d2\ne3--&gt;d3\nex--&gt;dx</code></pre> <p>Example: <pre><code>import DeepSaki as dsk\nimport tensorflow as tf\ninputs = tf.keras.layers.Input(shape = (256,256,4))\nmodel = tf.keras.Model(inputs=inputs, outputs=dsk.model.UNet((256,256,4),5).call(inputs))\nmodel.summary()\ntf.keras.utils.plot_model(model, show_shapes=True, expand_nested=True, show_dtype=True, to_file='Unet_model.png')\n</code></pre></p> <p>Initialize the <code>UNet</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>number_of_levels</code> <code>int</code> <p>Number of down and upsampling levels of the model. Defaults to 3.</p> <code>3</code> <code>upsampling</code> <code>str</code> <p>Describes the upsampling method used. Defaults to \"transpose_conv\".</p> <code>'transpose_conv'</code> <code>downsampling</code> <code>str</code> <p>Describes the downsampling method. Defaults to \"conv_stride_2\".</p> <code>'conv_stride_2'</code> <code>final_activation</code> <code>str</code> <p>String literal or tensorflow activation function object to obtain activation function for the model's output activation. Defaults to \"hard_sigmoid\".</p> <code>'hard_sigmoid'</code> <code>filters</code> <code>int</code> <p>Number of filters for the initial encoder block. Defaults to 64.</p> <code>64</code> <code>kernels</code> <code>int</code> <p>Size of the convolutions kernels. Defaults to 3.</p> <code>3</code> <code>first_kernel</code> <code>int</code> <p>The first convolution can have a different kernel size, to e.g. increase the perceptive field, while the channel depth is still low. Defaults to 5.</p> <code>5</code> <code>split_kernels</code> <code>bool</code> <p>To decrease the number of parameters, a convolution with the kernel_size <code>(kernel,kernel)</code> can be splitted into two consecutive convolutions with the kernel_size <code>(kernel,1)</code> and <code>(1,kernel)</code> respectivly. Defaults to False.</p> <code>False</code> <code>number_of_blocks</code> <code>int</code> <p>Number of consecutive convolutional building blocks, i.e. <code>Conv2DBlock</code>. Defaults to 2.</p> <code>2</code> <code>activation</code> <code>str</code> <p>String literal or tensorflow activation function object to obtain activation function. Defaults to \"leaky_relu\".</p> <code>'leaky_relu'</code> <code>limit_filters</code> <code>int</code> <p>Limits the number of filters, which is doubled with every downsampling block. Defaults to 512.</p> <code>512</code> <code>use_ResidualBlock</code> <code>bool</code> <p>Whether or not to use the <code>ResidualBlock</code> instead of the <code>Conv2DBlock</code>. Defaults to False.</p> <code>False</code> <code>residual_cardinality</code> <code>int</code> <p>Cardinality for the <code>ResidualBlock</code>. Defaults to 1.</p> <code>1</code> <code>n_bottleneck_blocks</code> <code>int</code> <p>Number of consecutive convolution blocks in the bottleneck. Defaults to 1.</p> <code>1</code> <code>dropout_rate</code> <code>float</code> <p>Probability of the dropout layer. If the preceeding layer has more than one channel, spatial dropout is applied, otherwise standard dropout. Defaults to 0.2.</p> <code>0.2</code> <code>use_spec_norm</code> <code>bool</code> <p>Applies spectral normalization to convolutional and dense layers. Defaults to False.</p> <code>False</code> <code>use_bias</code> <code>bool</code> <p>Whether convolutions and dense layers include a bias or not. Defaults to True.</p> <code>True</code> <code>use_self_attention</code> <code>bool</code> <p>Determines whether to apply self-attention in the decoder. Defaults to False.</p> <code>False</code> <code>omit_skips</code> <code>int</code> <p>Defines how many layers should not output a skip connection output. Requires <code>output_skips</code> to be True. E.g. if <code>omit_skips = 2</code>, the first two levels do not output a skip connection, it starts at level 3. Defaults to 0.</p> <code>0</code> <code>fully_connected</code> <code>str</code> <p>Determines whether 1x1 convolutions are replaced by linear layers, which gives the same result, but linear layers are faster. Option: \"MLP\" or \"1x1_conv\". Defaults to \"MLP\".</p> <code>'MLP'</code> <code>padding</code> <code>PaddingType</code> <p>Padding type. Defaults to PaddingType.ZERO.</p> <code>PaddingType.ZERO</code> <code>kernel_initializer</code> <code>tf.keras.initializers.Initializer</code> <p>Initialization of the convolutions kernels. Defaults to None.</p> <code>None</code> <code>gamma_initializer</code> <code>tf.keras.initializers.Initializer</code> <p>Initialization of the normalization layers. Defaults to None.</p> <code>None</code> Source code in <code>DeepSaki/models/autoencoders.py</code> <pre><code>def __init__(self,\n            number_of_levels:int = 3,\n            upsampling:str = \"transpose_conv\",\n            downsampling:str = \"conv_stride_2\",\n            final_activation:str = \"hard_sigmoid\",\n            filters:int = 64,\n            kernels:int = 3,\n            first_kernel:int = 5,\n            split_kernels:bool = False,\n            number_of_blocks:int = 2,\n            activation:str = \"leaky_relu\",\n            limit_filters:int = 512,\n            use_ResidualBlock:bool = False,\n            residual_cardinality:int = 1,\n            n_bottleneck_blocks:int = 1,\n            dropout_rate:float = 0.2,\n            use_spec_norm:bool = False,\n            use_bias:bool = True,\n            use_self_attention:bool=False,\n            omit_skips:int = 0,\n            fully_connected:str = \"MLP\",\n            padding:PaddingType=PaddingType.ZERO,\n            kernel_initializer: Optional[tf.keras.initializers.Initializer] = None,\n            gamma_initializer: Optional[tf.keras.initializers.Initializer] =  None\n            )-&gt;None:\n    \"\"\"Initialize the `UNet` object.\n\n    Args:\n        number_of_levels (int, optional): Number of down and upsampling levels of the model. Defaults to 3.\n        upsampling (str, optional): Describes the upsampling method used. Defaults to \"transpose_conv\".\n        downsampling (str, optional): Describes the downsampling method. Defaults to \"conv_stride_2\".\n        final_activation (str, optional): String literal or tensorflow activation function object to obtain activation\n            function for the model's output activation. Defaults to \"hard_sigmoid\".\n        filters (int, optional): Number of filters for the initial encoder block. Defaults to 64.\n        kernels (int, optional): Size of the convolutions kernels. Defaults to 3.\n        first_kernel (int, optional): The first convolution can have a different kernel size, to e.g. increase the\n            perceptive field, while the channel depth is still low. Defaults to 5.\n        split_kernels (bool, optional): To decrease the number of parameters, a convolution with the kernel_size\n            `(kernel,kernel)` can be splitted into two consecutive convolutions with the kernel_size `(kernel,1)` and\n            `(1,kernel)` respectivly. Defaults to False.\n        number_of_blocks (int, optional): Number of consecutive convolutional building blocks, i.e. `Conv2DBlock`.\n            Defaults to 2.\n        activation (str, optional): String literal or tensorflow activation function object to obtain activation\n            function. Defaults to \"leaky_relu\".\n        limit_filters (int, optional): Limits the number of filters, which is doubled with every downsampling block.\n            Defaults to 512.\n        use_ResidualBlock (bool, optional): Whether or not to use the `ResidualBlock` instead of the\n            `Conv2DBlock`. Defaults to False.\n        residual_cardinality (int, optional): Cardinality for the `ResidualBlock`. Defaults to 1.\n        n_bottleneck_blocks (int, optional): Number of consecutive convolution blocks in the bottleneck. Defaults to 1.\n        dropout_rate (float, optional): Probability of the dropout layer. If the preceeding layer has more than one\n            channel, spatial dropout is applied, otherwise standard dropout. Defaults to 0.2.\n        use_spec_norm (bool, optional): Applies spectral normalization to convolutional and dense layers. Defaults to\n            False.\n        use_bias (bool, optional): Whether convolutions and dense layers include a bias or not. Defaults to True.\n        use_self_attention (bool, optional): Determines whether to apply self-attention in the decoder. Defaults to\n            False.\n        omit_skips (int, optional): Defines how many layers should not output a skip connection output. Requires\n            `output_skips` to be True. E.g. if `omit_skips = 2`, the first two levels do not output a skip connection,\n            it starts at level 3. Defaults to 0.\n        fully_connected (str, optional): Determines whether 1x1 convolutions are replaced by linear layers, which gives\n            the same result, but linear layers are faster. Option: \"MLP\" or \"1x1_conv\". Defaults to \"MLP\".\n        padding (PaddingType, optional): Padding type. Defaults to PaddingType.ZERO.\n        kernel_initializer (tf.keras.initializers.Initializer, optional): Initialization of the convolutions kernels.\n            Defaults to None.\n        gamma_initializer (tf.keras.initializers.Initializer, optional): Initialization of the normalization layers.\n            Defaults to None.\n    \"\"\"\n    super(UNet, self).__init__()\n\n    if fully_connected not in (\"MLP\", \"1x1_conv\"):\n        raise ValueError(f\"{fully_connected= } is not a supported option.\")\n\n    self.number_of_levels=number_of_levels\n    self.filters=filters\n    self.split_kernels=split_kernels\n    self.kernels=kernels\n    self.first_kernel=first_kernel\n    self.number_of_blocks=number_of_blocks\n    self.activation=activation\n    self.final_activation=final_activation\n    self.use_ResidualBlock=use_ResidualBlock\n    self.residual_cardinality=residual_cardinality\n    self.limit_filters=limit_filters\n    self.n_bottleneck_blocks=n_bottleneck_blocks\n    self.upsampling=upsampling\n    self.downsampling=downsampling\n    self.dropout_rate=dropout_rate\n    self.use_spec_norm=use_spec_norm\n    self.use_bias=use_bias\n    self.use_self_attention=use_self_attention\n    self.omit_skips=omit_skips\n    self.fully_connected=fully_connected\n    self.padding=padding\n    self.kernel_initializer=kernel_initializer\n    self.gamma_initializer=gamma_initializer\n\n    self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n\n    self.encoder = Encoder(number_of_levels=number_of_levels, filters=filters, limit_filters=limit_filters,  downsampling=downsampling, kernels=kernels, split_kernels=split_kernels, number_of_blocks=number_of_blocks,activation=activation, first_kernel=first_kernel,use_ResidualBlock=use_ResidualBlock,use_spec_norm=use_spec_norm, omit_skips=omit_skips, output_skips=True, use_bias = use_bias, residual_cardinality=residual_cardinality,padding = padding, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n    self.bottleNeck = Bottleneck(use_ResidualBlock=use_ResidualBlock, n_bottleneck_blocks=n_bottleneck_blocks, kernels=kernels, split_kernels=split_kernels,number_of_blocks=number_of_blocks,activation = activation, dropout_rate=dropout_rate, use_spec_norm=use_spec_norm, use_bias = use_bias, residual_cardinality=residual_cardinality,padding = padding, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n    self.decoder = Decoder(number_of_levels=number_of_levels, upsampling=upsampling, filters=filters, limit_filters=limit_filters,  kernels=kernels, split_kernels=split_kernels,number_of_blocks=number_of_blocks,activation=activation,dropout_rate=dropout_rate, use_ResidualBlock=use_ResidualBlock,use_spec_norm=use_spec_norm,use_self_attention=use_self_attention, use_bias = use_bias, residual_cardinality=residual_cardinality,padding = padding, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer,enable_skip_connections_input=True)\n#To enable mixed precission support for matplotlib and distributed training and to increase training stability\n    self.linear_dtype = tf.keras.layers.Activation(\"linear\", dtype = tf.float32)\n</code></pre>"},{"location":"reference/DeepSaki/models/#DeepSaki.models.autoencoders.UNet.call","title":"call","text":"<pre><code>call(inputs: tf.Tensor) -&gt; tf.Tensor\n</code></pre> <p>Calls the <code>UNet</code> model.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>tf.Tensor</code> <p>Tensor of shape (<code>batch</code>,<code>height</code>,<code>width</code>,<code>channel</code>).</p> required <p>Returns:</p> Type Description <code>tf.Tensor</code> <p>tf.Tensor: Tensor of shape (<code>batch</code>,<code>height</code>,<code>width</code>,<code>channel</code>)</p> Source code in <code>DeepSaki/models/autoencoders.py</code> <pre><code>def call(self, inputs:tf.Tensor)-&gt;tf.Tensor:\n    \"\"\"Calls the `UNet` model.\n\n    Args:\n        inputs (tf.Tensor): Tensor of shape (`batch`,`height`,`width`,`channel`).\n\n    Returns:\n        tf.Tensor: Tensor of shape (`batch`,`height`,`width`,`channel`)\n    \"\"\"\n    x = inputs\n    x, skip_connections = self.encoder(x)\n    x = self.bottleNeck(x)\n    x = self.decoder([x,skip_connections])\n    x = self.img_reconstruction(x)\n    return self.linear_dtype(x)\n</code></pre>"},{"location":"reference/DeepSaki/models/#DeepSaki.models.discriminators.LayoutContentDiscriminator","title":"LayoutContentDiscriminator","text":"<pre><code>LayoutContentDiscriminator(\n    filters: int = 64,\n    downsampling: str = \"conv_stride_2\",\n    kernels: int = 3,\n    first_kernel: int = 5,\n    split_kernels: bool = False,\n    number_of_blocks: int = 2,\n    activation: str = \"leaky_relu\",\n    dropout_rate: float = 0.2,\n    use_spec_norm: bool = False,\n    use_bias: bool = True,\n    padding: PaddingType = PaddingType.ZERO,\n    fully_connected: str = \"MLP\",\n    use_self_attention: bool = False,\n    kernel_initializer: Optional[\n        tf.keras.initializers.Initializer\n    ] = None,\n    gamma_initializer: Optional[\n        tf.keras.initializers.Initializer\n    ] = None,\n)\n</code></pre> <p>             Bases: <code>tf.keras.Model</code></p> <p>Discriminator/critic model with two outputs to enforce disentanglement of layout and content discrimination.</p> <p>Usually used in a GAN framework.</p> Info <p>Implementation as used in the VoloGAN paper.</p> Limitations <p>For now the input height and width of a tensor of shape (batch, height, width, channels) must be at least 256x256</p> Architecture <pre><code>flowchart LR\ni([Input])--&gt;e1\nsubgraph Encoder\ne1--&gt;e2--&gt;e3--&gt;sa[Self-Attention]\nend\nsubgraph \"Content Branch\"\nsa--&gt;c1--&gt;c2--&gt;c3--&gt;c4\nend\nsubgraph \"Layout Branch\"\nsa--&gt;l1--&gt;l2--&gt;l3--&gt;l4\nend\nl4--&gt;lo([layout])\nc4--&gt;co([content])</code></pre> <p>Example: <pre><code>import DeepSaki as dsk\nimport tensorflow as tf\ninputs = tf.keras.layers.Input(shape = (256,256,4))\nmodel = tf.keras.Model(inputs=inputs, outputs=dsk.models.LayoutContentDiscriminator().call(inputs))\nmodel.summary()\ntf.keras.utils.plot_model(model, show_shapes=True, expand_nested=True, show_dtype=True, to_file='Unet_discriminator_model.png')\n</code></pre></p> <p>Initialize the <code>LayoutContentDiscriminator</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>filters</code> <code>int</code> <p>Number of filters for the initial encoder block. Defaults to 64.</p> <code>64</code> <code>downsampling</code> <code>str</code> <p>Describes the downsampling method. Defaults to \"conv_stride_2\".</p> <code>'conv_stride_2'</code> <code>kernels</code> <code>int</code> <p>Size of the convolutions kernels. Defaults to 3.</p> <code>3</code> <code>first_kernel</code> <code>int</code> <p>The first convolution can have a different kernel size, to e.g. increase the perceptive field, while the channel depth is still low. Defaults to 5.</p> <code>5</code> <code>split_kernels</code> <code>bool</code> <p>To decrease the number of parameters, a convolution with the kernel_size <code>(kernel,kernel)</code> can be splitted into two consecutive convolutions with the kernel_size <code>(kernel,1)</code> and <code>(1,kernel)</code> respectivly. Defaults to False.</p> <code>False</code> <code>number_of_blocks</code> <code>int</code> <p>Number of consecutive convolutional building blocks, i.e. <code>Conv2DBlock</code>. Defaults to 2.</p> <code>2</code> <code>activation</code> <code>str</code> <p>String literal or tensorflow activation function object to obtain activation function. Defaults to \"leaky_relu\".</p> <code>'leaky_relu'</code> <code>dropout_rate</code> <code>float</code> <p>Probability of the dropout layer. If the preceeding layer has more than one channel, spatial dropout is applied, otherwise standard dropout. Defaults to 0.2.</p> <code>0.2</code> <code>use_spec_norm</code> <code>bool</code> <p>Applies spectral normalization to convolutional and dense layers. Defaults to False.</p> <code>False</code> <code>use_bias</code> <code>bool</code> <p>Whether convolutions and dense layers include a bias or not. Defaults to True.</p> <code>True</code> <code>padding</code> <code>PaddingType</code> <p>Padding type. Defaults to PaddingType.NONE.</p> <code>PaddingType.ZERO</code> <code>fully_connected</code> <code>str</code> <p>Determines whether 1x1 convolutions are replaced by linear layers, which gives the same result, but linear layers are faster. Option: \"MLP\" or \"1x1_conv\". Defaults to \"MLP\".</p> <code>'MLP'</code> <code>use_self_attention</code> <code>bool</code> <p>Determines whether to apply self-attention in the decoder. Defaults to False.</p> <code>False</code> <code>kernel_initializer</code> <code>tf.keras.initializers.Initializer</code> <p>Initialization of the convolutions kernels. Defaults to None.</p> <code>None</code> <code>gamma_initializer</code> <code>tf.keras.initializers.Initializer</code> <p>Initialization of the normalization layers. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If provided parameter for <code>fully_connected</code> is not supported.</p> Source code in <code>DeepSaki/models/discriminators.py</code> <pre><code>def __init__(self,\n            filters:int = 64,\n            downsampling:str = \"conv_stride_2\",\n            kernels:int = 3,\n            first_kernel:int = 5,\n            split_kernels:bool = False,\n            number_of_blocks:int = 2,\n            activation:str = \"leaky_relu\",\n            dropout_rate:float = 0.2,\n            use_spec_norm:bool=False,\n            use_bias:bool = True,\n            padding:PaddingType=PaddingType.ZERO,\n            fully_connected:str = \"MLP\",\n            use_self_attention:bool = False,\n            kernel_initializer:Optional[tf.keras.initializers.Initializer] = None,\n            gamma_initializer:Optional[tf.keras.initializers.Initializer] = None\n            ):\n    \"\"\"Initialize the `LayoutContentDiscriminator` object.\n\n    Args:\n        filters (int, optional): Number of filters for the initial encoder block. Defaults to 64.\n        downsampling (str, optional): Describes the downsampling method. Defaults to \"conv_stride_2\".\n        kernels (int, optional): Size of the convolutions kernels. Defaults to 3.\n        first_kernel (int, optional): The first convolution can have a different kernel size, to e.g. increase the\n            perceptive field, while the channel depth is still low. Defaults to 5.\n        split_kernels (bool, optional): To decrease the number of parameters, a convolution with the kernel_size\n            `(kernel,kernel)` can be splitted into two consecutive convolutions with the kernel_size `(kernel,1)` and\n            `(1,kernel)` respectivly. Defaults to False.\n        number_of_blocks (int, optional): Number of consecutive convolutional building blocks, i.e. `Conv2DBlock`.\n            Defaults to 2.\n        activation (str, optional): String literal or tensorflow activation function object to obtain activation\n            function. Defaults to \"leaky_relu\".\n        dropout_rate (float, optional): Probability of the dropout layer. If the preceeding layer has more than one\n            channel, spatial dropout is applied, otherwise standard dropout. Defaults to 0.2.\n        use_spec_norm (bool, optional): Applies spectral normalization to convolutional and dense layers. Defaults to\n            False.\n        use_bias (bool, optional): Whether convolutions and dense layers include a bias or not. Defaults to True.\n        padding (PaddingType, optional): Padding type. Defaults to PaddingType.NONE.\n        fully_connected (str, optional): Determines whether 1x1 convolutions are replaced by linear layers, which gives\n            the same result, but linear layers are faster. Option: \"MLP\" or \"1x1_conv\". Defaults to \"MLP\".\n        use_self_attention (bool, optional): Determines whether to apply self-attention in the decoder. Defaults to\n            False.\n        kernel_initializer (tf.keras.initializers.Initializer, optional): Initialization of the convolutions kernels.\n            Defaults to None.\n        gamma_initializer (tf.keras.initializers.Initializer, optional): Initialization of the normalization layers.\n            Defaults to None.\n\n    Raises:\n        ValueError: If provided parameter for `fully_connected` is not supported.\n    \"\"\"\n    super(LayoutContentDiscriminator, self).__init__()\n\n    self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n\n    self.encoder = Encoder(number_of_levels=3, filters=filters, limit_filters=1024, downsampling=downsampling, kernels=kernels, split_kernels=split_kernels, number_of_blocks=number_of_blocks,activation=activation, first_kernel=first_kernel,use_ResidualBlock=False,channel_list=[4*filters,4*filters,8*filters],use_spec_norm=use_spec_norm, padding = padding, use_bias = use_bias, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n    if use_self_attention:\n        self.SA = ScalarGatedSelfAttention(use_spec_norm=use_spec_norm, intermediate_channel=None, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n    else:\n        self.SA = None\n\n    if fully_connected == \"MLP\":\n        self.cont1 = DenseBlock(units = filters * 8, use_spec_norm = use_spec_norm, number_of_blocks = number_of_blocks, activation = activation, dropout_rate =dropout_rate, use_bias = use_bias, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n        self.cont2 = DenseBlock(units = filters * 8, use_spec_norm = use_spec_norm, number_of_blocks = number_of_blocks, activation = activation, dropout_rate =dropout_rate, use_bias = use_bias, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n        self.cont3 = DenseBlock(units = filters * 8, use_spec_norm = use_spec_norm, number_of_blocks = number_of_blocks, activation = activation, dropout_rate =0, final_activation=False, apply_final_normalization = False, use_bias = use_bias, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n    elif fully_connected == \"1x1_conv\":\n        self.cont1 = Conv2DBlock(filters=filters * 8, kernels = 1, activation = activation, split_kernels = split_kernels,number_of_blocks=number_of_blocks, dropout_rate=dropout_rate,use_spec_norm=use_spec_norm, padding=padding,use_bias = use_bias, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n        self.cont2 = Conv2DBlock(filters=filters * 8, kernels = 1, activation = activation, split_kernels = split_kernels,number_of_blocks=number_of_blocks, dropout_rate=dropout_rate,use_spec_norm=use_spec_norm, padding=padding,use_bias = use_bias, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n        self.cont3 = Conv2DBlock(filters=filters * 8, kernels = 1, activation = activation, split_kernels = split_kernels,number_of_blocks=number_of_blocks, dropout_rate=0,use_spec_norm=use_spec_norm, final_activation=False, apply_final_normalization = False, padding=padding,use_bias = use_bias, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n    else:\n        raise ValueError(f\"{fully_connected=} is not defined.\")\n\n    self.lay1 = Conv2DBlock(filters=1, kernels = kernels, activation = activation, split_kernels = split_kernels,number_of_blocks=number_of_blocks, dropout_rate=0,use_spec_norm=use_spec_norm, padding=padding, use_bias = use_bias, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n    self.lay2 = Conv2DBlock(filters=1, kernels = kernels, activation = activation, split_kernels = split_kernels,number_of_blocks=number_of_blocks, dropout_rate=dropout_rate,use_spec_norm=use_spec_norm, padding=padding,use_bias = use_bias, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n    self.lay3 = Conv2DBlock(filters=1, kernels = kernels, activation = activation, split_kernels = split_kernels,number_of_blocks=number_of_blocks, dropout_rate=dropout_rate,use_spec_norm=use_spec_norm, padding=padding,use_bias = use_bias, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n    self.lay4 = Conv2DBlock(filters=1, kernels = kernels, activation = activation, split_kernels = split_kernels,number_of_blocks=number_of_blocks, dropout_rate=0,use_spec_norm=use_spec_norm,final_activation=False, apply_final_normalization = False, padding=padding,use_bias = use_bias, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n    #To enable mixed precission support for matplotlib and distributed training and to increase training stability\n    self.linear_dtype = tf.keras.layers.Activation(\"linear\", dtype = tf.float32)\n</code></pre>"},{"location":"reference/DeepSaki/models/#DeepSaki.models.discriminators.LayoutContentDiscriminator.call","title":"call","text":"<pre><code>call(inputs: tf.Tensor) -&gt; Tuple[tf.Tensor, tf.Tensor]\n</code></pre> <p>Calls the <code>LayoutContentDiscriminator</code> model.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>tf.Tensor</code> <p>Tensor of shape <code>(batch, height, width, channel)</code>.</p> required <p>Returns:</p> Name Type Description <code>content_output</code> <code>tf.Tensor</code> <p>Tensor of shape <code>(batch, 1, 1, C)</code> focusing on the content of an image rather than the position. <code>C</code> is <code>filters</code>2*3, where 3 is the number of downsampling blocks in the Encoder().</p> <code>layout_output</code> <code>tf.Tensor</code> <p>Tensor of shape <code>(batch, H, W, 1)</code> focusing on the input's layout by reducing its number of channels to 1. <code>H</code>=<code>height</code>/(2^3) and <code>W</code>=<code>width</code>/(2^3)</p> Source code in <code>DeepSaki/models/discriminators.py</code> <pre><code>def call(self, inputs:tf.Tensor)-&gt;Tuple[tf.Tensor,tf.Tensor]:\n    \"\"\"Calls the `LayoutContentDiscriminator` model.\n\n    Args:\n        inputs (tf.Tensor): Tensor of shape `(batch, height, width, channel)`.\n\n    Returns:\n        content_output: Tensor of shape `(batch, 1, 1, C)` focusing on the content of an image rather than the position.\n            `C` is `filters`*2**3, where 3 is the number of downsampling blocks in the Encoder().\n        layout_output: Tensor of shape `(batch, H, W, 1)` focusing on the input's layout by reducing its number of\n            channels to 1. `H`=`height`/(2^3) and `W`=`width`/(2^3)\n    \"\"\"\n    x = inputs\n    encoder_out = self.encoder(x)\n    if self.SA is not None:\n        encoder_out = self.SA(encoder_out)\n\n    _, pool_height, pool_width, _ = encoder_out.shape\n    out1 = tf.keras.layers.AveragePooling2D(pool_size=(pool_height, pool_width))(encoder_out)\n    out1 = self.cont1(out1)\n    out1 = self.cont2(out1)\n    out1 = self.cont3(out1)\n    out1 = self.linear_dtype(out1)\n\n    out2 = self.lay1(encoder_out)\n    out2 = self.lay2(out2)\n    out2 = self.lay3(out2)\n    out2 = self.lay4(out2)\n    out2 = self.linear_dtype(out2)\n\n    return out1, out2\n</code></pre>"},{"location":"reference/DeepSaki/models/#DeepSaki.models.discriminators.PatchDiscriminator","title":"PatchDiscriminator","text":"<pre><code>PatchDiscriminator(\n    filters: int = 64,\n    downsampling: str = \"average_pooling\",\n    kernels: int = 3,\n    first_kernel: int = 5,\n    split_kernels: bool = False,\n    number_of_blocks: int = 2,\n    activation: str = \"leaky_relu\",\n    num_down_blocks: int = 3,\n    dropout_rate: float = 0.2,\n    use_spec_norm: bool = False,\n    use_bias: bool = True,\n    use_self_attention: bool = False,\n    padding: PaddingType = PaddingType.ZERO,\n    kernel_initializer: Optional[\n        tf.keras.initializers.Initializer\n    ] = None,\n    gamma_initializer: Optional[\n        tf.keras.initializers.Initializer\n    ] = None,\n)\n</code></pre> <p>             Bases: <code>tf.keras.Model</code></p> <p>Discriminator/critic model with patched output rather than single value.</p> <p>Usually used in a GAN framework.</p> Architecture <pre><code>flowchart LR\ni([Input])--&gt;e1\nsubgraph Encoder\ne1--&gt;e2--&gt;ex\nend\nex--&gt;conv1--&gt;conv2--&gt;o([output])\n</code></pre> <p>Example: <pre><code>import DeepSaki as dsk\nimport tensorflow as tf\ninputs = tf.keras.layers.Input(shape = (256,256,4))\nmodel = tf.keras.Model(inputs=inputs, outputs=dsk.models.PatchDiscriminator().call(inputs))\nmodel.summary()\ntf.keras.utils.plot_model(model, show_shapes=True, expand_nested=True, show_dtype=True, to_file='PatchDiscriminator_model.png')\n</code></pre></p> <p>Initialize the <code>PatchDiscriminator</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>filters</code> <code>int</code> <p>Number of filters for the initial encoder block. Defaults to 64.</p> <code>64</code> <code>downsampling</code> <code>str</code> <p>Describes the downsampling method. Defaults to \"average_pooling\".</p> <code>'average_pooling'</code> <code>kernels</code> <code>int</code> <p>Size of the convolutions kernels. Defaults to 3.</p> <code>3</code> <code>first_kernel</code> <code>int</code> <p>The first convolution can have a different kernel size, to e.g. increase the perceptive field, while the channel depth is still low. Defaults to 5.</p> <code>5</code> <code>split_kernels</code> <code>bool</code> <p>To decrease the number of parameters, a convolution with the kernel_size <code>(kernel,kernel)</code> can be splitted into two consecutive convolutions with the kernel_size <code>(kernel,1)</code> and <code>(1,kernel)</code> respectivly. Defaults to False.</p> <code>False</code> <code>number_of_blocks</code> <code>int</code> <p>Number of consecutive convolutional building blocks, i.e. <code>Conv2DBlock</code>. Defaults to 2.</p> <code>2</code> <code>activation</code> <code>str</code> <p>String literal or tensorflow activation function object to obtain activation function. Defaults to \"leaky_relu\".</p> <code>'leaky_relu'</code> <code>num_down_blocks</code> <code>int</code> <p>Number of levels in the encoder that performs a downsampling operation at its end. Defaults to 3.</p> <code>3</code> <code>dropout_rate</code> <code>float</code> <p>Probability of the dropout layer. If the preceeding layer has more than one channel, spatial dropout is applied, otherwise standard dropout. Defaults to 0.2.</p> <code>0.2</code> <code>use_spec_norm</code> <code>bool</code> <p>Applies spectral normalization to convolutional and dense layers. Defaults to False.</p> <code>False</code> <code>use_bias</code> <code>bool</code> <p>Whether convolutions and dense layers include a bias or not. Defaults to True.</p> <code>True</code> <code>use_self_attention</code> <code>bool</code> <p>Determines whether to apply self-attention in the decoder. Defaults to False.</p> <code>False</code> <code>padding</code> <code>PaddingType</code> <p>Padding type. Defaults to PaddingType.NONE.</p> <code>PaddingType.ZERO</code> <code>kernel_initializer</code> <code>tf.keras.initializers.Initializer</code> <p>Initialization of the convolutions kernels. Defaults to None.</p> <code>None</code> <code>gamma_initializer</code> <code>tf.keras.initializers.Initializer</code> <p>Initialization of the normalization layers. Defaults to None.</p> <code>None</code> Source code in <code>DeepSaki/models/discriminators.py</code> <pre><code>def __init__(self,\n            filters:int = 64,\n            downsampling:str = \"average_pooling\",\n            kernels:int = 3,\n            first_kernel:int = 5,\n            split_kernels:bool = False,\n            number_of_blocks:int = 2,\n            activation:str = \"leaky_relu\",\n            num_down_blocks:int = 3,\n            dropout_rate:float = 0.2,\n            use_spec_norm:bool= False,\n            use_bias:bool = True,\n            use_self_attention:bool=False,\n            padding:PaddingType=PaddingType.ZERO,\n            kernel_initializer:Optional[tf.keras.initializers.Initializer] = None,\n            gamma_initializer:Optional[tf.keras.initializers.Initializer] = None\n            ):\n    \"\"\"Initialize the `PatchDiscriminator` object.\n\n    Args:\n        filters (int, optional): Number of filters for the initial encoder block. Defaults to 64.\n        downsampling (str, optional): Describes the downsampling method. Defaults to \"average_pooling\".\n        kernels (int, optional): Size of the convolutions kernels. Defaults to 3.\n        first_kernel (int, optional): The first convolution can have a different kernel size, to e.g. increase the\n            perceptive field, while the channel depth is still low. Defaults to 5.\n        split_kernels (bool, optional): To decrease the number of parameters, a convolution with the kernel_size\n            `(kernel,kernel)` can be splitted into two consecutive convolutions with the kernel_size `(kernel,1)` and\n            `(1,kernel)` respectivly. Defaults to False.\n        number_of_blocks (int, optional): Number of consecutive convolutional building blocks, i.e. `Conv2DBlock`.\n            Defaults to 2.\n        activation (str, optional): String literal or tensorflow activation function object to obtain activation\n            function. Defaults to \"leaky_relu\".\n        num_down_blocks (int, optional): Number of levels in the encoder that performs a downsampling operation at its\n            end. Defaults to 3.\n        dropout_rate (float, optional): Probability of the dropout layer. If the preceeding layer has more than one\n            channel, spatial dropout is applied, otherwise standard dropout. Defaults to 0.2.\n        use_spec_norm (bool, optional): Applies spectral normalization to convolutional and dense layers. Defaults to\n            False.\n        use_bias (bool, optional): Whether convolutions and dense layers include a bias or not. Defaults to True.\n        use_self_attention (bool, optional): Determines whether to apply self-attention in the decoder. Defaults to\n            False.\n        padding (PaddingType, optional): Padding type. Defaults to PaddingType.NONE.\n        kernel_initializer (tf.keras.initializers.Initializer, optional): Initialization of the convolutions kernels.\n            Defaults to None.\n        gamma_initializer (tf.keras.initializers.Initializer, optional): Initialization of the normalization layers.\n            Defaults to None.\n    \"\"\"\n    super(PatchDiscriminator, self).__init__()\n\n    self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n\n    self.encoder = Encoder(number_of_levels=num_down_blocks, filters=filters, limit_filters=512,  downsampling=downsampling, kernels=kernels, split_kernels=split_kernels,number_of_blocks=number_of_blocks,activation=activation,first_kernel=first_kernel,use_spec_norm=use_spec_norm,use_self_attention=use_self_attention, use_bias = use_bias,padding = padding, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n    self.conv1 = Conv2DBlock(filters = filters * (2**(num_down_blocks)),  kernels = kernels, split_kernels = split_kernels, number_of_blocks = number_of_blocks, activation = activation,dropout_rate=dropout_rate,use_spec_norm=use_spec_norm, use_bias = use_bias,padding = padding, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n    self.conv2 = Conv2DBlock(filters = 1, kernels = 5, split_kernels  = False, number_of_blocks = 1, activation = None,use_spec_norm=use_spec_norm, apply_final_normalization = False, use_bias = use_bias,padding = padding, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n    #To enable mixed precission support for matplotlib and distributed training and to increase training stability\n    self.linear_dtype = tf.keras.layers.Activation(\"linear\", dtype = tf.float32)\n</code></pre>"},{"location":"reference/DeepSaki/models/#DeepSaki.models.discriminators.PatchDiscriminator.call","title":"call","text":"<pre><code>call(inputs: tf.Tensor) -&gt; tf.Tensor\n</code></pre> <p>Calls the <code>PatchDiscriminator</code> model.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>tf.Tensor</code> <p>Tensor of shape <code>(batch, height, width, channel)</code>.</p> required <p>Returns:</p> Type Description <code>tf.Tensor</code> <p>tf.Tensor: Tensor of shape <code>(batch, height//2**</code>number_of_blocks<code>, width//2**</code>number_of_blocks<code>, 1)</code>.</p> Source code in <code>DeepSaki/models/discriminators.py</code> <pre><code>def call(self, inputs:tf.Tensor)-&gt;tf.Tensor:\n    \"\"\"Calls the `PatchDiscriminator` model.\n\n    Args:\n        inputs (tf.Tensor): Tensor of shape `(batch, height, width, channel)`.\n\n    Returns:\n        tf.Tensor: Tensor of shape `(batch, height//2**`number_of_blocks`, width//2**`number_of_blocks`, 1)`.\n    \"\"\"\n    x = inputs\n    x = self.encoder(x)\n    x = self.conv1(x)\n    x = self.conv2(x)\n    return self.linear_dtype(x)\n</code></pre>"},{"location":"reference/DeepSaki/models/#DeepSaki.models.discriminators.UNetDiscriminator","title":"UNetDiscriminator","text":"<pre><code>UNetDiscriminator(\n    number_of_levels: int = 4,\n    upsampling: str = \"transpose_conv\",\n    downsampling: str = \"average_pooling\",\n    kernels: int = 3,\n    first_kernel: int = 5,\n    split_kernels: bool = False,\n    number_of_blocks: int = 2,\n    activation: str = \"leaky_relu\",\n    use_ResidualBlock: bool = False,\n    residual_cardinality: int = 1,\n    limit_filters: int = 512,\n    n_bottleneck_blocks: int = 1,\n    filters: int = 64,\n    dropout_rate: float = 0.2,\n    use_self_attention: bool = False,\n    use_spec_norm: bool = False,\n    use_bias: bool = True,\n    fully_connected: str = \"MLP\",\n    padding: PaddingType = PaddingType.ZERO,\n    kernel_initializer: Optional[\n        tf.keras.initializers.Initializer\n    ] = None,\n    gamma_initializer: Optional[\n        tf.keras.initializers.Initializer\n    ] = None,\n)\n</code></pre> <p>             Bases: <code>tf.keras.Model</code></p> <p>U-Net based discriminator for pixel-wise real/fake prediction plus additional output for global prediction.</p> <p>Usually used in a GAN framework.</p> Info <p>Implementation as used in the VoloGAN paper.</p> Architecture <pre><code>flowchart LR\ni([Input])--&gt;e1\nsubgraph Encoder\ne1--&gt;e2--&gt;e3--&gt;ex\nend\nsubgraph Bottleneck\nex--&gt;b1--&gt;bx\nend\nbx--&gt;gp[GlobalSumPooling]--&gt;sn[SPecNorm]--&gt;eo([Global Prediction])\nsubgraph Decoder\nbx--&gt;dx--&gt;d3--&gt;d2--&gt;d1\nend\nd1--&gt;o([Pixel-Wise Prediction])\ne1--&gt;d1\ne2--&gt;d2\ne3--&gt;d3\nex--&gt;dx</code></pre> <p>Example: <pre><code>import DeepSaki as dsk\nimport tensorflow as tf\ninputs = tf.keras.layers.Input(shape = (256,256,4))\nmodel = tf.keras.Model(inputs=inputs, outputs=dsk.models.UNetDiscriminator(5).call(inputs))\nmodel.summary()\ntf.keras.utils.plot_model(model, show_shapes=True, expand_nested=True, show_dtype=True, to_file='model.png')\n</code></pre></p> <p>Initialize the <code>UNetDiscriminator</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>number_of_levels</code> <code>int</code> <p>Number of down and upsampling levels of the model. Defaults to 4.</p> <code>4</code> <code>upsampling</code> <code>str</code> <p>Describes the upsampling method used. Defaults to \"transpose_conv\".</p> <code>'transpose_conv'</code> <code>downsampling</code> <code>str</code> <p>Describes the downsampling method. Defaults to \"average_pooling\".</p> <code>'average_pooling'</code> <code>kernels</code> <code>int</code> <p>Size of the convolutions kernels. Defaults to 3.</p> <code>3</code> <code>first_kernel</code> <code>int</code> <p>The first convolution can have a different kernel size, to e.g. increase the perceptive field, while the channel depth is still low. Defaults to 5.</p> <code>5</code> <code>split_kernels</code> <code>bool</code> <p>To decrease the number of parameters, a convolution with the kernel_size <code>(kernel,kernel)</code> can be splitted into two consecutive convolutions with the kernel_size <code>(kernel,1)</code> and <code>(1,kernel)</code> respectivly. Defaults to False.</p> <code>False</code> <code>number_of_blocks</code> <code>int</code> <p>Number of consecutive convolutional building blocks, i.e. <code>Conv2DBlock</code>. Defaults to 2.</p> <code>2</code> <code>activation</code> <code>str</code> <p>String literal or tensorflow activation function object to obtain activation function. Defaults to \"leaky_relu\".</p> <code>'leaky_relu'</code> <code>use_ResidualBlock</code> <code>bool</code> <p>Whether or not to use the ResidualBlock instead of the <code>Conv2DBlock</code>. Defaults to False.</p> <code>False</code> <code>residual_cardinality</code> <code>int</code> <p>Cardinality for the <code>ResidualBlock</code>. Defaults to 1.</p> <code>1</code> <code>limit_filters</code> <code>int</code> <p>Limits the number of filters, which is doubled with every downsampling block. Defaults to 512.</p> <code>512</code> <code>n_bottleneck_blocks</code> <code>int</code> <p>Number of consecutive convolution blocks in the bottleneck. Defaults to 1.</p> <code>1</code> <code>filters</code> <code>int</code> <p>Number of filters for the initial encoder block. Defaults to 64.</p> <code>64</code> <code>dropout_rate</code> <code>float</code> <p>Probability of the dropout layer. If the preceeding layer has more than one channel, spatial dropout is applied, otherwise standard dropout. Defaults to 0.2.</p> <code>0.2</code> <code>use_self_attention</code> <code>bool</code> <p>Determines whether to apply self-attention in the decoder. Defaults to False.</p> <code>False</code> <code>use_spec_norm</code> <code>bool</code> <p>Applies spectral normalization to convolutional and dense layers. Defaults to False.</p> <code>False</code> <code>use_bias</code> <code>bool</code> <p>Whether convolutions and dense layers include a bias or not. Defaults to True.</p> <code>True</code> <code>fully_connected</code> <code>str</code> <p>Determines whether 1x1 convolutions are replaced by linear layers, which gives the same result, but linear layers are faster. Option: \"MLP\" or \"1x1_conv\". Defaults to \"MLP\".</p> <code>'MLP'</code> <code>padding</code> <code>PaddingType</code> <p>Padding type. Defaults to PaddingType.ZERO.</p> <code>PaddingType.ZERO</code> <code>kernel_initializer</code> <code>tf.keras.initializers.Initializer</code> <p>Initialization of the convolutions kernels. Defaults to None.</p> <code>None</code> <code>gamma_initializer</code> <code>tf.keras.initializers.Initializer</code> <p>Initialization of the normalization layers. Defaults to None.</p> <code>None</code> Source code in <code>DeepSaki/models/discriminators.py</code> <pre><code>def __init__(self,\n            number_of_levels:int= 4,\n            upsampling:str = \"transpose_conv\",\n            downsampling:str = \"average_pooling\",\n            kernels:int = 3,\n            first_kernel:int = 5,\n            split_kernels:bool = False,\n            number_of_blocks:int = 2,\n            activation:str = \"leaky_relu\",\n            use_ResidualBlock:bool = False,\n            residual_cardinality:int = 1,\n            limit_filters:int = 512,\n            n_bottleneck_blocks:int = 1,\n            filters:int = 64,\n            dropout_rate:float = 0.2,\n            use_self_attention:bool=False,\n            use_spec_norm:bool=False,\n            use_bias:bool= True,\n            fully_connected:str = \"MLP\",\n            padding:PaddingType=PaddingType.ZERO,\n            kernel_initializer:Optional[tf.keras.initializers.Initializer] = None,\n            gamma_initializer:Optional[tf.keras.initializers.Initializer] =  None\n            ):\n    \"\"\"Initialize the `UNetDiscriminator` object.\n\n    Args:\n        number_of_levels (int, optional): Number of down and upsampling levels of the model. Defaults to 4.\n        upsampling (str, optional): Describes the upsampling method used. Defaults to \"transpose_conv\".\n        downsampling (str, optional): Describes the downsampling method. Defaults to \"average_pooling\".\n        kernels (int, optional): Size of the convolutions kernels. Defaults to 3.\n        first_kernel (int, optional): The first convolution can have a different kernel size, to e.g. increase the\n            perceptive field, while the channel depth is still low. Defaults to 5.\n        split_kernels (bool, optional): To decrease the number of parameters, a convolution with the kernel_size\n            `(kernel,kernel)` can be splitted into two consecutive convolutions with the kernel_size `(kernel,1)` and\n            `(1,kernel)` respectivly. Defaults to False.\n        number_of_blocks (int, optional): Number of consecutive convolutional building blocks, i.e. `Conv2DBlock`.\n            Defaults to 2.\n        activation (str, optional): String literal or tensorflow activation function object to obtain activation\n            function. Defaults to \"leaky_relu\".\n        use_ResidualBlock (bool, optional): Whether or not to use the ResidualBlock instead of the\n            `Conv2DBlock`. Defaults to False.\n        residual_cardinality (int, optional): Cardinality for the `ResidualBlock`. Defaults to 1.\n        limit_filters (int, optional): Limits the number of filters, which is doubled with every downsampling block.\n            Defaults to 512.\n        n_bottleneck_blocks (int, optional): Number of consecutive convolution blocks in the bottleneck. Defaults to 1.\n        filters (int, optional): Number of filters for the initial encoder block. Defaults to 64.\n        dropout_rate (float, optional): Probability of the dropout layer. If the preceeding layer has more than one\n            channel, spatial dropout is applied, otherwise standard dropout. Defaults to 0.2.\n        use_self_attention (bool, optional): Determines whether to apply self-attention in the decoder. Defaults to\n            False.\n        use_spec_norm (bool, optional): Applies spectral normalization to convolutional and dense layers. Defaults to\n            False.\n        use_bias (bool, optional): Whether convolutions and dense layers include a bias or not. Defaults to True.\n        fully_connected (str, optional): Determines whether 1x1 convolutions are replaced by linear layers, which gives\n            the same result, but linear layers are faster. Option: \"MLP\" or \"1x1_conv\". Defaults to \"MLP\".\n        padding (PaddingType, optional): Padding type. Defaults to PaddingType.ZERO.\n        kernel_initializer (tf.keras.initializers.Initializer, optional): Initialization of the convolutions kernels.\n            Defaults to None.\n        gamma_initializer (tf.keras.initializers.Initializer, optional): Initialization of the normalization layers.\n            Defaults to None.\n    \"\"\"\n    super(UNetDiscriminator, self).__init__()\n    ch = filters\n\n    self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n\n    self.encoder = Encoder(number_of_levels=number_of_levels, filters=filters, limit_filters=limit_filters,  downsampling=downsampling, kernels=kernels, split_kernels=split_kernels, number_of_blocks=number_of_blocks,activation=activation, first_kernel=first_kernel, use_ResidualBlock=use_ResidualBlock, channel_list=[ch,2*ch,4*ch,8*ch,8*ch], use_spec_norm=use_spec_norm,use_self_attention=use_self_attention,output_skips=True, use_bias = use_bias,residual_cardinality=residual_cardinality,padding = padding, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n    self.bottleNeck = Bottleneck(use_ResidualBlock=use_ResidualBlock, n_bottleneck_blocks=n_bottleneck_blocks, kernels=kernels, split_kernels=split_kernels,number_of_blocks=number_of_blocks, activation = activation,dropout_rate=dropout_rate, channel_list=[16*ch], use_spec_norm=use_spec_norm, use_bias = use_bias,residual_cardinality=residual_cardinality,padding = padding, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n    self.decoder = Decoder(number_of_levels=number_of_levels, upsampling=upsampling, filters=filters, limit_filters=limit_filters, kernels=kernels, split_kernels=split_kernels,number_of_blocks=number_of_blocks,activation=activation,dropout_rate=dropout_rate, use_ResidualBlock=use_ResidualBlock, channel_list=[8*ch,8*ch,4*ch,2*ch,ch], use_spec_norm=use_spec_norm, use_bias = use_bias,residual_cardinality=residual_cardinality,padding = padding, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer,enable_skip_connections_input=True)\n    if fully_connected == \"MLP\":\n        self.img_reconstruction = DenseBlock(units = 1, use_spec_norm = use_spec_norm, number_of_blocks = 1, activation = None, apply_final_normalization = False, use_bias = use_bias, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n    elif fully_connected == \"1x1_conv\":\n        self.img_reconstruction = Conv2DBlock(filters = 1,  kernels = 1, split_kernels  = False, number_of_blocks = 1, activation = None,use_spec_norm=use_spec_norm, apply_final_normalization = False, use_bias = use_bias,padding = padding, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n    self.linear = DenseBlock(units = 1, use_spec_norm = use_spec_norm, number_of_blocks = 1, activation = None, apply_final_normalization = False, use_bias = use_bias, kernel_initializer = kernel_initializer, gamma_initializer = gamma_initializer)\n    #To enable mixed precission support for matplotlib and distributed training and to increase training stability\n    self.linear_dtype = tf.keras.layers.Activation(\"linear\", dtype = tf.float32)\n</code></pre>"},{"location":"reference/DeepSaki/models/#DeepSaki.models.discriminators.UNetDiscriminator.call","title":"call","text":"<pre><code>call(inputs: tf.Tensor) -&gt; Tuple[tf.Tensor, tf.Tensor]\n</code></pre> <p>Calls the <code>UNetDiscriminator</code> model.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>tf.Tensor</code> <p>Tensor of shape (<code>batch</code>,<code>height</code>,<code>width</code>,<code>channel</code>).</p> required <p>Returns:</p> Name Type Description <code>decoder_output</code> <code>tf.Tensor</code> <p>Real/fake prediction for each pixel of shape (batch, height, width, 1)</p> <code>encoder_output</code> <code>tf.Tensor</code> <p>Global real/fake prediction of shape (batch, 1).</p> Source code in <code>DeepSaki/models/discriminators.py</code> <pre><code>def call(self, inputs:tf.Tensor)-&gt;Tuple[tf.Tensor,tf.Tensor]:\n    \"\"\"Calls the `UNetDiscriminator` model.\n\n    Args:\n        inputs (tf.Tensor): Tensor of shape (`batch`,`height`,`width`,`channel`).\n\n    Returns:\n        decoder_output: Real/fake prediction for each pixel of shape (batch, height, width, 1)\n        encoder_output: Global real/fake prediction of shape (batch, 1).\n    \"\"\"\n    x = inputs\n    encoder_output, skip_connections = self.encoder(x)\n    bottleneck_output = self.bottleNeck(encoder_output)\n    decoder_output = self.decoder([bottleneck_output,skip_connections])\n\n    out1 = GlobalSumPooling2D()(bottleneck_output)\n    out1 = self.linear(out1)\n    out1 = self.linear_dtype(out1)\n\n    out2 = self.img_reconstruction(decoder_output)\n    out2 = self.linear_dtype(out2)\n    return out1, out2\n</code></pre>"},{"location":"reference/DeepSaki/optimizers/","title":"optimizers","text":"<p>The SWATS Optimizer is an optimizer that starts with ADAM and switches to SGD after a certain epoch.</p> <p>SWATS Paper: http://arxiv.org/abs/1712.07628</p> <p>This implementation is based on tensorflow's ADAM, SGD and NADAM optimizer TensorFlow ADAM: https://github.com/tensorflow/tensorflow/blob/85c8b2a817f95a3e979ecd1ed95bff1dc1335cff/tensorflow/python/keras/optimizer_v2/adam.py Tensorflow SGD: https://github.com/tensorflow/tensorflow/blob/85c8b2a817f95a3e979ecd1ed95bff1dc1335cff/tensorflow/python/keras/optimizer_v2/gradient_descent.py Tensorflow NADAM: https://github.com/tensorflow/tensorflow/blob/85c8b2a817f95a3e979ecd1ed95bff1dc1335cff/tensorflow/python/keras/optimizer_v2/nadam.py</p>"},{"location":"reference/DeepSaki/optimizers/#DeepSaki.optimizers.swats.SwatsAdam","title":"SwatsAdam","text":"<pre><code>SwatsAdam(\n    learning_rate: float = 0.001,\n    beta_1: float = 0.9,\n    beta_2: float = 0.999,\n    epsilon: float = 1e-07,\n    amsgrad: bool = False,\n    momentum: float = 0.0,\n    nesterov: bool = False,\n    name: str = \"SwatsAdam\",\n    **kwargs: Any\n)\n</code></pre> <p>             Bases: <code>optimizer_v2.OptimizerV2</code></p> Source code in <code>DeepSaki/optimizers/swats.py</code> <pre><code>def __init__(\n    self,\n    learning_rate: float = 0.001,\n    beta_1: float = 0.9,\n    beta_2: float = 0.999,\n    epsilon: float = 1e-7,\n    amsgrad: bool = False,\n    momentum: float = 0.0,\n    nesterov: bool = False,\n    name: str = \"SwatsAdam\",\n    **kwargs: Any,\n) -&gt; None:\n    super(SwatsAdam, self).__init__(name, **kwargs)\n    self._set_hyper(\"learning_rate\", kwargs.get(\"lr\", learning_rate))\n    self._set_hyper(\"decay\", self._initial_decay)\n    self._set_hyper(\"beta_1\", beta_1)\n    self._set_hyper(\"beta_2\", beta_2)\n    self.epsilon = epsilon or backend_config.epsilon()\n    self.amsgrad = amsgrad\n    self.currentOptimizer = \"adam\"\n\n    self._momentum = False\n    if isinstance(momentum, ops.Tensor) or callable(momentum) or momentum &gt; 0:\n        self._momentum = True\n    if isinstance(momentum, (int, float)) and (momentum &lt; 0 or momentum &gt; 1):\n        raise ValueError(\"`momentum` must be between [0, 1].\")\n    self._set_hyper(\"momentum\", momentum)\n\n    self.nesterov = nesterov\n</code></pre>"},{"location":"reference/DeepSaki/optimizers/#DeepSaki.optimizers.swats.SwatsAdam.get_config","title":"get_config","text":"<pre><code>get_config() -&gt; Dict[str, Any]\n</code></pre> <p>Serialization of the object.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with the class' variable names as keys.</p> Source code in <code>DeepSaki/optimizers/swats.py</code> <pre><code>def get_config(self) -&gt; Dict[str, Any]:\n    \"\"\"Serialization of the object.\n\n    Returns:\n        Dictionary with the class' variable names as keys.\n    \"\"\"\n    config = super(SwatsAdam, self).get_config()\n    config.update(\n        {\n            \"learning_rate\": self._serialize_hyperparameter(\"learning_rate\"),\n            \"decay\": self._serialize_hyperparameter(\"decay\"),\n            \"beta_1\": self._serialize_hyperparameter(\"beta_1\"),\n            \"beta_2\": self._serialize_hyperparameter(\"beta_2\"),\n            \"epsilon\": self.epsilon,\n            \"amsgrad\": self.amsgrad,\n            \"momentum\": self._serialize_hyperparameter(\"momentum\"),\n            \"nesterov\": self.nesterov,\n            \"current_optimizer\": self.currentOptimizer,\n        }\n    )\n    return config\n</code></pre>"},{"location":"reference/DeepSaki/optimizers/#DeepSaki.optimizers.swats.SwatsNadam","title":"SwatsNadam","text":"<pre><code>SwatsNadam(\n    learning_rate: float = 0.001,\n    beta_1: float = 0.9,\n    beta_2: float = 0.999,\n    epsilon: float = 1e-07,\n    momentum: float = 0.0,\n    nesterov: bool = False,\n    name: str = \"SwatsNadam\",\n    **kwargs: Any\n)\n</code></pre> <p>             Bases: <code>optimizer_v2.OptimizerV2</code></p> Source code in <code>DeepSaki/optimizers/swats.py</code> <pre><code>def __init__(\n    self,\n    learning_rate: float = 0.001,\n    beta_1: float = 0.9,\n    beta_2: float = 0.999,\n    epsilon: float = 1e-7,\n    momentum: float = 0.0,\n    nesterov: bool = False,\n    name: str = \"SwatsNadam\",\n    **kwargs: Any,\n) -&gt; None:\n    super(SwatsNadam, self).__init__(name, **kwargs)\n    self._set_hyper(\"learning_rate\", kwargs.get(\"lr\", learning_rate))\n    self._set_hyper(\"decay\", self._initial_decay)\n    self._set_hyper(\"beta_1\", beta_1)\n    self._set_hyper(\"beta_2\", beta_2)\n    self.epsilon = epsilon or backend_config.epsilon()\n    self.currentOptimizer = \"nadam\"\n\n    self._momentum = False\n    if isinstance(momentum, ops.Tensor) or callable(momentum) or momentum &gt; 0:\n        self._momentum = True\n    if isinstance(momentum, (int, float)) and (momentum &lt; 0 or momentum &gt; 1):\n        raise ValueError(\"`momentum` must be between [0, 1].\")\n    self._set_hyper(\"momentum\", momentum)\n\n    self.nesterov = nesterov\n    self._m_cache = None\n</code></pre>"},{"location":"reference/DeepSaki/optimizers/#DeepSaki.optimizers.swats.SwatsNadam.get_config","title":"get_config","text":"<pre><code>get_config() -&gt; Dict[str, Any]\n</code></pre> <p>Serialization of the object.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with the class' variable names as keys.</p> Source code in <code>DeepSaki/optimizers/swats.py</code> <pre><code>def get_config(self) -&gt; Dict[str, Any]:\n    \"\"\"Serialization of the object.\n\n    Returns:\n        Dictionary with the class' variable names as keys.\n    \"\"\"\n    config = super(SwatsNadam, self).get_config()\n    config.update(\n        {\n            \"learning_rate\": self._serialize_hyperparameter(\"learning_rate\"),\n            \"decay\": self._serialize_hyperparameter(\"decay\"),\n            \"beta_1\": self._serialize_hyperparameter(\"beta_1\"),\n            \"beta_2\": self._serialize_hyperparameter(\"beta_2\"),\n            \"epsilon\": self.epsilon,\n            \"momentum\": self._serialize_hyperparameter(\"momentum\"),\n            \"nesterov\": self.nesterov,\n            \"current_optimizer\": self.currentOptimizer,\n        }\n    )\n    return config\n</code></pre>"},{"location":"reference/DeepSaki/utils/","title":"utils","text":"<p>Collection of methods for setting-up the compute environment.</p> Tips <ul> <li>Overview on distributed training with TensorFlow.</li> <li>Tutorial of using tf.distrubute on custom     training.</li> </ul>"},{"location":"reference/DeepSaki/utils/#DeepSaki.utils.environment.detect_accelerator","title":"detect_accelerator","text":"<pre><code>detect_accelerator(\n    gpu_memory_groth: bool = False,\n) -&gt; Tuple[\n    tf.distribute.Strategy,\n    str,\n    Optional[\n        Union[\n            tf.distribute.cluster_resolver.TPUClusterResolver,\n            List[tf.config.LogicalDevice],\n        ]\n    ],\n]\n</code></pre> <p>Detects the availability of TPUs and GPUs and connects to all available devices.</p> <p>Parameters:</p> Name Type Description Default <code>gpu_memory_groth</code> <code>bool</code> <p>If true, memory is allocated on demand. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>tf.distribute.Strategy</code> <p><code>strategy</code>: pointer to the distribution strategy configuration object</p> <code>str</code> <p><code>runtime_environment</code>: Info string describing the HW that might be used for conditions, i.e. \"TPU, \"GPU\", \"CPU\"</p> <code>Optional[Union[tf.distribute.cluster_resolver.TPUClusterResolver, List[tf.config.LogicalDevice]]]</code> <p><code>hw_accelerator_handle</code>: pointer to the HW accelerator</p> Source code in <code>DeepSaki/utils/environment.py</code> <pre><code>def detect_accelerator(\n    gpu_memory_groth: bool = False,\n) -&gt; Tuple[\n    tf.distribute.Strategy,\n    str,\n    Optional[Union[tf.distribute.cluster_resolver.TPUClusterResolver, List[tf.config.LogicalDevice]]],\n]:\n    \"\"\"Detects the availability of TPUs and GPUs and connects to all available devices.\n\n    Args:\n        gpu_memory_groth (bool, optional): If true, memory is allocated on demand. Defaults to False.\n\n    Returns:\n        `strategy`: pointer to the distribution strategy configuration object\n        `runtime_environment`: Info string describing the HW that might be used for conditions, i.e. \"TPU, \"GPU\", \"CPU\"\n        `hw_accelerator_handle`: pointer to the HW accelerator\n    \"\"\"\n    hw_accelerator_handle = None\n    tpu = None\n    gpus = []\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n        hw_accelerator_handle = tpu\n    except ValueError:\n        if gpu_memory_groth:\n            for gpu in tf.config.experimental.list_physical_devices(\"GPU\"):\n                tf.config.experimental.set_memory_growth(gpu, enable=True)\n        gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n        hw_accelerator_handle = gpus\n\n    # Select appropriate distribution strategy\n    if tpu is not None:\n        runtime_environment = \"TPU\"\n        tf.config.experimental_connect_to_cluster(tpu)\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        strategy = tf.distribute.TPUStrategy(\n            tpu\n        )  # Going back and forth between TPU and host is expensive. Better to run 128 batches on the TPU before reporting back.\n        logging.info(f\"Running on TPU {tpu.cluster_spec().as_dict()['worker']}\")\n    elif len(gpus) &gt; 1:\n        runtime_environment = \"GPU\"\n        strategy = tf.distribute.MirroredStrategy([gpu.name for gpu in gpus])\n        logging.info(f\"Running on multiple GPUs {[gpu.name for gpu in gpus]}\")\n    elif len(gpus) == 1:\n        runtime_environment = \"GPU\"\n        strategy = tf.distribute.get_strategy()  # default strategy that works on CPU and single GPU\n        logging.info(f\"Running on single GPU {gpus[0].name}\")\n    else:\n        runtime_environment = \"CPU\"\n        strategy = tf.distribute.get_strategy()  # default strategy that works on CPU and single GPU\n        logging.info(\"Running on CPU\")\n\n    logging.info(f\"Number of accelerators: {strategy.num_replicas_in_sync}\")\n    logging.info(\"____________________________________________________________________________________\")\n    logging.info(\"Device List: \")\n    logging.info(device_lib.list_local_devices())\n\n    return strategy, runtime_environment, hw_accelerator_handle\n</code></pre>"},{"location":"reference/DeepSaki/utils/#DeepSaki.utils.environment.enable_mixed_precision","title":"enable_mixed_precision","text":"<pre><code>enable_mixed_precision() -&gt; None\n</code></pre> <p>Set mixed precission policy depending on the available HW accelerator. TPU:<code>mixed_bfloat16</code>. GPU:<code>mixed_float16</code>.</p> Source code in <code>DeepSaki/utils/environment.py</code> <pre><code>def enable_mixed_precision() -&gt; None:\n    \"\"\"Set mixed precission policy depending on the available HW accelerator. TPU:`mixed_bfloat16`. GPU:`mixed_float16`.\"\"\"\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n    except ValueError:\n        tpu = None\n\n    policy_config = \"mixed_bfloat16\" if tpu else \"mixed_float16\"\n    policy = tf.keras.mixed_precision.Policy(policy_config)\n    tf.keras.mixed_precision.set_global_policy(policy)\n    logging.info(\"Mixed precision enabled to {}\".format(policy_config))\n</code></pre>"},{"location":"reference/DeepSaki/utils/#DeepSaki.utils.environment.enable_xla_acceleration","title":"enable_xla_acceleration","text":"<pre><code>enable_xla_acceleration() -&gt; None\n</code></pre> <p>Enable compiler acceleration for linear algebra operations.</p> Source code in <code>DeepSaki/utils/environment.py</code> <pre><code>def enable_xla_acceleration() -&gt; None:\n    \"\"\"Enable compiler acceleration for linear algebra operations.\"\"\"\n    tf.config.optimizer.set_jit(enabled=\"autoclustering\")\n    logging.info(\"Linear algebra acceleration enabled\")\n</code></pre>"}]}